[
    {
        "title": "Esto piensan los migrantes venezolanos sobre lo que pasa en su pa\u00eds",
        "text": "Ha pasado una semana desde que el Consejo Nacional Electoral anunciara a Nicol\u00e1s Maduro como ganador de las elecciones presidenciales en Venezuela, en un proceso altamente cuestionado por su falta de transparencia. Esto es lo que piensan los venezolanos que han tenido que abandonar su pa\u00eds.",
        "url": "https://cnnespanol.cnn.com/video/migrantes-venezolanos-elecciones-mirador-mundial-tv/",
        "category": 1,
        "summary": "Ha pasado una semana desde que el Consejo Nacional Electoral anunciara a Nicol\u00e1s Maduro como ganador de las elecciones presidenciales en Venezuela, en un proceso altamente cuestionado por su falta de transparencia. Esto es lo que piensan los venezolanos que han tenido que abandonar su pa\u00eds."
    },
    {
        "title": "Gobiernos piden a su gente abandonar el L\u00edbano por aumento de tensiones",
        "text": "Pa\u00edses como EE.UU., Inglaterra y Francia, son algunos de los pa\u00edses que han pedido a sus ciudadanos abandonar el L\u00edbano, mientras las crecientes tensiones en la regi\u00f3n generan temores de un conflicto m\u00e1s amplio en Medio Oriente. Por otro lado, en las \u00faltimas horas, un ataque a\u00e9reo israel\u00ed mat\u00f3 a un funcionario de Hamas y su madre, seg\u00fan informa la familia de los fallecidos a CNN.",
        "url": "https://cnnespanol.cnn.com/video/gobiernos-ciudadanos-abandonar-libanotensiones-mirador-mundial-tv/",
        "category": 1,
        "summary": "Pa\u00edses como EE.UU., Inglaterra y Francia, son algunos de los pa\u00edses que han pedido a sus ciudadanos abandonar el L\u00edbano, mientras las crecientes tensiones en la regi\u00f3n generan temores de un conflicto m\u00e1s amplio en Medio Oriente. Por otro lado, en las \u00faltimas horas, un ataque a\u00e9reo israel\u00ed mat\u00f3 a un funcionario de Hamas y su madre, seg\u00fan informa la familia de los fallecidos a CNN."
    },
    {
        "title": "From golf to hunting, a new crop of startups want to make these experiences even better",
        "text": "From golf to fishing to pickleball, outdoor sports and recreation saw a boom during the pandemic. But unlike some pandemic-driven trends (virtual conferences, Zoom happy hours), the interest in outdoor activities has stuck.\n\nBy the end of 2023, outdoor participation grew to a record 175.8 million people, or 57% of all Americans aged 6 and older, according to the Outdoor Industry Association.\n\nBut the influx of interest exposed the lack of innovation in many parts of this industry. From over-the-phone bookings to cash payments to a gear market dominated by legacy brands, the outdoor recreation category was full of opportunity for entrepreneurs.\n\nIn the past couple of years, entrepreneurs have built SaaS software for hunting and fishing guides. Founders have developed AI-powered companies that find and book golf tee times. Kevin Durant invested in a startup that helps people locate pickleball courts. And the list goes on.\n\nVCs, meanwhile, have been interested as well. In 2019, VCs invested $48.60 million into 25 sports tech companies, according to PitchBook. In 2021 that rose to $949.26 million and 53 companies; in 2023, during the VC winter, investments totaled $189.71 million and 43 companies. While that\u2019s a major crash from 2021 (when VC investing was record-breaking across all industries), the dollars invested last year still represent a 290% increase over 2019\u2019s pre-pandemic levels.\n\nOnline acceleration\n\nBenjamin Lazarov, the co-founder and CEO of AnyCreek, a startup building booking and back-end business software for fishing and hunting guides, told TechCrunch that he would never have thought of building his company before the pandemic. But then Lazarov tried to book a hunting guide in Vermont in 2022.\n\nHe had asked the cashier at a nearby Orvis for some local guide recommendations and she gave him a paper list of seven names to call. As he called and left voicemails, it dawned on him that everything else had moved online during COVID-19, why was he still trying to book a guided hunt over the phone? After that he left his role as a regional director of growth at Compass and launched AnyCreek.\n\n\u201cMy thought is that had I tried to start this business five years before COVID-19, no way,\u201d Lazarov said \u201cCOVID-19 definitely accelerated the adoption to more technology. There is a new generation of guides that are tech first, mobile first, they are operating every other part of their life online.\u201d\n\nMallard Bay is another startup bringing hunting and fishing guides online. The Houston, Texas-based company launched in 2019 and saw its site blossom after lockdowns eased in 2021, from 19 guides on the platform to over 100, co-founder and CEO Logan Meaux told TechCrunch.\n\nLoop Golf, a startup that automates finding and booking a tee time at a public golf course, was founded as a response to the increase in new golfers making it difficult for existing players to play. Matthew Holden, the co-founder and CEO of Loop Golf, told TechCrunch in June that he got the idea when he realized that the rise in interest in golf that occurred post-pandemic wasn\u2019t going away.\n\n\u201cIt became increasingly more difficult to find a tee time,\u201d Holden said. \u201cI\u2019d be spending hours looking at the different options. I got fed up with it and my wife definitely got fed up with it.\u201d\n\nBehavior changes\n\nWhen the world was forced to move online, consumers learned to expect to interact with all businesses that way, Lazarov said. People simply don\u2019t want to go back to booking things over the phone, and they want technology to do more for their recreational lives, just as it\u2019s doing in their work and personal lives in other areas.\n\nIt\u2019s like a restaurant in New York that updated its point of sale system to handle cashless transactions. \u201cThey are never going back,\u201d Lazarov said, because the new POS system \u201chelps them better operate their business. Think of how much more money they can make.\u201d\n\nScott Holloway, a managing partner at Starting Line, and an investor in AnyCreek, said that people, especially younger generations, are increasingly looking to spend more money on experiences than physical things. This trend has been well-documented in numerous surveys dating back to a decade ago. He added that the companies building the tech to power those experience-based transactions are in a smart position.\n\nPlus, people often need to buy new gear and equipment to do said new activities.\n\nNumerous startups have also popped up to supply gear, clothes and accessories for these new hobbyists. Eastside Golf and Malbon Golf are both venture-backed startups looking to outfit and accessorize new-found golf fans that maybe don\u2019t want to look like 1960\u2019s era Arnold Palmer. Nettie and Recess are startups designing pickleball paddles that don\u2019t look like they came from a retirement community in Florida.\n\nEarly venture-backed entrants to this category like Hipcamp, a booking platform for campsites, and AutoCamp, a glamping company, showed that there was consumer appetite for innovation in this category years ago. Now, more than 10 years later, Holloway thinks there is still so much entrepreneurs can do.\n\nThere\u2019s reason to believe he\u2019s right. Rental services for things like canoes, kayaks and stand up paddleboards still have websites that look like they were built in 2002. Ditto for those offering services for everything from archery to ziplines. Many businesses in the outdoor recreation category could still use some tech help.\n\n\u201cThe market is massive,\u201d Holloway said. \u201cAs Marc Andreessen famously said, \u2018software is eating the world,\u2019 but this is one of the last pieces of consumer spend that software hasn\u2019t ate. Consumers are demanding it. It\u2019s a massive market opportunity to ride that wave.\u201d",
        "url": "https://techcrunch.com/2024/08/04/from-golf-to-hunting-a-new-crop-of-startups-want-to-make-these-experiences-even-better/",
        "category": 3,
        "summary": "Online acceleration\n\nBenjamin Lazarov, the co-founder and CEO of AnyCreek, a startup building booking and back-end business software for fishing and hunting guides, told TechCrunch that he would never have thought of building his company before the pandemic. Think of how much more money they can make.\u201d\n\nScott Holloway, a managing partner at Starting Line, and an investor in AnyCreek, said that people, especially younger generations, are increasingly looking to spend more money on experiences than physical things. The Houston, Texas-based company launched in 2019 and saw its site blossom after lockdowns eased in 2021, from 19 guides on the platform to over 100, co-founder and CEO Logan Meaux told TechCrunch."
    },
    {
        "title": "OpenAI says it\u2019s taking a \u2018deliberate approach\u2019 to releasing tools that can detect writing from ChatGPT",
        "text": "OpenAI has built a tool that could potentially catch students who cheat by asking ChatGPT to write their assignments \u2014 but according to The Wall Street Journal, the company is debating whether to actually release it.\n\nIn a statement provided to TechCrunch, an OpenAI spokesperson confirmed that the company is researching the text watermarking method described in the Journal\u2019s story, but said it\u2019s taking a \u201cdeliberate approach\u201d to due to \u201cthe complexities involved and its likely impact on the broader ecosystem beyond OpenAI.\u201d\n\n\u201cThe text watermarking method we\u2019re developing is technically promising, but has important risks we\u2019re weighing while we research alternatives, including susceptibility to circumvention by bad actors and the potential to disproportionately impact groups like non-English speakers,\u201d the spokesperson said.\n\nThis would be a different approach from most previous efforts to detect AI-generated text, which have been largely ineffective. Even OpenAI itself shut down its previous AI text detector last year due to its \u201clow rate of accuracy.\u201d\n\nWith text watermarking, OpenAI would focus solely on detecting writing from ChatGPT, not from other companies\u2019 models. It would do so by making small changes to how ChatGPT selects words, essentially creating an invisible watermark in the writing that could later be detected by a separate tool.\n\nFollowing the publication of the Journal\u2019s story, OpenAI also updated a May blog post about its research around detecting AI-generated content. The update says text watermarking has proven \u201chighly accurate and even effective against localized tampering, such as paraphrasing,\u201d but has proven \u201cless robust against globalized tampering; like using translation systems, rewording with another generative model, or asking the model to insert a special character in between every word and then deleting that character.\u201d\n\nAs a result, OpenAI writes that this method is \u201ctrivial to circumvention by bad actors.\u201d OpenAI\u2019s update also echoes the spokesperson\u2019s point about non-English speakers, writing that text watermarking could \u201cstigmatize use of AI as a useful writing tool for non-native English speakers.\u201d",
        "url": "https://techcrunch.com/2024/08/04/openai-says-its-taking-a-deliberate-approach-to-releasing-tools-that-can-detect-writing-from-chatgpt/",
        "category": 0,
        "summary": "OpenAI has built a tool that could potentially catch students who cheat by asking ChatGPT to write their assignments \u2014 but according to The Wall Street Journal, the company is debating whether to actually release it. In a statement provided to TechCrunch, an OpenAI spokesperson confirmed that the company is researching the text watermarking method described in the Journal\u2019s story, but said it\u2019s taking a \u201cdeliberate approach\u201d to due to \u201cthe complexities involved and its likely impact on the broader ecosystem beyond OpenAI.\u201d\n\n\u201cThe text watermarking method we\u2019re developing is technically promising, but has important risks we\u2019re weighing while we research alternatives, including susceptibility to circumvention by bad actors and the potential to disproportionately impact groups like non-English speakers,\u201d the spokesperson said. The update says text watermarking has proven \u201chighly accurate and even effective against localized tampering, such as paraphrasing,\u201d but has proven \u201cless robust against globalized tampering; like using translation systems, rewording with another generative model, or asking the model to insert a special character in between every word and then deleting that character.\u201d\n\nAs a result, OpenAI writes that this method is \u201ctrivial to circumvention by bad actors.\u201d OpenAI\u2019s update also echoes the spokesperson\u2019s point about non-English speakers, writing that text watermarking could \u201cstigmatize use of AI as a useful writing tool for non-native English speakers.\u201d"
    },
    {
        "title": "Even after $1.6B in VC money, the lab-grown meat industry is facing \u2018massive\u2019 issues",
        "text": "When Mosa Meat served up a first-of-its-kind, lab-grown hamburger in 2013, it cost over $300,000. Eleven years later, around 200 startups worldwide remain hopeful that growing meat from cells, rather than slaughtering animals, will one day be a major portion of our food supply.\n\nDespite their optimism, such success is not a given. In 2024, the industry has hit such rocky times that multiple startups have been forced to scale back or close shop.\n\nThe industry is talking about eventually producing about 30 million pounds of finished product annually. However, over 100 billion pounds of traditional meat is produced annually today. And if plant-based meat accounts for about 1% of all meat by volume, it\u2019s going to take time for cultivated meat to get to that point, said Better Meat CEO Paul Shapiro, who wrote a book in 2018 called \u201cClean Meat.\u201d\n\nAny goal that puts cultivated meat in big box grocery stores or on fast food menus in the 2020s is \u201cunrealistic,\u201d he told TechCrunch.\n\n\u201cEven if it were ready now, and the funding was available now, the time that it takes to build these factories is years. And the fact is, the money isn\u2019t there for it, which is why a lot of these companies have abandoned their plans for commercial-scale factories,\u201d Shapiro said.\n\nFor instance, New Age Eats shut down in early 2023, with founder Brian Spears posting on LinkedIn that the company was unable to secure funds to complete its pilot facility. Berkeley-based Upside Foods laid off workers and put plans on hold for a new Chicago-area facility. Israel-based Aleph Farms let go of 30% of its staff in June, also citing difficulties in raising capital.\n\nSan Francisco Bay Area-based SCiFi Foods also permanently closed in June. SCiFi CEO Joshua March shared on LinkedIn: \u201cUnfortunately, in this funding environment, we could not raise the capital that we needed to commercialize the SCiFi burger, and SCiFi Foods ran out of time.\u201d\n\n\u201cIt\u2019s a really tough time right now, not just for cultivated meat, but any biotech related field,\u201d said Tufts University Professor of Biomedical Engineering David Kaplan. \u201cThe economy is in the toilet, the investing funds are not there and people are being very, very cautious these days.\u201d\n\nIt\u2019s important to note that the startups pursuing lab-grown meat are not just pursuing scientific curiosity or a more humane, but equally nutritious, protein alternative. Most global organizations, including the United Nations, are throwing out 2050 as the date when we will need to be producing 60% more food to feed the nearly 10 billion people expected to be inhabiting Earth.\n\nThose working on cultured meat hope it will be a significant portion of that 60%, with no need to slaughter animals or use the kind of land, water and energy resources needed by the traditional meat industry.\n\nStill, as promising as this field was 11 years ago, there has been frustratingly slow progress on the industry\u2019s main barriers.\n\nCompanies working on lab-grown meat \u2014 although the industry prefers the terms cell-cultured or cultivated meat \u2014 make it from animal cells, typically stem cells, that are fed growth factors in some sort of cell-feeding solution, or medium. The cells are fed and grown in bioreactors, then processed with ingredients and flavorings to mimic the taste, texture, look and mouth feel of traditional meat.\n\nYet most companies are unable to produce large quantities of meat from their processes, much less at a low-enough cost or even at price parity with traditional meat. Moreover, the facilities cost hundreds of millions of dollars and take years to build. Achieving taste and texture is also a problem, as is changing the perceptions of people who tend to think of these products as unappetizing \u201cFranken meat.\u201d\n\nOn top of all that, very few companies have achieved regulatory approval in the U.S. for their cultivated meat processes.\n\nPerhaps the biggest difficulty of all is the downturn in venture capital funding. In 2021 and 2022, cultivated meat companies pulled in over $1.6 billion in venture funding, according to Crunchbase analysis. As of June, Crunchbase was showing around $20 million in funding into this industry so far in 2024.\n\n\u201cChanging the world and reinventing the food system is hard, which is probably the least shocking conclusion that one can come to,\u201d Amy Chen, chief operating officer for Upside Foods, told TechCrunch.\n\nHowever, she, like all others in the cultured-meat industry, believes it can be done. She thinks there will be a point in development where some kind of Moore\u2019s law equivalent will kick in, and the industry will start seeing dramatic increases in production and achieve regulatory approval, which will increase the ways this product is brought to market, driving affordability and public acceptance.\n\nUpside Foods\u2019 cultivated chicken filet. (Image credit: Upside Foods) Image Credits: Upside Foods /\n\nGovernment funding to the funding rescue?\n\nBefore these companies can solve their technical problems, they must first overcome their funding ones. Lever VC managing partner Nick Cooney says investment into the category \u201chas dropped considerably in the last year or so,\u201d largely due to the general drop in VC funding overall. \u201cBut this sector is outpacing that drop,\u201d Cooney said.\n\nThe problem is that (other than all things AI), VCs are currently avoiding funding tech that has enormous upfront capital costs, doesn\u2019t currently produce much (if any) revenue (let alone profits), and may never prove to be viable businesses.\n\n\u201cVCs have largely made this shift from growth to profitability, and that\u2019s wreaked havoc\u201d on this industry, said Alex Frederick, senior emerging technology analyst at PitchBook. It\u2019s difficult to be profitable when you don\u2019t have a product to sell, he points out.\n\nPitchBook puts fundraising into cultivated meat at a double-digits decline over the past few years, Frederick said. The first quarter of 2024 was on pace to somewhat match the low pace of 2023 funding with 12 deals logged so far. Another 20 or so more potential deals are in the pipeline, he said.\n\nAt the start of 2024, there were around 200 cultured meat companies worldwide, according to PitchBook. But because most cultivated meat companies are startups, if they lose their ability to raise more venture funding, they tend to go out of business or be acquired. That\u2019s the stage where Tuft\u2019s Kaplan says the market sits now and, unfortunately, he has no prediction on when that will change, or how many will survive.\n\nOne possible solution is for startups to outsource cell manufacturing, leasing equipment and production rather than each of them spending $100 million to $200 million on their own facilities, Frederick says. Venture capitalists have liked this approach and infused some funding into companies doing this, like Ark Biotech, Prolific Machines, Pow.bio, No Meat Factory and Planetary.\n\nAnother funding option, Kaplan points out, is if governments are willing to kick in. Singapore, the first country to approve cultured meat for consumer consumption, is doing so. It\u2019s committed $230 million to research of alternative proteins. And the Israel Innovation Authority has an $18 million fund for alternative protein startups and research. Tufts\u2019 Kaplan believes we\u2019ll see more countries follow.\n\n\u201cIn a world that\u2019s kind of struggling right now with food security, it will become how much can the government invest into this approach,\u201d he said. \u201cJust like the government has invested in battery technology and chips, they are going to have to do the same thing for cultivated meat if we are going to make this work.\u201d\n\nHe has reason to hope. He points to Mosa Meat\u2019s $300,000 hamburger, saying that most companies today can make the same hamburger for $20.\n\nYes, that\u2019s still way more costly than a McDonald\u2019s Big Mac, but in 10 years, there was a four orders of magnitude reduction in cost with minimum government investment, he said.\n\n\u2018Massive\u2019 engineering hurdles\n\nOthers point out that even if money wasn\u2019t so tight, the industry still hasn\u2019t figured out how to make enough meat. Upside Foods knows about this. A lot about this.\n\nSo does competitor Eat Just. Founder Josh Tetrick said his company has sold 10 times the amount of cultivated meat as the entire rest of the industry combined. \u201cBut that\u2019s hardly any meat,\u201d he told TechCrunch. \u201cIt\u2019s in the single digit thousands of pounds, just to give you a sense of how small the volumes are, since only a handful of companies have regulatory approval.\u201d\n\nEat Just and Upside Foods are two of the only companies to receive regulatory approval to sell this meat to consumers, with Eat Just being the first to sell in Singapore and then the United States. Tetrick is using this market advantage to focus on how to make millions of pounds at or below the cost of conventional meat. But \u201cthere are massive engineering and technological hurdles to be overcome,\u201d he said.\n\nFor instance, his company is working on increasing cell densities, or edible cells produced per unit volume. That\u2019s a key metric for manufacturers in order to produce the maximum amount of meat from each bioreactor.\n\nThere are a variety of bioreactor technologies, each with different approaches to cell density. Some use batch methods (fixed amount of cells and the growth food medium processed at one time); others use continuous methods (a steady stream of inputs/outputs). Some stir the cells when adding fresh cell food; others suspend the cells and rotate the walls of the reactor.\n\nWhich of these technologies will be reliably best is still a matter of scientific research. Cultivated meat producer Believer Meats, for instance, showed in a 2023 study that cells grown in suspension can deliver densities of over 100 billion cells per liter \u2014 which it claims is over 17 times the industry standard. This increased process yields from 2% to 36% weight per volume of edible meat per run.\n\nImage of WildType\u2019s sushi-grade, lab-grown salmon. Image Credit: Arye Elfenbein/WildType Image Credits: Arye Elfenbein/WildType\n\nCostly cell food\n\nBeyond the reactor engineering, another major hurdle is both the engineering and cost of the cell growth medium. Cell media typically includes a mixture of an energy source, like glucose, that includes amino acids, salts, vitamins, water and other components.\n\nAlong with the hundreds of millions of dollars to build a facility, the cost to produce this media at scale is quite expensive. A 2022 study by the Department of Agricultural Economics at Oklahoma State University found that 1 kilogram (equal to about 2 pounds) of cell-cultured meat was estimated to cost $63 to produce. That was compared to $6.17 per kilogram for beef.\n\nWildtype, for instance, is making cultivated salmon. It started with a single cell and hasn\u2019t needed to go back to an animal to obtain more cells for five years now, according to co-founder Ary\u00e9 Elfenbein. It has now gained more understanding in how to best feed these cells to improve cell density.\n\n\u201cWe\u2019ve improved the yield of that process over time by understanding what nutrients these cells do best in,\u201d Elfenbein said. \u201cRaw fish is just extraordinarily complex, and all the aromatics and different components are something that we\u2019ve aspired to create a more difficult, structured product from the beginning.\u201d\n\nThe industry is also still working on methods to get the cells without taking them from animals. MarineXcell, for instance, is developing a way to produce embryonic stem-like cells, called induced pluripotent stem cells, or iPSCs, from crustacean cells \u2014 like lobster, shrimp and crab \u2014 using advanced nuclear reprogramming technologies.\n\nThe Israeli-based company says the technology, spearheaded by chief scientific officer Yossi Buganim, accelerates cell growth twice as fast as adult stem cells, but also maintains differentiation and cell growth potential over time, even under suboptimal conditions. Buganim\u2019s lab was able to do this with bovine cells and is now applying similar techniques to crustaceans.\n\nGetting along with the government\n\nFounders say that the lack of regulatory policies is holding the industry back, too.\n\n\u201cIt\u2019s the main reason why quite a number of companies haven\u2019t launched products yet,\u201d Wildtype co-founder Justin Kolbeck said. \u201cThey\u2019re on the journey during a multi-year regulatory review process, which is what consumers are watching. They want to make sure that the food regulators are taking their time looking under every stone, making sure that what we\u2019re putting out on the market is as safe as possible.\u201d\n\nThat said, no one thinks food safety is an area to skimp on \u2014 Wildtype\u2019s conversations with the U.S. Food and Drug Administration were \u201cconstructive and positive iterative processes for a number of years now,\u201d Kolbeck said. However, the company has also had conversations with potentially large customers interested in buying their products today. And Kolbeck doesn\u2019t want to speculate when Wildtype\u2019s regulatory approval will come.\n\nUpside\u2019s Chen said progress is being made. She believes regulators now have a better understanding about what cultivated meat is and more educated safety and regulatory concerns.\n\n\u201cWhen we got the first FDA approval, and others followed, it pretty much answered the question of, \u2018Could this ever be approved and is it safe?\u2019 Now our next-generation products need to go through a similar regulatory process, but that\u2019s more of a \u2018when,\u2019 not an \u2018if,\u2019\u201d she said.\n\nScientist holding petri dish with cultured meat. Image Credits: Liudmila Chernetska Image Credits: Liudmila Chernetska (opens in a new window) / Getty Images\n\nPublic perception\n\nBoth Upside Foods and Eat Just tested out their cultivated chicken products in a few restaurants following regulatory approval. However, Upside\u2019s Chen and Eat Just\u2019s Tetrick say those pilots have ended until they can scale further.\n\nOne thing they learned: Wide consumer appeal remains a problem, with people calling it \u201cFrankenfood,\u201d \u201cfaux meat\u201d or \u201clab-grown\u201d meat \u2014 which technically it is \u2014 but those descriptions don\u2019t sound appetizing. Florida has even already banned lab-grown meat.\n\n\u201cA challenge for all of us is how to help consumers fall in love with the category, understand what cultivated meat is, why we are behind it and what\u2019s in it for them,\u201d Chen said.\n\nTuft\u2019s Kaplan believes that more education, more transparency by the industry and more peer-reviewed published papers from respected universities, will all help.\n\nChen expects the field to be very different even two years from now. She\u2019s optimistic that consumers in a variety of geographies will be able to take their first bite of cultivated meat and \u201cthat it will be delicious.\u201d\n\nLever VC\u2019s Cooney also sees real progress being made. He points to Lever\u2019s portfolio company Clever Carnivore, a cultivated meat company that has raised around $9 million. \u201cFrom a price point reduction standpoint, they\u2019ve found a way to produce meaningful pilot quantities at quite a reasonable capex,\u201d Cooney said.\n\nIn the meantime, Eat Just\u2019s approach overall will be what the company is doing currently in Singapore with launching its cultivated meat in retail. The product is 3% cultivated meat, while the other portion is plant-based proteins.\n\nTetrick admits it is significantly less than the 60+% Eat Just first launched in 2020. However, by developing meat at 3%, he believes the company can significantly drive the cost down, thus building more consumer experience and awareness around cultivated meat.\n\nHe has a plan to increase that 3% over the next three to five years, while at the same time working on a lower-cost infrastructure, working on getting cell densities up and working on getting media costs down.\n\n\u201cWe don\u2019t think there\u2019s anything magical about it,\u201d Tetrick said. \u201cWe just have to do the necessary work across those different dimensions to get it done.\u201d",
        "url": "https://techcrunch.com/2024/08/04/even-after-1-6b-in-vc-money-the-lab-grown-meat-industry-is-facing-massive-issues/",
        "category": 3,
        "summary": "They want to make sure that the food regulators are taking their time looking under every stone, making sure that what we\u2019re putting out on the market is as safe as possible.\u201d\n\nThat said, no one thinks food safety is an area to skimp on \u2014 Wildtype\u2019s conversations with the U.S. Food and Drug Administration were \u201cconstructive and positive iterative processes for a number of years now,\u201d Kolbeck said. And if plant-based meat accounts for about 1% of all meat by volume, it\u2019s going to take time for cultivated meat to get to that point, said Better Meat CEO Paul Shapiro, who wrote a book in 2018 called \u201cClean Meat.\u201d\n\nAny goal that puts cultivated meat in big box grocery stores or on fast food menus in the 2020s is \u201cunrealistic,\u201d he told TechCrunch. SCiFi CEO Joshua March shared on LinkedIn: \u201cUnfortunately, in this funding environment, we could not raise the capital that we needed to commercialize the SCiFi burger, and SCiFi Foods ran out of time.\u201d\n\n\u201cIt\u2019s a really tough time right now, not just for cultivated meat, but any biotech related field,\u201d said Tufts University Professor of Biomedical Engineering David Kaplan."
    },
    {
        "title": "Meet the founder who built and sold a $600M enterprise software startup from Sri Lanka",
        "text": "Sri Lanka isn\u2019t renowned for its startup ecosystem, but one company has been something of an outlier in the South Asian island nation these past two decades. An open source enterprise software provider with customers such as Samsung, Axa, and AT&T, WSO2 recently agreed to be acquired by private equity giant EQT, at a valuation TechCrunch reported at the time to be north of $600 million. (We can now confirm that the valuation was in fact exactly $600 million.)\n\nThe transaction, which remains subject to regulatory approvals, means that EQT will become WSO2\u2019s sole owner, procuring all outstanding shares including those of WSO2\u2019s investors and current and ex-WSO2 employees.\n\nThis liquidity event could also create significant wealth among those inclined to start their own ventures, given that 30% of the proceeds will be going to those employees.\n\n\u201cThis shows that equity is important \u2014 one of the things that we have insisted on from day one is that every employee has been a shareholder,\u201d Weerawarana told TechCrunch in an interview. \u201cThat\u2019s very important, and it\u2019s a concept that has not been understood here before, because there haven\u2019t been companies that exited and gave any amount of meaningful financial return. Seeing is believing, right? Talk is cheap.\u201d\n\nThriving through war and unrest\n\nFounded out of the Sri Lankan capital, Colombo, in 2005, WSO2 is a middleware stack constituting tools such as API management, similar to Apigee which Google acquired for $625 million; and identity and access management (IAM), along the lines of $15 billion publicly traded Okta.\n\nThe main driving force behind this has been Weerawarana, a computer scientist and key figure in the open source community over the past 25 years, both as a member of the Apache Software Foundation and more recently as the creator of Ballerina, a cloud-native general purpose programming language for integrating distributed systems.\n\nPrior to WSO2, Weerawarana worked within IBM\u2019s research and development team in the U.S., where he helped develop web service specifications such as WSDL and BPEL. And it was there that the seed for WSO2 was sown.\n\n\u201cI actually tried inside IBM to build a new kind of middleware stack, but IBM wasn\u2019t interested,\u201d Weerawarana said. \u201cSo the only option was either start a company, or give up on the idea.\u201d\n\nWeerawarana spawned WSO2 in August 2005 alongside two co-founders: Davanum Srinivas, who left after two years; and Weerawarana\u2019s former IBM colleague Paul Fremantle, who would go on to serve as CTO until stepping down in 2015 (he later rejoined and then left again, but remains an advisor today).\n\nNotably, WSO2\u2019s center of gravity has remained in Sri Lanka, despite a longstanding civil war and external pressure to relocate to the U.S., where Weerawarana had lived previously for 16 years.\n\n\u201cI came back [to Sri Lanka] in 2001, and two weeks before I landed in Colombo, the airport was attacked by a terrorist group \u2014 there were still pieces of planes on the ground,\u201d he said. \u201cIn 2005, the war was still going on. Sri Lanka as a country has not been able to maintain a consistent calm environment for us, but that\u2019s okay.\u201d\n\nToday, 80% of WSO2\u2019s 780 employees are in Sri Lanka, with the remainder spread across a smattering of hubs in the U.S., Europe, and Asia.\n\n\u201cI wanted to show we could build a product-oriented tech company from Sri Lanka,\u201d Weerawarana continued. \u201cThere had never been a company like this, and at that time there wasn\u2019t even a company out of India like this. Indian companies were very services-oriented, as were Sri Lankan companies. But one of the big prices [for staying in Sri Lanka] was that at pretty much every funding round, the majority of investors would ask when I was moving back [to the U.S.]. And my answer was always the same: \u2018I\u2019m not moving back.\u2019\u201d\n\nInvestors weren\u2019t the only ones who pressured WSO2 to move: Customers and competitors have also used its location against it at various junctures.\n\n\u201cSome of our competitors fought against us, saying, \u2018Do you know where they are located?,\u2019 and that becomes a challenge,\u201d Weerawarana said. \u201cThen we\u2019ve had customers saying, \u2018You\u2019re located way over there, why are you charging us these prices?\u2019\u201d\n\nOn the flip side, WSO2\u2019s geographic setting gave it the pick of technical talent, owning mostly to the fact that it was a product-based business in a sea of services.\n\n\u201cWe\u2019ve never had a problem with engineering and technical talent. We\u2019ve been able to hire the best people in Sri Lanka for the last 19 years,\u201d Weerawarana said. \u201cIf you are a creative engineer, would you rather work for a services company, or be in a role where you could be creative and work on top-of-the-line technology?\u201d\n\nWSO2 CEO Sanjiva Weerawarana speaks to media during a product launch in Colombo on February 26, 2014 Image Credits: Ishara S.KODIKARA/AFP via Getty Images\n\nIntel inside\n\nAfter WSO2 raised a small round of angel funding in 2005, Intel\u2019s VC arm emerged as its earliest backer, investing in 2006 and through several follow-on rounds in subsequent years.\n\nIntel Capital\u2019s initial $2 million cash injection was critical to WSO2\u2019s early growth, and was the result of fortuitous timing. Pradeep Tagare was a senior investment manager at Intel Capital at that time and met Weerawarana through their associations with the Apache Software Foundation. Tagare was looking to invest in an open source startup to complement a duo of other open source investments it had made \u2014 one into Java-centric application server company JBoss (which Red Hat later acquired for $350 million), and another into database company MySQL (which Sun later snapped up for $1 billion).\n\n\u201cWe were looking at a bunch of open source investments as a strategic initiative for Intel, essentially to build an alternate stack on Intel hardware,\u201d Tagare explained to TechCrunch. \u201cWe had invested in JBoss, and we invested in MySQL. So we were now looking for an open source middleware company, and WSO2 fit the bill exactly.\u201d\n\nTagare\u2019s thesis was that countries situated in Asia would not only stand to benefit from the open source movement, but would also be likely to contribute a lot. Open source software development is naturally distributed, opening up the coding and collaboration process to those who didn\u2019t work at the big tech companies of those times.\n\n\u201cNow they could contribute \u2014 before, it was all really controlled by the Microsofts and the Oracles of the world,\u201d Tagare said. \u201cIts location wasn\u2019t necessarily a requirement, but being was based in Asia just made WSO2 even more interesting.\u201d\n\nMuch has changed in the 20 years since WSO2 arrived on the scene. With the advent of cloud computing and microservices \u2014 software built from smaller, loosely connected components that can be developed and maintained independently and which conveniently rely on APIs \u2014 WSO2 has been well-positioned as enterprises transition from legacy monolithic applications.\n\nNow with the AI revolution in full-swing, WSO2 is also set to capitalize given that APIs and and IAM are key components of the AI stack \u2014 from integrations through authentication and beyond. Moreover, WSO2 is integrating AI into its own products, recently debuting a new API manager that allows developers to integrate an AI-powered chatbot into their APIs to allow non-coders to test APIs using natural language.\n\nAccording to Crunchbase data, WSO2 raised $133 million over the years. However, Weerawarana clarified only $70 million was primary capital. Other rounds, like the $93 million Series E round two years ago led by Goldman Sachs, consisted of equity and debt.\n\nHowever the funding is sliced and diced, there\u2019s no ignoring the fact that WSO2 was a startup dinosaur by the time EQT came calling. After all, most successful VC-backed companies reach an exit within 10 years.\n\nSo what gives?\n\n\u201cWe\u2019ve had multiple people wanting to buy our company through the years, but I resisted because I always wanted to build a company that would reach an IPO \u2014 an independent business, basically,\u201d Weerawarana said.\n\nThat all changed in May, when WSO2 accepted an offer from EQT Private Capital Asia (formerly Baring Private Equity Asia), a private equity firm EQT acquired in 2022 for more than $7 billion. The difference this time was simple: one of WSO2\u2019s controlling shareholders \u201cwanted to get liquidity,\u201d according to Weerawarana.\n\n\u201cBecause they had more than 50%, it becomes a control transaction,\u201d he said.\n\nThat shareholder was San Francisco-based Toba Capital, a VC firm set up by Vinny Smith in 2012 after he sold Quest Software to Dell for more than $2 billion. Quest had previously invested in WSO2, equity that transferred to Dell through that acquisition \u2014 but Toba bought that stock back from Dell and went on to make further investments in WSO2, including buying Intel Capital\u2019s portion. Toba Capital partner Tyler Jewell also replaced Weerawarana as CEO for a two-year period, with Weerawarana returning to the hotseat in 2020.\n\nWeerawarana says the company has been cash-flow positive since 2017, and profitable \u201csince around 2018,\u201d but it hasn\u2019t had the luxury of vast pools of capital that would allow it to look at \u201cmultiple year strategies.\u201d This is something it will be able to do under EQT, one of the world\u2019s biggest private equity firms.\n\nIndeed, WSO2 says it will hit $100 million in annual recurring revenue (ARR) by Q3 this year, which is one of the key reasons EQT came calling.\n\n\u201cWSO2 really has all the ingredients we look for in a software business,\u201d EQT partner and global co-head of services Hari Gopalakrishnan told TechCrunch. \u201cDeep and long-lasting enterprise client relationships, successful product-led-growth, technically robust products, and prudent financial management. Pick a strength, WSO2 probably has it.\u201d\n\nFrom the outside, selling to private equity might not seem like the dream outcome for a founder with ambitions to go public and who values his company\u2019s independence. But Weerawarana insists that this outcome will better enable WSO2 to do just that.\n\n\u201cI started the company to make something that lasts. One of the reasons we didn\u2019t sell it previously is that we knew that would be the end of it,\u201d he said. \u201cEQT doesn\u2019t have any other businesses in this domain, they\u2019re trying to build around WSO2, not merge it with something else. Their goal is to build the company for five years, which aligns with what I wanted, and gives us five years to get to an IPO.\u201d\n\nDriving force\n\nUber logo on top of car Image Credits: Marek Antoni Iwanczuk/SOPA Images/LightRocket via Getty Images\n\nWhile running WSO2 is a time-consuming endeavor on its own, Weerawarana keeps busy with other initiatives such as a philanthropic effort called the Avinya Foundation, which he established in 2022 to support economically disadvantaged children via vocational education programs.\n\nIn 2017, Weerawarana also started driving for Uber, a move he says was designed to make it more socially acceptable in Sri Lanka to work in such jobs. If a successful businessman like him can do it, then anyone can.\n\n\u201cI would be coming home from work and I would just pick somebody up along the way,\u201d he said. \u201cThe main point I was trying to get across was that somebody who does a driving job is no different to somebody who does any other job \u2014 they\u2019re just offering a service and you pay for it. We have this mindset here that people who do certain kinds of jobs are not the same as other kinds of people. And breaking that is very important \u2014 doing Uber-driving is part of it. The Avinya Foundation is also focused on that problem, trying to support all our skilled workers, such as tradespeople.\u201d\n\nThe pandemic, among other global events, put a temporary halt on Weerawarana\u2019s Uber driving exploits; because people were doing it for survival, he didn\u2019t want to take money from people who needed it.\n\n\u201cI will do it again \u2014 things are getting much better,\u201d he said. \u201cTourism is almost back to normal, so the demand will be there, and it might make sense for me to drive. But I don\u2019t want to take any business from somebody else.\u201d",
        "url": "https://techcrunch.com/2024/08/03/meet-the-founder-who-built-and-sold-a-600m-enterprise-software-startup-from-sri-lanka/",
        "category": 3,
        "summary": "Talk is cheap.\u201d\n\nThriving through war and unrest\n\nFounded out of the Sri Lankan capital, Colombo, in 2005, WSO2 is a middleware stack constituting tools such as API management, similar to Apigee which Google acquired for $625 million; and identity and access management (IAM), along the lines of $15 billion publicly traded Okta. Their goal is to build the company for five years, which aligns with what I wanted, and gives us five years to get to an IPO.\u201d\n\nDriving force\n\nUber logo on top of car Image Credits: Marek Antoni Iwanczuk/SOPA Images/LightRocket via Getty Images\n\nWhile running WSO2 is a time-consuming endeavor on its own, Weerawarana keeps busy with other initiatives such as a philanthropic effort called the Avinya Foundation, which he established in 2022 to support economically disadvantaged children via vocational education programs. \u201cIf you are a creative engineer, would you rather work for a services company, or be in a role where you could be creative and work on top-of-the-line technology?\u201d\n\nWSO2 CEO Sanjiva Weerawarana speaks to media during a product launch in Colombo on February 26, 2014 Image Credits: Ishara S.KODIKARA/AFP via Getty Images\n\nIntel inside\n\nAfter WSO2 raised a small round of angel funding in 2005, Intel\u2019s VC arm emerged as its earliest backer, investing in 2006 and through several follow-on rounds in subsequent years."
    },
    {
        "title": "Tesla Dojo: Elon Musk\u2019s big plan to build an AI supercomputer, explained",
        "text": "For years, Elon Musk has talked about Dojo \u2014 the AI supercomputer that will be the cornerstone of Tesla\u2019s AI ambitions. It\u2019s important enough to Musk that he recently said the company\u2019s AI team is going to \u201cdouble down\u201d on Dojo as Tesla gears up to reveal its robotaxi in October.\n\nBut what exactly is Dojo? And why is it so critical to Tesla\u2019s long-term strategy?\n\nIn short: Dojo is Tesla\u2019s custom-built supercomputer that\u2019s designed to train its \u201cFull Self-Driving\u201d neural networks. Beefing up Dojo goes hand-in-hand with Tesla\u2019s goal to reach full self-driving and bring a robotaxi to market. FSD, which is on about 2 million Tesla vehicles today, can perform some automated driving tasks, but still requires a human to be attentive behind the wheel.\n\nTesla delayed the reveal of its robotaxi, which was slated for August, to October, but both Musk\u2019s public rhetoric and information from sources inside Tesla tell us that the goal of autonomy isn\u2019t going away.\n\nAnd Tesla appears poised to spend big on AI and Dojo to reach that feat.\n\nTesla\u2019s Dojo backstory\n\nElon Musk speaks at the Tesla Giga Texas manufacturing \u201cCyber Rodeo\u201d grand opening party on April 7, 2022 in Austin, Texas. Image Credits: Suzanne Cordeiro/AFP via Getty images Image Credits: Getty Images\n\nMusk doesn\u2019t want Tesla to be just an automaker, or even a purveyor of solar panels and energy storage systems. Instead, he wants Tesla to be an AI company, one that has cracked the code to self-driving cars by mimicking human perception.\n\nMost other companies building autonomous vehicle technology rely on a combination of sensors to perceive the world \u2013 like lidar, radar and cameras \u2013 as well as high-definition maps to localize the vehicle. Tesla believes it can achieve fully autonomous driving by relying on cameras alone to capture visual data and then use advanced neural networks to process that data and make quick decisions about how the car should behave.\n\nAs Tesla\u2019s former head of AI, Andrej Karpathy, said at the automaker\u2019s first AI Day in 2021, the company is basically trying to build \u201ca synthetic animal from the ground up.\u201d (Musk had been teasing Dojo since 2019, but Tesla officially announced it at AI Day.)\n\nCompanies like Alphabet\u2019s Waymo have commercialized Level 4 autonomous vehicles \u2013 which the SAE defines as a system that can drive itself without the need for human intervention under certain conditions \u2014 through a more traditional sensor and machine learning approach. Tesla has still yet to produce an autonomous system that doesn\u2019t require a human behind the wheel.\n\nAbout 1.8 million people have paid the hefty subscription price for Tesla\u2019s FSD, which currently costs $8,000 and has been priced as high as $15,000. The pitch is that Dojo-trained AI software will eventually be pushed out to Tesla customers via over-the-air updates. The scale of FSD also means Tesla has been able to rake in millions of miles worth of video footage that it uses to train FSD. The idea there is that the more data Tesla can collect, the closer the automaker can get to actually achieving full self-driving.\n\nHowever, some industry experts say there might be a limit to the brute force approach of throwing more data at a model and expecting it to get smarter.\n\n\u201cFirst of all, there\u2019s an economic constraint, and soon it will just get too expensive to do that,\u201d Anand Raghunathan, Purdue University\u2019s Silicon Valley professor of electrical and computer engineering, told TechCrunch. Further, he said, \u201cSome people claim that we might actually run out of meaningful data to train the models on. More data doesn\u2019t necessarily mean more information, so it depends on whether that data has information that is useful to create a better model, and if the training process is able to actually distill that information into a better model.\u201d\n\nRaghunathan said despite these doubts, the trend of more data appears to be here for the short-term at least. And more data means more compute power needed to store and process it all to train Tesla\u2019s AI models. That is where Dojo, the supercomputer, comes in.\n\nWhat is a supercomputer?\n\nDojo is Tesla\u2019s supercomputer system that\u2019s designed to function as a training ground for AI, specifically FSD. The name is a nod to the space where martial arts are practiced.\n\nA supercomputer is made up of thousands of smaller computers called nodes. Each of those nodes has its own CPU (central processing unit) and GPU (graphics processing unit). The former handles overall management of the node, and the latter does the complex stuff, like splitting tasks into multiple parts and working on them simultaneously. GPUs are essential for machine learning operations like those that power FSD training in simulation. They also power large language models, which is why the rise of generative AI has made Nvidia the most valuable company on the planet.\n\nEven Tesla buys Nvidia GPUs to train its AI (more on that later).\n\nWhy does Tesla need a supercomputer?\n\nTesla\u2019s vision-only approach is the main reason Tesla needs a supercomputer. The neural networks behind FSD are trained on vast amounts of driving data to recognize and classify objects around the vehicle and then make driving decisions. That means that when FSD is engaged, the neural nets have to collect and process visual data continuously at speeds that match the depth and velocity recognition capabilities of a human.\n\nIn other words, Tesla means to create a digital duplicate of the human visual cortex and brain function.\n\nTo get there, Tesla needs to store and process all the video data collected from its cars around the world and run millions of simulations to train its model on the data.\n\nTesla appears to rely on Nvidia to power its current Dojo training computer, but it doesn\u2019t want to have all its eggs in one basket \u2014 not least because Nvidia chips are expensive. Tesla also hopes to make something better that increases bandwidth and decreases latencies. That\u2019s why the automaker\u2019s AI division decided to come up with its own custom hardware program that aims to train AI models more efficiently than traditional systems.\n\nAt that program\u2019s core is Tesla\u2019s proprietary D1 chips, which the company says are optimized for AI workloads.\n\nTell me more about these chips\n\nGanesh Venkataramanan, former senior director of Autopilot hardware, presenting the D1 training tile at Tesla\u2019s 2021 AI Day. Image Credits: Tesla/screenshot of streamed event Image Credits: Screenshot | Tesla\n\nTesla is of a similar opinion to Apple, in that it believes hardware and software should be designed to work together. That\u2019s why Tesla is working to move away from the standard GPU hardware and design its own chips to power Dojo.\n\nTesla unveiled its D1 chip, a silicon square the size of a palm, on AI Day in 2021. The D1 chip entered into production as of at least May this year. The Taiwan Semiconductor Manufacturing Company (TSMC) is manufacturing the chips using 7 nanometer semiconductor nodes. The D1 has 50 billion transistors and a large die size of 645 millimeters squared, according to Tesla. This is all to say that the D1 promises to be extremely powerful and efficient and to handle complex tasks quickly.\n\n\u201cWe can do compute and data transfers simultaneously, and our custom ISA, which is the instruction set architecture, is fully optimized for machine learning workloads,\u201d said Ganesh Venkataramanan, former senior director of Autopilot hardware, at Tesla\u2019s 2021 AI Day. \u201cThis is a pure machine learning machine.\u201d\n\nThe D1 is still not as powerful as Nvidia\u2019s A100 chip, though, which is also manufactured by TSMC using a 7 nanometer process. The A100 contains 54 billion transistors and has a die size of 826 square millimeters, so it performs slightly better than Tesla\u2019s D1.\n\nTo get a higher bandwidth and higher compute power, Tesla\u2019s AI team fused 25 D1 chips together into one tile to function as a unified computer system. Each tile has a compute power of 9 petaflops and 36 terabytes per second of bandwidth, and contains all the hardware necessary for power, cooling and data transfer. You can think of the tile as a self-sufficient computer made up of 25 smaller computers. Six of those tiles make up one rack, and two racks make up a cabinet. Ten cabinets make up an ExaPOD. At AI Day 2022, Tesla said Dojo would scale by deploying multiple ExaPODs. All of this together makes up the supercomputer.\n\nTesla is also working on a next-gen D2 chip that aims to solve information flow bottlenecks. Instead of connecting the individual chips, the D2 would put the entire Dojo tile onto a single wafer of silicon.\n\nTesla hasn\u2019t confirmed how many D1 chips it has ordered or expects to receive. The company also hasn\u2019t provided a timeline for how long it will take to get Dojo supercomputers running on D1 chips.\n\nIn response to a June post on X that said: \u201cElon is building a giant GPU cooler in Texas,\u201d Musk replied that Tesla was aiming for \u201chalf Tesla AI hardware, half Nvidia/other\u201d over the next 18 months or so. The \u201cother\u201d could be AMD chips, per Musk\u2019s comment in January.\n\nWhat does Dojo mean for Tesla?\n\nTesla\u2019s humanoid robot Optimus Prime II at WAIC in Shanghai, China, on July 7, 2024. Image Credits: Costfoto/NurPhoto via Getty Images) Image Credits: Getty Images\n\nTaking control of its own chip production means that Tesla might one day be able to quickly add large amounts of compute power to AI training programs at a low cost, particularly as Tesla and TSMC scale up chip production.\n\nIt also means that Tesla may not have to rely on Nvidia\u2019s chips in the future, which are increasingly expensive and hard to secure.\n\nDuring Tesla\u2019s second-quarter earnings call, Musk said that demand for Nvidia hardware is \u201cso high that it\u2019s often difficult to get the GPUs.\u201d He said he was \u201cquite concerned about actually being able to get steady GPUs when we want them, and I think this therefore requires that we put a lot more effort on Dojo in order to ensure that we\u2019ve got the training capability that we need.\u201d\n\nThat said, Tesla is still buying Nvidia chips today to train its AI. In June, Musk posted on X:\n\n\u201cOf the roughly $10B in AI-related expenditures I said Tesla would make this year, about half is internal, primarily the Tesla-designed AI inference computer and sensors present in all of our cars, plus Dojo. For building the AI training superclusters, Nvidia hardware is about 2/3 of the cost. My current best guess for Nvidia purchases by Tesla are $3B to $4B this year.\u201d\n\nInference compute refers to the AI computations performed by Tesla cars in real time, and is separate from the training compute that Dojo is responsible for.\n\nDojo is a risky bet, one that Musk has hedged several times by saying that Tesla might not succeed.\n\nIn the long run, Tesla could theoretically create a new business model based on its AI division. Musk has said that the first version of Dojo will be tailored for Tesla computer vision labeling and training, which is great for FSD and for training Optimus, Tesla\u2019s humanoid robot. But it wouldn\u2019t be useful for much else.\n\nMusk has said that future versions of Dojo will be more tailored to general purpose AI training. One potential problem with that is that almost all AI software out there has been written to work with GPUs. Using Dojo to train general purpose AI models would require rewriting the software.\n\nThat is, unless Tesla rents out its compute, similar to how AWS and Azure rent out cloud computing capabilities. Musk also noted during Q2 earnings that he sees \u201ca path to being competitive with Nvidia with Dojo.\u201d\n\nA September 2023 report from Morgan Stanley predicted that Dojo could add $500 billion to Tesla\u2019s market value by unlocking new revenue streams in the form of robotaxis and software services.\n\nIn short, Dojo\u2019s chips are an insurance policy for the automaker, but one that could pay dividends.\n\nHow far along is Dojo?\n\nNvidia CEO Jen-Hsun Huang and Tesla CEO Elon Musk at the GPU Technology Conference in San Jose, California. Image Credits: Kim Kulish/Corbis via Getty Images Image Credits: Getty Images\n\nReuters reported last year that Tesla began production on Dojo in July 2023, but a June 2023 post from Musk suggested that Dojo had been \u201conline and running useful tasks for a few months.\u201d\n\nAround the same time, Tesla said it expected Dojo to be one of the top five most powerful supercomputers by February 2024 \u2014 a feat that has yet to be publicly disclosed, leaving us doubtful that it has occurred.\n\nThe company also said it expects Dojo\u2019s total compute to reach 100 exaflops in October 2024. (1 exaflop is equal to 1 quintillion computer operations per second. To reach 100 exaflops and assuming that one D1 can achieve 362 teraflops, Tesla would need more than 276,000 D1s, or around 320,500 Nvidia A100 GPUs.)\n\nTesla also pledged in January 2024 to spend $500 million to build a Dojo supercomputer at its gigafactory in Buffalo, New York.\n\nIn May 2024, Musk noted that the rear portion of Tesla\u2019s Austin gigafactory will be reserved for a \u201csuper dense, water-cooled supercomputer cluster.\u201d\n\nJust after Tesla\u2019s second-quarter earnings call, Musk posted on X that the automaker\u2019s AI team is using Tesla HW4 AI computer (renamed AI4), which is the hardware that lives on Tesla vehicles, in the training loop with Nvidia GPUs. He noted that the breakdown is roughly 90,000 Nvidia H100s plus 40,000 AI4 computers.\n\n\u201cAnd Dojo 1 will have roughly 8k H100-equivalent of training online by end of year,\u201d he continued. \u201cNot massive, but not trivial either.\u201d",
        "url": "https://techcrunch.com/2024/08/03/tesla-dojo-elon-musks-big-plan-to-build-an-ai-supercomputer-explained/",
        "category": 3,
        "summary": "During Tesla\u2019s second-quarter earnings call, Musk said that demand for Nvidia hardware is \u201cso high that it\u2019s often difficult to get the GPUs.\u201d He said he was \u201cquite concerned about actually being able to get steady GPUs when we want them, and I think this therefore requires that we put a lot more effort on Dojo in order to ensure that we\u2019ve got the training capability that we need.\u201d\n\nThat said, Tesla is still buying Nvidia chips today to train its AI. In May 2024, Musk noted that the rear portion of Tesla\u2019s Austin gigafactory will be reserved for a \u201csuper dense, water-cooled supercomputer cluster.\u201d\n\nJust after Tesla\u2019s second-quarter earnings call, Musk posted on X that the automaker\u2019s AI team is using Tesla HW4 AI computer (renamed AI4), which is the hardware that lives on Tesla vehicles, in the training loop with Nvidia GPUs. Image Credits: Kim Kulish/Corbis via Getty Images Image Credits: Getty Images\n\nReuters reported last year that Tesla began production on Dojo in July 2023, but a June 2023 post from Musk suggested that Dojo had been \u201conline and running useful tasks for a few months.\u201d\n\nAround the same time, Tesla said it expected Dojo to be one of the top five most powerful supercomputers by February 2024 \u2014 a feat that has yet to be publicly disclosed, leaving us doubtful that it has occurred."
    },
    {
        "title": "Many safety evaluations for AI models have significant limitations",
        "text": "Despite increasing demand for AI safety and accountability, today\u2019s tests and benchmarks may fall short, according to a new report.\n\nGenerative AI models \u2014 models that can analyze and output text, images, music, videos and so on \u2014 are coming under increased scrutiny for their tendency to make mistakes and generally behave unpredictably. Now, organizations from public sector agencies to big tech firms are proposing new benchmarks to test these models\u2019 safety.\n\nToward the end of last year, startup Scale AI formed a lab dedicated to evaluating how well models align with safety guidelines. This month, NIST and the U.K. AI Safety Institute released tools designed to assess model risk.\n\nBut these model-probing tests and methods may be inadequate.\n\nThe Ada Lovelace Institute (ALI), a U.K.-based nonprofit AI research organization, conducted a study that interviewed experts from academic labs, civil society, and who are producing vendors models, as well as audited recent research into AI safety evaluations. The co-authors found that while current evaluations can be useful, they\u2019re non-exhaustive, can be gamed easily, and don\u2019t necessarily give an indication of how models will behave in real-world scenarios.\n\n\u201cWhether a smartphone, a prescription drug or a car, we expect the products we use to be safe and reliable; in these sectors, products are rigorously tested to ensure they are safe before they are deployed,\u201d Elliot Jones, senior researcher at the ALI and co-author of the report, told TechCrunch. \u201cOur research aimed to examine the limitations of current approaches to AI safety evaluation, assess how evaluations are currently being used and explore their use as a tool for policymakers and regulators.\u201d\n\nBenchmarks and red teaming\n\nThe study\u2019s co-authors first surveyed academic literature to establish an overview of the harms and risks models pose today, and the state of existing AI model evaluations. They then interviewed 16 experts, including four employees at unnamed tech companies developing generative AI systems.\n\nThe study found sharp disagreement within the AI industry on the best set of methods and taxonomy for evaluating models.\n\nSome evaluations only tested how models aligned with benchmarks in the lab, not how models might impact real-world users. Others drew on tests developed for research purposes, not evaluating production models \u2014 yet vendors insisted on using these in production.\n\nWe\u2019ve written about the problems with AI benchmarks before, and the study highlights all these problems and more.\n\nThe experts quoted in the study noted that it\u2019s tough to extrapolate a model\u2019s performance from benchmark results and unclear whether benchmarks can even show that a model possesses a specific capability. For example, while a model may perform well on a state bar exam, that doesn\u2019t mean it\u2019ll be able to solve more open-ended legal challenges.\n\nThe experts also pointed to the issue of data contamination, where benchmark results can overestimate a model\u2019s performance if the model has been trained on the same data that it\u2019s being tested on. Benchmarks, in many cases, are being chosen by organizations not because they\u2019re the best tools for evaluation, but for the sake of convenience and ease of use, the experts said.\n\n\u201cBenchmarks risk being manipulated by developers who may train models on the same data set that will be used to assess the model, equivalent to seeing the exam paper before the exam, or by strategically choosing which evaluations to use,\u201d Mahi Hardalupas, researcher at the ALI and a study co-author, told TechCrunch. \u201cIt also matters which version of a model is being evaluated. Small changes can cause unpredictable changes in behaviour and may override built-in safety features.\u201d\n\nThe ALI study also found problems with \u201cred-teaming,\u201d the practice of tasking individuals or groups with \u201cattacking\u201d a model to identify vulnerabilities and flaws. A number of companies use red-teaming to evaluate models, including AI startups OpenAI and Anthropic, but there are few agreed-upon standards for red teaming, making it difficult to assess a given effort\u2019s effectiveness.\n\nExperts told the study\u2019s co-authors that it can be difficult to find people with the necessary skills and expertise to red-team, and that the manual nature of red teaming makes it costly and laborious \u2014 presenting barriers for smaller organizations without the necessary resources.\n\nPossible solutions\n\nPressure to release models faster and a reluctance to conduct tests that could raise issues before a release are the main reasons AI evaluations haven\u2019t gotten better.\n\n\u201cA person we spoke with working for a company developing foundation models felt there was more pressure within companies to release models quickly, making it harder to push back and take conducting evaluations seriously,\u201d Jones said. \u201cMajor AI labs are releasing models at a speed that outpaces their or society\u2019s ability to ensure they are safe and reliable.\u201d\n\nOne interviewee in the ALI study called evaluating models for safety an \u201cintractable\u201d problem. So what hope does the industry \u2014 and those regulating it \u2014 have for solutions?\n\nMahi Hardalupas, researcher at the ALI, believes that there\u2019s a path forward, but that it\u2019ll require more engagement from public-sector bodies.\n\n\u201cRegulators and policymakers must clearly articulate what it is that they want from evaluations,\u201d he said. \u201cSimultaneously, the evaluation community must be transparent about the current limitations and potential of evaluations.\u201d\n\nHardalupas suggests that governments mandate more public participation in the development of evaluations and implement measures to support an \u201cecosystem\u201d of third-party tests, including programs to ensure regular access to any required models and data sets.\n\nJones thinks that it may be necessary to develop \u201ccontext-specific\u201d evaluations that go beyond simply testing how a model responds to a prompt, and instead look at the types of users a model might impact (e.g. people of a particular background, gender or ethnicity) and the ways in which attacks on models could defeat safeguards.\n\n\u201cThis will require investment in the underlying science of evaluations to develop more robust and repeatable evaluations that are based on an understanding of how an AI model operates,\u201d she added.\n\nBut there may never be a guarantee that a model\u2019s safe.\n\n\u201cAs others have noted, \u2018safety\u2019 is not a property of models,\u201d Hardalupas said. \u201cDetermining if a model is \u2018safe\u2019 requires understanding the contexts in which it is used, who it is sold or made accessible to, and whether the safeguards that are in place are adequate and robust to reduce those risks. Evaluations of a foundation model can serve an exploratory purpose to identify potential risks, but they cannot guarantee a model is safe, let alone \u2018perfectly safe.\u2019 Many of our interviewees agreed that evaluations cannot prove a model is safe and can only indicate a model is unsafe.\u201d",
        "url": "https://techcrunch.com/2024/08/04/many-safety-evaluations-for-ai-models-have-significant-limitations/",
        "category": 2,
        "summary": "\u201cBenchmarks risk being manipulated by developers who may train models on the same data set that will be used to assess the model, equivalent to seeing the exam paper before the exam, or by strategically choosing which evaluations to use,\u201d Mahi Hardalupas, researcher at the ALI and a study co-author, told TechCrunch. \u201cSimultaneously, the evaluation community must be transparent about the current limitations and potential of evaluations.\u201d\n\nHardalupas suggests that governments mandate more public participation in the development of evaluations and implement measures to support an \u201cecosystem\u201d of third-party tests, including programs to ensure regular access to any required models and data sets. \u201cOur research aimed to examine the limitations of current approaches to AI safety evaluation, assess how evaluations are currently being used and explore their use as a tool for policymakers and regulators.\u201d\n\nBenchmarks and red teaming\n\nThe study\u2019s co-authors first surveyed academic literature to establish an overview of the harms and risks models pose today, and the state of existing AI model evaluations."
    },
    {
        "title": "Yelp\u2019s chief product officer talks AI and authenticity",
        "text": "Yelp might not be the first company that comes to mind when someone mentions artificial intelligence, but Chief Product Officer Craig Saldanha said AI is already transforming the Yelp experience.\n\nIn fact, most of the company\u2019s recent announcements center on AI, whether that\u2019s adding new AI-powered summaries or launching an AI assistant to connect consumers with service providers. So I spoke to Saldanha (who joined Yelp after nearly a decade at Amazon) to learn more about Yelp\u2019s AI strategy.\n\nWe also discussed what advantages Yelp brings to the AI race, how Yelp can add AI without threatening the authenticity of the user reviews on the platform, and how it\u2019s competing with new avenues for local discovery like TikTok.\n\nThis interview has been edited for length and clarity.\n\nGoing back through all the recent news from Yelp, it\u2019s all AI, AI, AI. Can you say more about how you look at AI and the role it plays at Yelp?\n\nImage: Yelp\n\nJust to set the table, our stated mission hasn\u2019t changed. Our goal is to connect consumers with great local businesses, and that hasn\u2019t changed over time.\n\nWe\u2019ve been investing in AI for more than 10 years now. But over the last couple of years, the advances in generative AI and other LLMs has really allowed us to take advantage of a couple of things. The first is, the real differentiator of Yelp is the hundreds of millions of reviews that we have. LLMs essentially allow us to parse all of that data in a way and at a speed that we\u2019ve never had before. It allows us to present information to consumers in a way that feels both precise, as well as personal \u2014 you can now find that needle in the haystack.\n\nWe recognize that users come to Yelp to connect with either other users or pros, and they come because of the authenticity of our content, because they know it\u2019s from actual human beings. We\u2019ll never take that away. So we use AI, essentially, to remove all of the friction to facilitate those types of connections.\n\nWe think about the consumer as having three phases when they come to Yelp. The first is, they come with a very strong search intent, they know they want to find a plumber, they know they want to find a good place for lunch, etc. So the first step is essentially defining that intent. The second step is, once we\u2019ve helped them define that intent, and they know exactly what they\u2019re looking for, we present them with a lot of different results, and they need to pick either a single business or like a couple of businesses that they want to connect with. Then the third step is actually making that connection. We\u2019ve invested heavily in AI in each of those steps.\n\nThe first step, refining search intent when a consumer comes to Yelp. [If you\u2019re doing a simple search like] \u201cI\u2019m looking for a Mediterranean restaurant,\u201d we have a pretty sophisticated model that first understands what you\u2019re looking for, and then essentially decides not only what restaurants to show you, but the order in which to show you those restaurants.\n\nWhat\u2019s really cool now is the advent of LLMs means you can search for even more specific things, and it will understand what you\u2019re looking for. As an example, we live in suburban Seattle, and my wife is always on the hunt for these very specialized spices for different kinds of cuisines. In the past, let\u2019s say she\u2019s making Indian food, I would look for \u201cIndian grocery store,\u201d and we essentially do a match for those words and return the results. Now, I can search for a very specific Indian spice, and the LLM will understand that it\u2019s a spice, that it\u2019s found in an Indian store. Even better than that, it is able to go through all of the reviews that we have, understand when other consumers are referring to those spices \u2014 so it could be a different spice, but it understands now that those grocery stores actually carry these types of spices.\n\nThen when it shows me the results, it will not only order them in a way that is a better match for me, but it will highlight the specific snippets of consumer reviews. That\u2019s super powerful, it genuinely feels very, very personal.\n\nIn the past, say, if you were looking for tacos, we would show you restaurants that had tacos, not a big deal. Now, we are able to look at every photo that consumers have submitted for every single restaurant, pull out tacos from those specific restaurants and show them right in search.\n\nI think the piece that I\u2019m most excited about is that we\u2019re taking [these capabilities] off of Yelp as well. So we\u2019ve recently announced what we\u2019re calling our Yelp Fusion API. [This interview was conducted prior to a recent controversy among indie developers over paid access to Yelp\u2019s API.]\n\nNow, someone on a third party, let\u2019s say a travel website, can essentially ask a question, \u201cWhere can I find a Sunday brunch that\u2019s open after 11, and kid friendly?\u201d And through our API, we can return with the same level of personalization off of Yelp. I think that just expands the number of consumers we can help simultaneously.\n\nFor Yelp to differentiate in AI, you don\u2019t need to have the most incredible AI team or create breakthrough core technologies, it\u2019s more about this unique data set. Is that right?\n\nI think it\u2019s both. Our core value proposition is content. Our consumers are just awesome, they write such deep reviews that are so nuanced. And that\u2019s what keeps folks coming back.\n\nFor finding snippets and stuff like that, we can use a lot of off-the-shelf models, because the core problem we\u2019re trying to solve is simply natural language processing.\n\nI think the place where our technology shines is in areas like Yelp Assistant. In 2016, Yelp introduced \u201crequest a quote,\u201d and that allowed consumers to quickly get a variety of quotes from a variety of service providers. We\u2019ve expanded that over time, we added Yelp Guaranteed, all of that has helped to reduce the friction and drive quicker and deeper connections.\n\nThen last year, we updated our whole back-end AI model to use neural networks; that really helped drive precise matches. So then the next problem to solve was, what if you don\u2019t know which [type of pro] you\u2019re looking for? If you see a wet spot in your wall and you don\u2019t know if your roof is leaking, your gutter\u2019s leaking, or if you have a broken pipe.\n\nWe felt like the next step of this was: Just tell us what your problem is, we\u2019ll help you narrow down, we\u2019ll help you find the pro.\n\nAnd I think that\u2019s where we really push the technology, because general models will give you general responses. What we have, and what we\u2019ve built up over time, is a very deep understanding of what pros do, and what types of jobs they don\u2019t actually do, too.\n\nYou also mentioned the importance of protecting the authenticity of user reviews. As you imagine AI, including generative AI content, becoming a more central part of the Yelp experience, how do you protect that authenticity?\n\nFirst, just to say upfront, using Gen AI to write reviews is a violation of our policies. We work very hard to keep those types of reviews out. We have been investing in pretty sophisticated solutions for a long time to validate the authenticity of reviews, and whether it\u2019s bots, or solicited reviews, this was something that we were thinking about from day zero. And so we are prepared for it, we\u2019ve deployed a bunch of solutions, all types of technology. It\u2019s a constant game of keeping ahead of what bad actors might use; we will continue to draw a hard line.\n\nI imagine that one of the incentives for writing a thoughtful review is that I\u2019m hoping somebody will actually read it, not that it\u2019s just going to be fed into an AI model that spits out a summary. How do you make sure there\u2019s still an incentive for users to write good reviews?\n\nOverall, I think Gen AI will be very helpful for both the quantity and the quality of the reviews. The more connections you get between consumers and businesses, the more shots you have at writing reviews.\n\nOn the review writing piece, there are a couple of things that are very helpful. First is, we are now using AI \u2014 and specifically Gen AI \u2014 to give you gentle nudges and prompts to help you remember what made your experience special. So as you\u2019re typing, if you talk about the ambience, it will give you a little tag that says, \u201cYou\u2019ve checked off the ambience, now you can talk about the service, you can talk about the food, etc.\u201d We\u2019ve rolled this out for restaurants, we\u2019re rolling this out for other categories. That really helps with the depth and the quality of the reviews.\n\nThe second piece is photos. Now your photo surfaces into places which are new. We have a brand-new home feed, which is very visual, it\u2019s very photo- and very video-heavy. And we talked about [photos in search].\n\nThen to answer your specific question: We put our reviews front and center. So instead of telling you what the answer is, we have gotten to the source faster. We\u2019re taking you to the reviewer and to the review. We\u2019re making it easier for you to find the exact user who had the same experience.\n\nSo my hypothesis is that it\u2019s actually an even bigger motivation [now]. Because in the past, if you\u2019re at a restaurant that has 200 reviews, and you\u2019re the 200th, [you might think,] \u201cCan I really add value?\u201d But now, knowing that I can say, \u201cThey brought my 18-month-old a highchair and they gave her something to color with,\u201d that\u2019s new information. If somebody with an 18-month-old is looking for it, they\u2019ll find my specific review.\n\nAnd now we actually close the loop. So if you write a review, we will actually send you feedback and say, \u201cSince you wrote that review, this business has got 200 more views\u201d or \u201cseven people found it helpful,\u201d etc.\n\nSo we\u2019ve been talking about how AI has already changed the Yelp experience. Is there anything you can say about what you\u2019d like to see happen with AI and Yelp in the future?\n\nWe have pictures and we have video and we have descriptions, and we\u2019re using AI to stitch all of those together and give you that whole 360 experience of what it\u2019s like to actually be there. I\u2019m very, very excited about that because that\u2019s not a single person\u2019s point of view, but it\u2019s all user-generated content. We\u2019re not artificially generating anything, so it feels authentic.\n\nOn the business side, it\u2019s not Gen AI, but we have a ton of AI, and a really big team focused on matching. Pros and businesses have told us we have high intent consumers, and they want those high intent leads. So we spend a lot of time just focusing on how do we get a better match? How do we match the right pro with the right consumer at the right time?\n\nThe second piece [for businesses] is: we announced smart budgets. We found that a lot of new businesses, they\u2019re really good at what they do, but they don\u2019t know how to run a business, it\u2019s day one for them. So we have this AI tool that takes a bunch of information about where they\u2019re located, what competitors are spending, what\u2019s the size of their business, what the number of leads we think they would need to grow, and every business gets its own recommendation for how much money we think they should spend.\n\n[Back on the consumer side,] AI is getting good enough that you can just show me a picture or take a video [and we can match you with the right pro or business]. We\u2019re not there yet, but it\u2019s quite logical to see that\u2019s the path. And then on the pro side, there\u2019s a lot we can do to help them qualify leads, whether it\u2019s asking questions on their behalf, whether it\u2019s making sure that they never miss a call by having an assistant for them, by guiding them on how users might prefer their response, whether it\u2019s structured or unstructured.\n\nStepping back from AI, the local discovery landscape has changed dramatically in the last few years. I have friends who now say, \u201cLet\u2019s go try this dish, let\u2019s go to this restaurant because I heard about it on TikTok.\u201d And obviously, search is changing. So as all this is happening, what do you see as Yelp\u2019s role and differentiator?\n\nFirst, we already talked about the breadth and depth and volume of our reviews. At Yelp, you get the wisdom of the crowd, you get a collective sense of what a restaurant is, and you\u2019re able to very quickly combine different points of view and choose which one is closest to your own. Versus with the influencer model, you could trust an individual, that\u2019s why you follow them, but it\u2019s a single individual.\n\nI think the two less obvious [differences] are, one is just the breadth of categories that we have on Yelp. It\u2019s quite easy to follow influencers for restaurants and maybe home decor and stuff like that. But as you think about plumbing and roofing and accountants and lawyers and doctors, the breadth of coverage that we have is very, very useful.\n\nThen the last one is really the balance of the views. Most of the time on social media, people will share if they had a phenomenally good experience, or a phenomenally bad experience. There was a study done on the review distribution of various platforms, and Yelp has the most even distribution between one, two, three, four and five stars. If you really want that balanced view, as opposed to the polarizing one star or five stars, that\u2019s where Yelp can make a difference.",
        "url": "https://techcrunch.com/2024/08/04/yelps-chief-product-officer-talks-ai-and-authenticity/",
        "category": 1,
        "summary": "And then on the pro side, there\u2019s a lot we can do to help them qualify leads, whether it\u2019s asking questions on their behalf, whether it\u2019s making sure that they never miss a call by having an assistant for them, by guiding them on how users might prefer their response, whether it\u2019s structured or unstructured. Because in the past, if you\u2019re at a restaurant that has 200 reviews, and you\u2019re the 200th, [you might think,] \u201cCan I really add value?\u201d But now, knowing that I can say, \u201cThey brought my 18-month-old a highchair and they gave her something to color with,\u201d that\u2019s new information. The second step is, once we\u2019ve helped them define that intent, and they know exactly what they\u2019re looking for, we present them with a lot of different results, and they need to pick either a single business or like a couple of businesses that they want to connect with."
    },
    {
        "title": "Warren Buffet\u2019s Berkshire Hathaway sells half its Apple stock",
        "text": "Warren Buffett\u2019s Berkshire Hathaway cut its Apple holding by around half, to $84.2 billion, according to an SEC filing.\n\nWhile Apple remains the firm\u2019s largest stock holding by far, Buffett had already reduced its stake by 13 percent earlier this year, hinting that he didn\u2019t mind selling \u201ca little Apple\u201d for tax reasons.\n\nBerkshire Hathaway made huge profits on the sale, according to calculations by The Financial Times; Buffett had largely avoided tech investments before beginning to buy Apple stock in 2016. This could be a sign that Buffett has lost some faith in Apple, or he may just be in a selling mood \u2014 he\u2019s been selling off other stocks as well, for example $3.8 billion of shares in Bank of America.\n\nThe filing comes after Apple announced its third quarter earnings on Thursday, with iPad growth offering a bright spot as global iPhone sales declined for the second consecutive quarter, due in part to competition in China from companies like Huawei.\n\nCEO Tim Cook said the company has been diverting resources to prepare to launch Apple Intelligence \u2014 a suite of AI features that it plans to release in the fall.",
        "url": "https://techcrunch.com/2024/08/03/warren-buffets-berkshire-hathaway-sells-half-its-apple-stock/",
        "category": 4,
        "summary": "Berkshire Hathaway made huge profits on the sale, according to calculations by The Financial Times; Buffett had largely avoided tech investments before beginning to buy Apple stock in 2016. While Apple remains the firm\u2019s largest stock holding by far, Buffett had already reduced its stake by 13 percent earlier this year, hinting that he didn\u2019t mind selling \u201ca little Apple\u201d for tax reasons. The filing comes after Apple announced its third quarter earnings on Thursday, with iPad growth offering a bright spot as global iPhone sales declined for the second consecutive quarter, due in part to competition in China from companies like Huawei."
    },
    {
        "title": "When a big company comes after a hot startup, it\u2019s not a slam dunk decision to sell",
        "text": "Rumors first surfaced last month that Google was going after cloud security startup Wiz and a $23 billion offer was on the table, the most lucrative offer ever made for a startup. Before the deal eventually died, there would have been a lot of moving parts, and it\u2019s fair to ask: What are the mechanics when a big deal like this is set in motion, and how does a startup decide to sell or not?\n\nWe spoke to Jyoti Bansal, who is founder and CEO at Harness, a developer tools startup that has raised approximately $575 million and has made a bunch of small acquisitions along the way. While Bansal doesn\u2019t have direct knowledge of the Google-Wiz negotiation process, he experienced being courted by a large company when Cisco came after his previous startup AppDynamics. Cisco ended up buying the company just a few days before it was set to go public in 2017 for $3.7 billion.\n\nHe says there are three factors in play when it comes to deals like this. The first is how serious the offer is and whether it\u2019s concrete or just exploratory. For a private company like Wiz, chances are it\u2019s going to be exploratory at first because there is not a lot of public information available on its financials as there would be with a public company.\n\nBansal says when he went through the AppDynamics negotiations with Cisco, he had recently filed an S-1 with the SEC and all his financial cards were already on the table. \u201cSo for an acquirer, acquiring a private company that\u2019s on the IPO path and a few days from an IPO is essentially no different than acquiring a public company,\u201d he said. \u201cAll the information they need is out there, and they don\u2019t have to worry about if they\u2019re missing some information, or the information is not clean, audited or scrutinized.\u201d\n\nOnce you determine how serious the company is, you have to explore whether this would be a good match. \u201cThe second factor in any kind of courtship that happens is what\u2019s the reason for the combined company? Is that interesting? Is that exciting?\u201d You also have to take into consideration what happens to your employees and your products: Will some employees lose their jobs? Will products be deprecated or canceled?\n\nFinally, and perhaps most importantly, you have to scrutinize the economics of the deal to see whether they make sense and whether they are a good value for shareholders. From Wiz\u2019s perspective, it was a huge offer (assuming the rumored amount was accurate) that was 46 times its current ARR and 23 times its projected 2025 ARR. Yet Wiz thought it would be better off remaining a private company.\n\nIn Bansal\u2019s case, when Cisco came a courtin\u2019, he was in the middle of his company\u2019s IPO road show. It was days before the company was going public, but even with the information out there for Cisco to analyze, there were discussions, and it wasn\u2019t easy for Bansal to give up his baby, even if the price eventually was right.\n\nThe two companies knew that there was a strict deadline in front of them. Once the IPO happened, that would be that. The negotiations ended up involving three offers, and when it was over, Cisco got its company. \u201cUltimately, it comes down to what\u2019s best for all the shareholders in terms of risk and reward. It\u2019s all about what\u2019s the risk of being independent versus the reward of selling,\u201d Bansal said.\n\nThe first offer was in line with IPO value and was an easy no. The second one was better, but after discussing it with the board, Bansal said no again. \u201cThen they came back with a third offer, and in the third offer, it made sense from a risk versus reward for our shareholders to sell the company.\u201d And sell they did in the range 2.5 to 3 times the IPO valuation.\n\nIt\u2019s easy to think that with billions of dollars at stake, it would be an easy decision to sell, but it really wasn\u2019t. \u201cIt was not an easy decision from our side. It sounds like [$3.7 billion] is a very easy decision.\u201d But he says you have to poll your investors, your fellow executives, your board members \u2014 and they all have different interests, and you are trying to come to the right decision for everyone involved.\n\nWiz thought it was better staying independent. For AppDynamics, with the pressure of the IPO deadline looming and a good offer on the table, the company finally went for it. \u201cSo for us to independently grow into that valuation of two and a half, three times more than our IPO valuation would have taken us at least three years of good execution to grow into it,\u201d he said. \u201cAnd there were a lot of unknowns, a lot of risk for the company like what happens in the next three years.\u201d\n\nBut that doesn\u2019t mean he doesn\u2019t have some regrets in spite of making more than 300 of his employees millionaires with the transaction and personal wealth for himself. When he looks back at the timing of the announcement, he realizes that it\u2019s entirely possible he could have made that much money and more.\n\n\u201cI always wonder what AppDynamics could have become if we had gone through with the IPO. There are a lot of unknowns, and hindsight is 20/20, but if you look back, we sold the company in 2017, the few years after that sale, after 2017, were some of the best boom years in the tech industry, especially for B2B SaaS,\u201d he said. In the end, he might have made more, but instead he started Harness, and he\u2019s happy building a second company.\n\nIt\u2019s important to note that Wiz\u2019s offer remains mired in rumor, so it may or may not be that much money. But if it was, the founders could also have regrets if Wiz doesn\u2019t grow into the value it could have had if it had taken the big money money and run.",
        "url": "https://techcrunch.com/2024/08/03/when-a-big-company-comes-after-a-hot-startup-its-not-a-slam-dunk-decision-to-sell/",
        "category": 3,
        "summary": "\u201cAnd there were a lot of unknowns, a lot of risk for the company like what happens in the next three years.\u201d\n\nBut that doesn\u2019t mean he doesn\u2019t have some regrets in spite of making more than 300 of his employees millionaires with the transaction and personal wealth for himself. We spoke to Jyoti Bansal, who is founder and CEO at Harness, a developer tools startup that has raised approximately $575 million and has made a bunch of small acquisitions along the way. It sounds like [$3.7 billion] is a very easy decision.\u201d But he says you have to poll your investors, your fellow executives, your board members \u2014 and they all have different interests, and you are trying to come to the right decision for everyone involved."
    },
    {
        "title": "Trade My Spin is building a business around used Peloton equipment",
        "text": "Peloton had one of the most turbulent half decades in tech. The home fitness firm experienced some of the industry\u2019s highest highs and lowest lows in dizzying succession. It\u2019s the story of buzzy startup that became the target of a cult-like following among influencers and fitness fanatics. A global pandemic shot the brand to unknown heights, before over-investment, recalls, mass layoffs and executive departures brought the brand crashing back down to earth.\n\nAs of mid-2024, Peloton is down, but not out. The company avoided a major liquidity crunch with a massive debt refinance at the end of May. That marked the end of a month that also saw a 15% staff reduction and the exit of CEO Barry McCarthy a little over two years after he took over for founder John Foley.\n\nPeloton\u2019s high-profile roller-coaster ride has had wide-ranging knock-on effects. Excitement peaked at the height of the pandemic, but once the world began to reopen, sales cratered. Some who were hooked at the height of social distancing have remained loyal to the brand. Plenty of others, however, lost that connection. A degree of attrition is inevitable with any fitness offering, but those figures were unquestionably exacerbated by the reopening of gyms and other exercise alternatives.\n\nThe result is that a lot of unused pieces of pricey fitness equipment are occupying space in homes across America; they\u2019re now \u201cclothing racks,\u201d as a colleague recently referred to her Peloton bike. A quick search on Facebook Marketplace reveals row after row of the stationary bike, routinely listed around $300 to $500 \u2014 a fraction of the cost of a new model (around $1,500). For many once enthusiastic owners, the hardware has become a nuisance.\n\nBut for a pair of East Coast entrepreneurs, it\u2019s an opportunity.\n\nThe Trade My Spin origin story starts modestly, when now CEO Ari Kimmelfeld began looking for a good deal on a used Peleton bike. As good as the Facebook and Craigslist prices were, relative to buying new from the manufacturer, the experience had its own issues.\n\n\u201cThere was a massive inconvenience, buying something that bulky,\u201d Kimmelfeld, who was then working at Ernst & Young\u2019s strategy consulting arm, EY-Parthenon, tells TechCrunch. \u201cFive hundred dollars was a lot of money, and meeting up with a stranger and giving them money for a piece of equipment that you can\u2019t really test out. Also, I live in New York City. Getting something like that from an apartment in Brooklyn to Manhattan is difficult. Also, there\u2019s no warranty.\u201d\n\nLocal logistics\n\nTrade My Spin\n\nKimmelfeld began a pilot for what would become Trade My Spin last year, picking up and selling used Peloton equipment. At its heart, the offering was a DIY logistics play, removing the friction from buying and selling used exercise equipment. It was a conversation with Joey Benjamini that transitioned the one-man operation into a viable business.\n\nBenjamini built contractor-based logistics network for Collectible Classics. His Pennsylvania-based vintage car dealership relies on those contracted drivers to deliver vehicles primarily sold through used car platform, Bring a Trailer.\n\n\u201cLogistics are the most complicated and the most important part of this business \u2014 and the biggest barrier to entry,\u201d Benjamini tells TechCrunch. \u201cWe have a database of 1099 contractors who do deliveries for us. We\u2019re constantly growing that network of drivers who know our company and our process. Once a driver is trained, we dispatch them to pick up bikes. It\u2019s very simple.\u201d\n\nThe new team began work on the Trade My Spin site prior to seeking funding. The page remains simple, even as the inventory has grown to include Peloton\u2019s treadmills, rower and a variety of accessories. A Buy button displays the service\u2019s bustling marketplace, while Sell surfaces a form for the equipment you\u2019re looking to unload. With the site in place, the young company raised a small pre-seed to scale operations.\n\nTalking to Peloton\n\nThe startup has also had multiple conversations with Peloton since officially launching in March. Trade My Spin\u2019s primary goal with the calls is convincing that theirs is a symbiotic \u2013 rather than parasitic \u2013 relationship. At first glance, it\u2019s easy to understand why Peloton might be antagonistic toward the company.\n\nViewed as a zero-sum game, every used bike sold represents a potential lost sale on a new bike. While it\u2019s true that keeping bikes in circulation is a net positive on the sustainability front, Peloton shareholders are no doubt looking at the sales bottom line in hopes of seeing a turnaround.\n\nThe math changes, however, when considering that Peloton\u2019s ultimate goal is being a content company that sells hardware, rather than the other way around. Rather than simply ever used bike sale as a missed sale on a new one, Trade My Spin\u2019s pitch is that every bike removed from circulation is one fewer subscription to Peloton\u2019s content platform of classes.\n\n\u201cEvery bike we take is from someone who is not using that bike,\u201d says Benjamini. \u201cIf someone\u2019s not using the bike, they\u2019re not using the subscription. Peloton is a subscription service. It\u2019s $44 a month. Every time we flip a bike \u2013 and we\u2019ve flipped thousands of bikes \u2013 they make $500 a year.\u201d\n\nThe relationship would no doubt be different had Peloton been more proactive about moving its own used equipment. Ultimately, however, Trade My Spin stepped in to fill that underserved hole in the market.\n\nA new spin\n\nTrade My Spin Founders (L-R): Ari Kimmelfeld, Joey Benjamini\n\nTrade My Spin has pieced together a logistics network capable of offering same or next-day delivery in most major cities in the continental U.S. More-remote locales can take up to five days to complete, which is still faster than the three to five days Peloton takes to process orders.\n\nIn the short term, expansion involves adding more fitness equipment to Trade My Spin\u2019s buying and selling options. Longer term, the company is looking to leverage its growing network of contractors to include the buying and selling of all sorts of unwieldy objects. Trade My Spin will likely require an additional funding round to get there.\n\n\u201cWe want to transition,\u201d Benjamini says. \u201cWe take it from where we\u2019re currently at, and we build it into a large-scale marketplace for bulky items with logistics. That\u2019s the game plan, and no else is going to do that. There\u2019s a barrier to entry and a moat around the business with regards to having the drivers.\u201d",
        "url": "https://techcrunch.com/2024/08/03/trade-my-spin-is-building-a-business-around-used-peloton-equipment/",
        "category": 3,
        "summary": "Every time we flip a bike \u2013 and we\u2019ve flipped thousands of bikes \u2013 they make $500 a year.\u201d\n\nThe relationship would no doubt be different had Peloton been more proactive about moving its own used equipment. The result is that a lot of unused pieces of pricey fitness equipment are occupying space in homes across America; they\u2019re now \u201cclothing racks,\u201d as a colleague recently referred to her Peloton bike. A new spin\n\nTrade My Spin Founders (L-R): Ari Kimmelfeld, Joey Benjamini\n\nTrade My Spin has pieced together a logistics network capable of offering same or next-day delivery in most major cities in the continental U.S. More-remote locales can take up to five days to complete, which is still faster than the three to five days Peloton takes to process orders."
    },
    {
        "title": "Why Bill Gates\u2019 Breakthrough Energy and other investors are scouring universities for founders",
        "text": "The humble garage is so steeped in Silicon Valley lore it\u2019s almost clich\u00e9. Yet that\u2019s exactly how Caleb Boyd and Kevin Bush started Molten Industries: in the garage of the Stanford professor\u2019s on-campus home, where Kevin rented an apartment.\n\nIt had everything they needed: space and, most importantly, power. The two wanted to break methane\u2019s back, so to speak, stripping hydrogen from carbon in a way that didn\u2019t emit atmosphere-warming carbon dioxide.\n\n\u201cWe call it a garage, but it was really just a carport. We plugged into his EV charger, heated up a methane pyrolysis reactor to around 1,000 Celsius and started cracking methane,\u201d Boyd told TechCrunch.\n\nThe professor who lived there \u201cwas super helpful,\u201d Boyd said. \u201cHe would just come by, help us tinker with things and give us advice.\u201d\n\nWhile the garage can still be a great place to do basic research, it\u2019s the next step that poses a problem. Climate tech companies often face a \u201cvalley of death\u201d between lab experiment and investable company.\n\nFounders have typically had to solve that problem themselves. But increasingly, investors are intervening early.\n\nWhen Boyd and Bush were still in the garage, they received a visit from Ashley Grosh, vice president at Breakthrough Energy, the climate tech organization founded by Bill Gates that includes a for-profit venture capital arm and various nonprofit programs. Grosh was representing one such program called Breakthrough Energy Discovery, a new division devoted to early-stage companies, the company told TechCrunch.\n\nDiscovery is an evolution of Breakthrough\u2019s Fellows program, which has been operating since 2021. Discovery identifies promising first-time founders, who are often fresh out of grad school or a postdoc and provides them with grants of up to $500,000, Grosh said. The organization has also created digital resources for common problems and pays for fellows to attend various conferences and meetings.\n\nTo date, the Breakthrough Energy Fellows program has supported 42 companies spanning the gamut of climate tech, from cement and hydrogen to agriculture and fusion power. Altogether, the startups have raised a cumulative $250 million.\n\nGrosh has been overseeing the program since 2020. \u201cThe way we have built a thesis around this is there\u2019s government funding, there are programs like ARPA-E, but they\u2019re not really positioned to pick winners. They can do the science, but they\u2019re not really going to go out and pick winners and double down on a company,\u201d Grosh told TechCrunch.\n\nVenture capital has historically been hesitant to commit to companies that it considers too early. \u201cWe saw what happened in cleantech 1.0,\u201d she said, referring to the first wave of climate-related investments that peaked about 15 years ago. \u201cPeople came in a little too early. Now they\u2019ve moved back and figured out where the strike zone is for venture. But I think what we\u2019re seeing is that there\u2019s still a lot of scientific discovery that needs to be done.\u201d\n\nFor investors who can stomach earlier stages, the advantage is clear: an early window into the founders of tomorrow. These bets tend to be riskier and because the valuations are lower and the checks are modest, the potential returns can be significant.\n\n\u201cThe term we use internally on this topic is proto-companies,\u201d Johanna Wolfson, managing partner at Azolla Ventures, told TechCrunch. \u201cIt\u2019s not a company yet, but if you squint, you can see how it could become a company.\u201d\n\nPlus, in climate tech, moving earlier in the pipeline is about more than just returns. At Azolla Ventures, in particular, finding companies and opportunities that have been overlooked is part of the organization\u2019s mandate.\n\n\u201cAs time passes, and as we keep missing our emissions targets, the crisis deepens,\u201d Wolfson said. \u201cAnd so it heightens the stakes to be able to make sure we\u2019re not leaving anything on the table.\u201d\n\nFunding basic research: Earlier than early\n\nFor Breakthrough Energy, the application process alone has helped it identify some promising areas where basic research still needs to be funded.\n\n\u201cWe started seeing some ideas that were further upstream. We\u2019d say, \u2018Oh, this is interesting. It\u2019s not quite ready to be a fellow, but this research would be really helpful,\u201d Grosh said. \u201cWe started to amass a list of those applications, and we then started funding a few as research grants.\u201d\n\nSoon, Grosh and her team realized they\u2019d need to be more systematic about it. Rather than put out the usual request for proposals, Breakthrough Energy Discovery started convening workshops for researchers spanning the spectrum of experience, from grad students to Nobel Prize winners. At a workshop, they would identify the most promising and impactful opportunities.\n\n\u201cOut of that is where we will start to seed a couple of research projects,\u201d Grosh said.\n\nAzolla Ventures is taking a slightly different tack, bringing on what they call a tech scout fellow.\n\n\u201cWe fund a graduate student to look around for interesting projects and tell us what they\u2019re excited about,\u201d Wolfson said, \u201cbecause graduate students are going to be the ones who are the most plugged in.\u201d\n\nThe program is still young. So far, Azolla is working with grad students at Georgia Tech, a research powerhouse that the firm felt was being overlooked by venture capital.\n\n\u201cIf you had to guess how active the venture community is there, you\u2019d probably guess less than MIT, Harvard, Stanford, or Berkeley just based on geography, unfortunately. Georgia Tech is an example of a place where we\u2019re experimenting, we\u2019re saying there\u2019s probably some undervalued opportunities.\u201d\n\nEven among the usual academic suspects, promising research can fall through the cracks and opportunities can be overlooked. It\u2019s why Collaborative Fund gave Harvard University\u2019s Wyss Institute $15 million to start a lab to research sustainable materials. The goal is to identify promising projects and scientists and sharpen them to the point where they\u2019re ready to raise funds, according to partner Sophie Bakalar.\n\nFrom lab to real business: How founders benefit\n\nCollaborative gets first dibs on the projects, which have ranged from PFAS detection to addressing air-quality issues, and Bakalar is now also a visiting scholar at the Wyss Institute, maintaining a front row seat at the institute. Along the way, Bakalar and Collaborative offer support to help founders bridge the valley of death between lab project and investable startup. Bakalar said she expects the first project to emerge from the lab in the next couple months.\n\nThose sorts of resources can be helpful for the sort of founders that climate tech investors need. Many of them have spent years head down in the lab. Even if they had exposure to the business side through coursework, it\u2019s an entirely different experience from running a startup.\n\n\u201cWe\u2019re still based at a university,\u201d said Mattia Saccoccio, co-founder and CTO of NitroVolt, which makes sustainable ammonia for fertilizer. \u201cWe sometimes miss the exchanges with other companies or companies that like us are working on climate solutions or on deep tech.\u201d\n\nTo counter that isolation, Breakthrough Energy groups its fellows into cohorts and encourages them to stay in touch during their tenure and after, including with the growing alumni network. \u201cWe meet regularly with other founders,\u201d Saccoccio said. \u201cI found that one of the most precious parts of the program.\u201d\n\nFounders also said that access to Breakthrough Energy\u2019s business fellows was particularly helpful. The business fellows are a mix of what VCs might consider advisers or operating partners.\n\n\u201cIf we need help with IP, we can get help there. If we want to get into the ammonia industry, there\u2019s a fellow who has worked with industry and can help us open doors,\u201d said Suzanne Zamany Andersen, co-founder and CEO of NitroVolt.\n\nFor Boyd, the Molten Industries co-founder, the business fellows have been indispensable as his company has evolved. In addition to hydrogen, the company\u2019s process also produces carbon. Initially, \u201cwe were like, we\u2019re just going to bury it or put it in concrete or something,\u201d he said. But as the startup went out to fundraise for a Series A, it started considering alternative uses, eventually settling on making graphite for lithium-ion batteries.\n\n\u201cThe whole Breakthrough Fellows team was super supportive during that, helping us not only think through that and what the implications would be, the pros, the cons, but then also just taking it in stride,\u201d Boyd said. \u201cAs a founder, you want your investors to be partners alongside you and not freak out or be controlling. That\u2019s something the Breakthrough Energy Fellows team does really well.\u201d\n\nTed McKlveen, co-founder and CEO of Verne, which is developing a new way to store hydrogen, agreed. \u201cIt does help get you from zero to one, from nothing to something that you can take to investors and say, \u2018Okay, well, we got it, we\u2019re real.\u2019\u201d\n\nCrossing the chasm from idea to reality is just the first of many that climate tech startups have to traverse. Not all will make it, but as investors and their affiliates step in to fill the gap, their odds are certainly improving.",
        "url": "https://techcrunch.com/2024/08/03/why-bill-gates-breakthrough-energy-and-other-investors-are-scouring-universities-for-founders/",
        "category": 3,
        "summary": "From lab to real business: How founders benefit\n\nCollaborative gets first dibs on the projects, which have ranged from PFAS detection to addressing air-quality issues, and Bakalar is now also a visiting scholar at the Wyss Institute, maintaining a front row seat at the institute. \u201cWe sometimes miss the exchanges with other companies or companies that like us are working on climate solutions or on deep tech.\u201d\n\nTo counter that isolation, Breakthrough Energy groups its fellows into cohorts and encourages them to stay in touch during their tenure and after, including with the growing alumni network. When Boyd and Bush were still in the garage, they received a visit from Ashley Grosh, vice president at Breakthrough Energy, the climate tech organization founded by Bill Gates that includes a for-profit venture capital arm and various nonprofit programs."
    },
    {
        "title": "DSA vs. DMA: How Europe\u2019s twin digital regulations are hitting Big Tech",
        "text": "It\u2019s no accident that the European Union\u2019s Digital Services Act and Digital Markets Act have such similar-sounding names: They were conceived together and, at the end of 2020, proposed in unison as a twin package of digital policy reforms. EU lawmakers had overwhelmingly approved them by mid-2022, and both regimes were fully up and running by early 2024. While each law aims to achieve distinct things, via its own set of differently applied rules, they are best understood as a joint response to Big Tech\u2019s market power.\n\nKey concerns driving lawmakers include a belief that major digital platforms have ignored consumer welfare in their rush to scale fatter profits online. The EU also sees dysfunctional digital markets as undermining the bloc\u2019s competitiveness, thanks to phenomena like network effects and the power of big data to cement a winner-takes-all dynamic.\n\nThe argument is that this is both bad for competition and bad news for consumers who are vulnerable to exploitation when markets tip.\n\nBroadly speaking, the DSA is concerned about rising risks for consumer welfare in an era of growing uptake of digital services. That could be from online distribution of illegal goods (fakes, dangerous stuff) on marketplaces or illegal content (CSAM, terrorism, etc.) on social media. But there are thornier issues, for example, with online disinformation: There may be civic risks (such as election interference), but how such content is handled (whether it\u2019s taken down; made less visible; labeled, etc.) could have implications for fundamental rights like freedom of expression.\n\nThe bloc decided it needed an updated digital framework to tackle all these risks to ensure \u201ca fair and open online platform environment\u201d to underpin the next decades of online growth.\n\nTheir goal with the DSA is absolutely a balancing act, though: The bloc is aiming to drive up content moderation standards in a quasi-hands-off way: by regulating the processes and procedures involved in content-related decisions, rather than defining what can and can\u2019t be put online. The aim is to harmonize and raise standards around governance decision-making processes, including by ensuring comms channels exist with relevant external experts in order to make platforms more responsible in moderating content.\n\nThere\u2019s a further twist: While the DSA\u2019s general rules apply to all sorts of digital apps and services, the strictest requirements \u2014 concerning algorithmic risk assessment and risk mitigation \u2014 only apply to a subset of the largest platforms. So the law has been designed to have the greatest impact on popular platforms, reflecting higher risks of harm flowing from stronger market power.\n\nBut when it comes to impact on Big Tech, the DMA is the real biggie: The mission of the DSA\u2019s sister regulation is to drive market contestability itself. The EU wants this regulation to rebalance power at the very top of the tech industry pyramid. That\u2019s why this regime is so highly targeted, applying to just over a handful of power players.\n\nLaws with teeth big enough to bite Big Tech?\n\nAnother important thing to note is that both laws have sizable teeth. The EU has long had a range of rules that apply to online businesses but no other dedicated digital regulations are this flashy. The DSA contains penalties of up to 6% of global annual turnover for any infringements; the DMA allows for fines of up to 10% (or even 20% for repeat offenses). In some cases, that could mean billions of dollars in fines.\n\nThere\u2019s a growing list of platform giants subject to the DSA\u2019s strictest level of oversight, including major marketplaces like Amazon, Shein and Temu; dominant mobile app stores operated by Apple and Google; social networks giants, including Facebook, Instagram, LinkedIn, TikTok and X (Twitter); and, more recently, a handful of adult content sites that have also been designated as very large online platforms (VLOPs) after crossing the DSA usage threshold of 45 million or more monthly active users in the EU.\n\nThe European Commission directly oversees compliance with DSA rules for VLOPs, centralizing the rulebook\u2019s enforcement on Big Tech inside the EU (versus enforcement of the DSA\u2019s general rules being decentralized to member state-level authorities). This structure underlines that the bloc\u2019s lawmakers are keen to avoid forum-shopping undermining its ability to enforce these rules on Big Tech as has happened with other major digital rulebooks (such as the GDPR).\n\nThe Commission\u2019s early priorities for DSA enforcement fall into a few broad areas: illegal content risks; election security; child protection; and marketplace safety, though its investigations opened to date cover a wider range of issues.\n\nAround 20 companies are in scope of the EU\u2019s enforcement in relation to around two dozen platforms\u2019 compliance with DSA rules for VLOPs. The Commission maintains a list of designated VLOPs and any actions it\u2019s taken on each.\n\nThe DMA is also enforced centrally by the Commission. But this regime applies to far fewer tech giants: Just six companies were originally designated as \u201cgatekeepers.\u201d Back in May, European travel giant Booking was named the seventh.\n\nThe gatekeeper designation kicks in for tech giants with at least 45 million monthly EU end users and 10,000 annual business users. And, in a similar fashion as the DSA, the DMA applies rules to specific types of platforms (a similar number of platforms are in scope of each law, though the respective lists are not identical). The EU has some discretion on whether to designate particular platforms (e.g., Apple\u2019s iMessage being let off the hook; same with Microsoft advertising and Edge browser. On the flip side, Apple\u2019s iPadOS was added to the list of core platform services in April).\n\nRegulated categories for the DMA cover strategic infrastructure where Big Tech platforms may be mediating other businesses\u2019 access to consumers, including operating systems; messaging platforms; ad services; social networks; and various other types of intermediation.\n\nThe structure means there can be overlap of application between the DSA and the DMA. For example, Google Search is both a DSA VLOP (technically it\u2019s a very large online search engine, or VLOSE, to use the correct acronym. But the EU also deploys VLOPSE to refer to both) and a DMA core platform service. The respective mobile apps stores of Apple and Google are also VLOPs and CPS. Such platforms face a double whammy of compliance requirements, though the EU would say this reflects its strategic importance to digital markets.\n\nShooting for a digital market reboot\n\nProblems the EU wants the regulations to address by reshaping behavior in digital markets include reduced consumer choice (i.e., fewer and less innovative services), and higher costs (free services may still have expensive access costs, such as forcing a lack of privacy on users).\n\nOnline business models that do not pay proper attention to consumer welfare, such as ad-funded Big Tech platforms that seek to drive engagement through outrage/polarization, are another target. And making platform power more responsible and accountable is a unifying thread running through both regimes.\n\nThe EU thinks this is necessary to drive trust in online services and power future growth. Without fair and open competition online, the EU\u2019s thesis is that not even startups can ride to the rescue of digital markets. It\u2019s harder for startups to reach as many consumers as the dominant players, which means there\u2019s a low chance that innovation alone will prevent/correct negative effects. Hence the bloc\u2019s decision to lean into regulation.\n\nThe DSA and DMA take a different approach to Big Tech\n\nSo while the DSA aims to leverage the power of transparency to drive accountability on major platforms \u2014 such as by making it obligatory for VLOPs to publish an ad archive and provide data access to independent researchers so they can study the societal impacts of their algorithmic content-sorting \u2014 the DMA tries to have a more upfront effect by laying down rules on how gatekeepers can operate strategic services that are prone to becoming choke points under a winner-takes-all playbook.\n\nThe EU likes to refer to these rules as the DMA\u2019s list of \u201cdos and don\u2019ts,\u201d which boil down to a pretty specific set of operational requirements based on stuff the bloc\u2019s enforcers have seen before, via earlier antitrust enforcements, such as the EU\u2019s multiple cases against Google over the past two decades. It hopes these commandments will nip any repeat bad behaviors in the bud.\n\nOne of the dos on the list, however, is an important order that aims to force CPS to open up to third parties to try to stop gatekeepers using control of their dominant platforms to close down competition.\n\nChanges announced by Apple earlier this year to iOS in the EU, to allow sideloading of apps through web distribution and third-party app stores, are a couple of examples of the DMA forcing more openness than was on offer through Big Tech\u2019s standard playbook.\n\nAnother key DMA interoperability mandate applies to messaging platforms. This \u201cdo\u201d will require Meta \u2014 so far the only designated gatekeeper to have messaging CPS, like WhatsApp and Messenger \u2014 to build infrastructure that will allow smaller platforms to offer ways for people to communicate with people using, say, WhatApp without the person needing to sign up for a WhatsApp account.\n\nThis requirement is in force but has yet to translate into new opportunities for messaging app consumers and competitors, given that the DMA allows for implementation periods for undertaking the necessary technical work. The EU has also allowed Meta more time to build the technical connectors. But policymakers are hoping that over time, the interoperability mandate for messaging will lead to a leveling of the playing field in this area because it would be empowering consumers to choose services based on innovation, rather than market forces.\n\nThe same competitive leveling goal applies across all CPS types the DMA regulates. The bloc\u2019s big hope is that a set of operational commandments applied to the most powerful forces in tech will trigger a wide-ranging market reset that rekindles service innovation and supports consumer welfare. But the success or otherwise of that competitive reset mission remains to seen.\n\nThe regulation only started applying on gatekeepers in February 2024 (versus late August 2023 for the DSA rules on VLOPSEs). The real-world effects of the flagship digital market reform will be playing out for months and years yet.\n\nThat said, if anyone thought the DMA\u2019s fixed \u201cdos and don\u2019ts\u201d would be self-executing as soon as the law began to apply, then the Commission\u2019s swift announcement (in March 2024) of a clutch of investigations for suspected noncompliance should have destroyed that. On certain issues, some gatekeepers are clearly digging in and preparing to fight.\n\nApple: Since March, the EU has been looking into the compliance of Apple\u2019s rules on steering developers in the App Store; the design of choice screens for alternatives to its Safari web browser; and whether its core technology fee (CTF) \u2014 a new charge introduced with the set of business terms that implement DMA entitlements \u2014 meets the bloc\u2019s rules. The law doesn\u2019t include a specific ban on gatekeepers charging fees, but they must abide by FRAND (fair, reasonable and nondiscriminatory) terms.\n\nIn June 2024, the Commission announced preliminary findings on the first two Apple probes and confirmed the formal CTF investigation. Its draft findings at that point included that Apple is breaching the DMA by not letting developers freely inform their users of alternative purchase opportunities. All these probes remain ongoing.\n\nAlphabet/Google: The EU has also been investigating Alphabet\u2019s rules on steering in Google Play, as well as self-preferencing in search results since March.\n\nMeta: Meta\u2019s \u201cpay or consent\u201d model also went under DMA investigation in March. Since November 2023, the tech giant has forced EU users of Facebook and Instagram to agree to being tracked and profiled for ad targeting in order to get free access to its social networks; otherwise, they would have to pay a monthly subscription to use the services. On July 1, the EU issued a preliminary finding that this binary choice Meta imposes breaches the DMA. The investigation is ongoing.\n\nDSA: EU investigations on VLOPSE\n\nOn the DSA side, the Commission has been slower to open formal investigations, although it does now have multiple probes open.\n\nBy far its most used enforcement action is a power to ask platforms for more information about how they\u2019re operating regulated services (known as a request for information, or RFI). This underpins the EU\u2019s ability to monitor and assess compliance and build cases where it identifies grievances, explaining why the tool has been used repeatedly over the past 11 months since the compliance deadline for VLOPSEs.\n\nX (Twitter): The first DSA investigation the EU opened was on X, back in December 2023. The formal proceeding concerned a raft of issues including suspected breaches of rules related to risk management; content moderation; dark patterns; advertising transparency; and data access for researchers. In July 2024 the Commission issued its first DSA preliminary findings, which concern aspects of its investigation of X.\n\nOne of the preliminary findings is that the design of the blue check on X is an illegal dark pattern under the DSA. A second preliminary finding is that X\u2019s ad repository does not comply with the regulatory standard. A third preliminary finding is that X has failed to provide the requisite data access for researchers. X was given a chance to respond.\n\nOther areas the EU continues investigating X for relate to the spread of illegal content; its handling of disinformation; and its Community Notes content moderation feature. So far it has yet to reach a preliminary view.\n\nTikTok: In February 2024 the EU announced a DSA probe of video social network TikTok it said is focused on protection of minors; advertising transparency; data access for researchers; and the risk management of addictive design and harmful content.\n\nAliExpress: In March 2024 the Commission opened its first DSA probe of an ecommerce marketplace, targeting AliExpress over suspected failings of risk management and mitigation; content moderation; its internal complaint-handling mechanisms; the transparency of advertising and recommender systems; and the traceability of traders and to data access for researchers.\n\nMeta: In April 2024 the EU took aim at Meta\u2019s social networks Facebook and Instagram, opening a formal DSA investigation for suspected breaches related to election integrity rules. Specifically it said it\u2019s concerned about the tech giant\u2019s moderation of political ads. It\u2019s also concerned about Meta\u2019s policies for moderating non-paid political content, suggesting they are opaque and overly restrictive.\n\nThe EU also said it would look into policies related to enabling outsiders to monitor elections. A further grievance it\u2019s probing relates to Meta\u2019s processes for letting users flag illegal content. EU enforcers are concerned these are not easy enough.\n\nPenalties and impacts\n\nSo far, no DSA or DMA investigations have been formally concluded by the Commission, meaning that no penalties have been issued yet. But that\u2019s likely to change as probes conclude in the coming months and years.\n\nAs with all EU regulations, it\u2019s worth emphasizing that enforcement is a spectrum, not an event. Just the fact of oversight can apply pressure and lead to operational changes, ahead of any formal finding of noncompliance. Assessing impact based on headline penalties and sanctions alone would be a very crude way of trying to understand a regulation\u2019s effect.\n\nNotably, there have already been some big changes to how major platforms are operating in the EU \u2014 such as Apple being forced to allow sideloading or open up its Safari browser, or Google having to ask users to link data for ad targeting across CPS, to name a few early DMA-related developments.\n\nBut it\u2019s also true that some major business model reforms have yet to happen.\n\nNotably, Apple has so far stuck to its fee-based model for the App Store (by creating a new fee, the CTF, in a bid to work around the effect of being forced to open its App Store); and Meta has sought to cling to a privacy-hostile mode by forcing users to choose between being tracked or paying to use the historically free services, despite blowback from enforcers of multiple EU rules.\n\nOn the DSA side, the EU has been quick to trumpet a number of developments as early wins, such as crediting the DSA with helping drive improvements in platforms\u2019 responsiveness to election security concerns ahead of the EU elections (also following its publication of detailed guidance and pre-election stress-testing exercises), or highlighting LinkedIn\u2019s decision to disable certain types of ads data linking following a DSA complaint. Another example the EU points to in order to illustrate early impact is TikTok pulling functionality from the TikTok Lite app in the region over addiction concerns.\n\nDMA effects the Commission may be less keen to own are claims by Apple and Meta that they\u2019re delaying the launch of certain AI features in the EU, as they\u2019re unsure how the DMA applies.",
        "url": "https://techcrunch.com/2024/08/03/dsa-vs-dma-how-europes-twin-digital-regulations-are-hitting-big-tech/",
        "category": 2,
        "summary": "Notably, Apple has so far stuck to its fee-based model for the App Store (by creating a new fee, the CTF, in a bid to work around the effect of being forced to open its App Store); and Meta has sought to cling to a privacy-hostile mode by forcing users to choose between being tracked or paying to use the historically free services, despite blowback from enforcers of multiple EU rules. The DSA and DMA take a different approach to Big Tech\n\nSo while the DSA aims to leverage the power of transparency to drive accountability on major platforms \u2014 such as by making it obligatory for VLOPs to publish an ad archive and provide data access to independent researchers so they can study the societal impacts of their algorithmic content-sorting \u2014 the DMA tries to have a more upfront effect by laying down rules on how gatekeepers can operate strategic services that are prone to becoming choke points under a winner-takes-all playbook. There\u2019s a growing list of platform giants subject to the DSA\u2019s strictest level of oversight, including major marketplaces like Amazon, Shein and Temu; dominant mobile app stores operated by Apple and Google; social networks giants, including Facebook, Instagram, LinkedIn, TikTok and X (Twitter); and, more recently, a handful of adult content sites that have also been designated as very large online platforms (VLOPs) after crossing the DSA usage threshold of 45 million or more monthly active users in the EU."
    },
    {
        "title": "How the theft of 40M UK voter register records was entirely preventable",
        "text": "A cyberattack on the U.K. Electoral Commission that resulted in the data breach of voter register records on 40 million people was entirely preventable had the organization used basic security measures, according to the findings from a damning report by the U.K.\u2019s data protection watchdog published this week.\n\nThe report published by the U.K.\u2019s Information Commissioner\u2019s Office on Monday blamed the Electoral Commission, which maintains copies of the U.K. register of citizens eligible to vote in elections, for a series of security failings that led to the mass theft of voter information beginning August 2021.\n\nThe Electoral Commission did not discover the compromise of its systems until more than a year later in October 2022 and took until August 2023 to publicly disclose the year-long data breach.\n\nThe Commission said at the time of public disclosure that the hackers broke into servers containing its email and stole, among other things, copies of the U.K. electoral registers. Those registers store information on voters who registered between 2014 and 2022, and include names, postal addresses, phone numbers and nonpublic voter information.\n\nThe U.K. government later attributed the intrusion to China, with senior officials warning that the stolen data could be used for \u201clarge-scale espionage and transnational repression of perceived dissidents and critics in the U.K.\u201d China denied involvement in the breach.\n\nThe ICO issued its formal rebuke of the Electoral Commission on Monday for violating U.K. data protection laws, adding: \u201cIf the Electoral Commission had taken basic steps to protect its systems, such as effective security patching and password management, it is highly likely that this data breach would not have happened.\u201d\n\nFor its part, the Electoral Commission conceded in a brief statement following the report\u2019s publication that \u201csufficient protections were not in place to prevent the cyber-attack on the Commission.\u201d\n\nUntil the ICO\u2019s report, it wasn\u2019t clear exactly what led to the compromise of tens of millions of U.K. voters\u2019 information \u2014 or what could have been done differently.\n\nNow we know that the ICO specifically blamed the Commission for not patching \u201cknown software vulnerabilities\u201d in its email server, which was the initial point of intrusion for the hackers who made off with reams of voter data. The report also confirms a detail as reported by TechCrunch in 2023 that the Commission\u2019s email was a self-hosted Microsoft Exchange server.\n\nIn its report, the ICO confirmed that at least two groups of malicious hackers broke into the Commission\u2019s self-hosted Exchange server during 2021 and 2022 using a chain of three vulnerabilities collectively referred to as ProxyShell, which allowed the hackers to break in, take control, and plant malicious code on the server.\n\nMicrosoft released patches for ProxyShell several months earlier in April and May 2021, but the Commission had not installed them.\n\nBy August 2021, U.S. cybersecurity agency CISA began sounding the alarm that malicious hackers were actively exploiting ProxyShell, at which point any organization that had an effective security patching process in place had already rolled out fixes months ago and were already protected. The Electoral Commission was not one of those organizations.\n\n\u201cThe Electoral Commission did not have an appropriate patching regime in place at the time of the incident,\u201d read the ICO\u2019s report. \u201cThis failing is a basic measure.\u201d\n\nAmong the other notable security issues discovered during the ICO\u2019s investigation, the Electoral Commission allowed passwords that were \u201chighly susceptible\u201d to have been guessed, and that the Commission confirmed it was \u201caware\u201d that parts of its infrastructure were out of date.\n\nICO deputy commissioner Stephen Bonner said in a statement on the ICO\u2019s report and reprimand: \u201cIf the Electoral Commission had taken basic steps to protect its systems, such as effective security patching and password management, it is highly likely that this data breach would not have happened.\u201d\n\nWhy didn\u2019t the ICO fine the Electoral Commission?\n\nAn entirely preventable cyberattack that exposed the personal data of 40 million U.K. voters might sound like a serious enough breach for the Electoral Commission to be penalized with a fine, not just a reprimand. Yet, the ICO has only issued a public dressing-down for the sloppy security.\n\nPublic sector bodies have faced penalties for breaking data protection rules in the past. But in June 2022 under the prior conservative government, the ICO announced it would trial a revised approach to enforcement on public bodies.\n\nThe regulator said the policy change meant public authorities would be unlikely to see large fines imposed for breaches for the next two years, even as the ICO suggested incidents would still be thoroughly investigated. But the sector was told to expect increased use of reprimands and other enforcement powers, rather than fines.\n\nIn an open letter explaining the move at the time, information commissioner John Edwards wrote: \u201cI am not convinced large fines on their own are as effective a deterrent within the public sector. They do not impact shareholders or individual directors in the same way as they do in the private sector but come directly from the budget for the provision of services. The impact of a public sector fine is also often visited upon the victims of the breach, in the form of reduced budgets for vital services, not the perpetrators. In effect, people affected by a breach get punished twice.\u201d\n\nAt a glance, it might look like the Electoral Commission had the good fortune to discover its breach within the ICO\u2019s two-year trial of a softer approach to sectoral enforcement.\n\nIn concert with the ICO saying it would test fewer sanctions for public sector data breaches, Edwards said the regulator would adopt a more proactive workflow of outreach to senior leaders at public authorities to try to raise standards and drive data protection compliance across government bodies through a harm-prevention approach.\n\nHowever, when Edwards revealed the plan to test combining softer enforcement with proactive outreach, he conceded it would require effort at both ends, writing: \u201c[W]e cannot do this on our own. There must be accountability to deliver these improvements on all sides.\u201d\n\nThe Electoral Commission breach might therefore raise wider questions over the success of the ICO\u2019s trial, including whether public sector authorities have held up their side of a bargain that was supposed to justify the softer enforcement.\n\nCertainly it does not appear that the Electoral Commission was adequately proactive in assessing breach risks in the early months of the ICO trial \u2014 that is, before it discovered the intrusion in October 2022. The ICO\u2019s reprimand dubbing the Commission\u2019s failure to patch known software flaw as a \u201cbasic measure,\u201d for example, sounds like the definition of an avoidable data breach the regulator had said it wanted its public sector policy shift to purge.\n\nIn this case, however, the ICO claims it did not apply the softer public sector enforcement policy in this case.\n\nResponding to questions about why it didn\u2019t impose a penalty on the Electoral Commission, ICO spokeswoman Lucy Milburn told TechCrunch: \u201cFollowing a thorough investigation, a fine was not considered for this case. Despite the number of people impacted, the personal data involved was limited to primarily names and addresses contained in the Electoral Register. Our investigation did not find any evidence that personal data was misused, or that any direct harm has been caused by this breach.\u201d\n\n\u201cThe Electoral Commission has now taken the necessary steps we would expect to improve its security in the aftermath, including implementing a plan to modernise their infrastructure, as well as password policy controls and multi-factor authentication for all users,\u201d the spokesperson added.\n\nAs the regulator tells it, no fine was issued because no data was misused, or rather, the ICO didn\u2019t find any evidence of misuse. Merely exposing the information of 40 million voters did not meet the ICO\u2019s bar.\n\nOne might wonder how much of the regulator\u2019s investigation was focused on figuring out how voter information might have been misused?\n\nReturning to the ICO\u2019s public sector enforcement trial in late June, as the experiment approached the two-year mark, the regulator issued a statement saying it would review the policy before making a decision on the future of its sectoral approach in the fall.\n\nWhether the policy sticks or there\u2019s a shift to fewer reprimands and more fines for public sector data breaches remains to be seen. Regardless, the Electoral Commission breach case shows the ICO is reluctant to sanction the public sector \u2014 unless exposing people\u2019s data can be linked to demonstrable harm.\n\nIt\u2019s not clear how a regulatory approach that\u2019s lax on deterrence by design will help drive up data protection standards across government.",
        "url": "https://techcrunch.com/2024/08/02/how-the-theft-of-40-million-uk-voter-register-records-was-entirely-preventable/",
        "category": 2,
        "summary": "In concert with the ICO saying it would test fewer sanctions for public sector data breaches, Edwards said the regulator would adopt a more proactive workflow of outreach to senior leaders at public authorities to try to raise standards and drive data protection compliance across government bodies through a harm-prevention approach. Our investigation did not find any evidence that personal data was misused, or that any direct harm has been caused by this breach.\u201d\n\n\u201cThe Electoral Commission has now taken the necessary steps we would expect to improve its security in the aftermath, including implementing a plan to modernise their infrastructure, as well as password policy controls and multi-factor authentication for all users,\u201d the spokesperson added. The ICO issued its formal rebuke of the Electoral Commission on Monday for violating U.K. data protection laws, adding: \u201cIf the Electoral Commission had taken basic steps to protect its systems, such as effective security patching and password management, it is highly likely that this data breach would not have happened.\u201d\n\nFor its part, the Electoral Commission conceded in a brief statement following the report\u2019s publication that \u201csufficient protections were not in place to prevent the cyber-attack on the Commission.\u201d\n\nUntil the ICO\u2019s report, it wasn\u2019t clear exactly what led to the compromise of tens of millions of U.K. voters\u2019 information \u2014 or what could have been done differently."
    },
    {
        "title": "Self-driving truck startup Aurora Innovation raises $483M in share sale ahead of commercial launch",
        "text": "Self-driving technology company Aurora Innovation was hoping to raise hundreds of millions in additional capital as it races toward a driverless commercial launch by the end of 2024. The company, which had arranged to sell up to $420 million worth of shares, exceeded its goal and raised $483 million.\n\nThe newly raised funds come a little over a year since Aurora completed a capital raise of $820 million from a public and concurrent private offering of its stock.\n\n\u201cThis raise is a testament to investors\u2019 confidence in Aurora\u2019s ability to be a company for the long term, prompted by a recent Analyst Day where investors experienced driverless truck rides, and recent milestones that underscore the strength of our partner ecosystem to deploy at scale,\u201d company spokesperson Rachel Chibidakis told TechCrunch in an email.\n\nAurora made its public debut through a special purpose acquisition merger in 2021, and its stock has traded as high as $13.12 on opening day. Aurora shares closed Friday at $3.84. Shares rose more than 2% in after-hours trading.\n\nAurora is pursuing a driver-as-a-service model, wherein carriers purchase trucks with the Aurora Driver tech on board and then offer their services via those trucks to shippers. But the company is planning to go to market as a carrier, offering up to 20 autonomous Paccar and Volvo trucks to shippers at the end of this year.\n\nAurora first revealed Thursday plans to sell up to $420 million worth of Class A common stock to underwriters Goldman Sachs, Allen & Company and Morgan Stanley, according to an SEC filing. The Thursday agreement came a day after Aurora filed a prospectus offering to sell $350 million worth of shares. Someone familiar with the matter told TechCrunch that due to strong investor demand, the offering had been upsized to $420 million.\n\nAurora expected the net proceeds from the sale to bring in about $405 million, or around $466 million \u201cif the underwriters exercise their option to purchase additional shares in full,\u201d after deducting the usual discounts, commissions and offering expenses, per an updated filing. The deal closed Friday afternoon pushed the raise to $483 million.\n\nAurora did not respond Thursday to questions about how it intends to use the net proceeds. The Thursday filing provided few hints, stating vaguely that the company will put the money toward \u201cworking capital and other general corporate purposes.\u201d The company also wrote in its filing that it\u2019ll first invest the proceeds from this offering into \u201cshort and long-term investment grade instruments, certificates of deposit or guaranteed obligations.\u201d\n\nAurora provided more detail after the deal closed Friday.\n\n\u201cThis opportunistic raise gives us runway well into 2026, putting us on the path to deploy driverless trucks at scale and become a cash flow positive company, which we expect in 2028,\u201d said Chibidakis, adding that as the company approaches its planned commercial launch that enthusiasm is building. \u201cOur continued momentum and more favorable market conditions made this an opportune time to raise additional capital.\u201d\n\nThe bid for more funds comes as Aurora reports its second-quarter results. As of June 30, 2024, Aurora had $402 million in cash and cash equivalents and $618 million in short-term investments. Not including the proceeds from its offering, the company expects this to be enough to fund operations into the fourth quarter of 2025.\n\nIn Q2 2024, Aurora spent $198 million, which is a direct loss because the startup isn\u2019t yet pulling in any revenue.\n\nThe company is slated to start its commercial service later this year on the Uber Freight network. In June, the two companies announced a multi-year collaboration that will see Aurora\u2019s autonomous driving technology offered on the Uber Freight network through 2030.\n\nUpdate: This story was updated to reflect that Aurora\u2019s $618 million in short-term investments are essentially liquid.\n\nThis story was originally published August 1, 2024 at 9:34 am PT. It has been updated to include estimated proceeds per an additional SEC filing. The article was updated Friday at 4:31 pm PT after Aurora had announced the final raise amount.",
        "url": "https://techcrunch.com/2024/08/02/self-driving-truck-startup-aurora-innovation-raises-483m-commercial-launch/",
        "category": 3,
        "summary": "\u201cThis opportunistic raise gives us runway well into 2026, putting us on the path to deploy driverless trucks at scale and become a cash flow positive company, which we expect in 2028,\u201d said Chibidakis, adding that as the company approaches its planned commercial launch that enthusiasm is building. \u201cThis raise is a testament to investors\u2019 confidence in Aurora\u2019s ability to be a company for the long term, prompted by a recent Analyst Day where investors experienced driverless truck rides, and recent milestones that underscore the strength of our partner ecosystem to deploy at scale,\u201d company spokesperson Rachel Chibidakis told TechCrunch in an email. The Thursday filing provided few hints, stating vaguely that the company will put the money toward \u201cworking capital and other general corporate purposes.\u201d The company also wrote in its filing that it\u2019ll first invest the proceeds from this offering into \u201cshort and long-term investment grade instruments, certificates of deposit or guaranteed obligations.\u201d\n\nAurora provided more detail after the deal closed Friday."
    },
    {
        "title": "FTC and Justice Department sue TikTok over alleged child privacy violations",
        "text": "The U.S. Federal Trade Commission and the Justice Department are suing TikTok and ByteDance, TikTok\u2019s parent company, with violating the Children\u2019s Online Privacy Protection Act (COPPA). The law requires digital platforms to notify and obtain parents\u2019 consent before collecting and using personal data from children under the age of 13.\n\nIn a press release issued Friday, the FTC\u2019s Bureau of Consumer Protection said that TikTok and ByteDance were \u201callegedly aware\u201d of the need to comply with COPPA, yet spent \u201cyears\u201d knowingly allowing millions of children under 13 on their platform. TikTok did so, the FTC alleges, even after settling with the FTC in 2019 over COPPA violations; as a part of that settlement, TikTok agreed to pay $5.7 million and implement steps to prevent kids under 13 from signing up.\n\n\u201cAs of 2020, TikTok had a policy of maintaining accounts of children that it knew were under 13 unless the child made an explicit admission of age and other rigid conditions were met,\u201d the FTC wrote in the press release. \u201cTikTok human reviewers allegedly spent an average of only five to seven seconds reviewing each account to make their determination of whether the account belonged to a child.\u201d\n\nTikTok and ByteDance maintained and used underage users\u2019 data, including data for ads targeting, even after employees raised concerns and TikTok reportedly changed its policy not to require an explicit admission of age, according to the FTC. More damningly, TikTok continued to allow users to sign up with third-party accounts, like Google and Instagram, without verifying that they were over 13, the FTC adds.\n\nThe FTC also found issue with TikTok Kids Mode, TikTok\u2019s supposedly more COPPA-compliant mobile experience. Kids Mode collected \u201cfar more data\u201d than needed, the FTC alleges, including info about users\u2019 in-app activities and identifiers that TikTok used to build profiles (and shared with third parties) to try to prevent attrition.\n\nWhen parents requested that their child\u2019s accounts be deleted, TikTok made it difficult, the FTC said, and often failed to comply with those requests.\n\n\u201cTikTok knowingly and repeatedly violated kids\u2019 privacy, threatening the safety of millions of children across the country,\u201d FTC chair Lina Khan said in a statement. \u201cThe FTC will continue to use the full scope of its authorities to protect children online \u2014 especially as firms deploy increasingly sophisticated digital tools to surveil kids and profit from their data.\u201d\n\nTikTok had this to share with TechCrunch via email: \u201cWe disagree with these allegations, many of which relate to past events and practices that are factually inaccurate or have been addressed. We are proud of our efforts to protect children, and we will continue to update and improve the platform. To that end, we offer age-appropriate experiences with stringent safeguards, proactively remove suspected underage users, and have voluntarily launched features such as default screen time limits, Family Pairing, and additional privacy protections for minors.\u201d\n\nThe FTC and Justice Department propose fining TikTok and ByteDance civil penalties up to $51,744 per violation per day and a permanent injunction to prevent future COPPA violations.",
        "url": "https://techcrunch.com/2024/08/02/ftc-and-justice-department-sue-tiktok-over-alleged-child-privacy-violations/",
        "category": 2,
        "summary": "\u201cThe FTC will continue to use the full scope of its authorities to protect children online \u2014 especially as firms deploy increasingly sophisticated digital tools to surveil kids and profit from their data.\u201d\n\nTikTok had this to share with TechCrunch via email: \u201cWe disagree with these allegations, many of which relate to past events and practices that are factually inaccurate or have been addressed. \u201cTikTok human reviewers allegedly spent an average of only five to seven seconds reviewing each account to make their determination of whether the account belonged to a child.\u201d\n\nTikTok and ByteDance maintained and used underage users\u2019 data, including data for ads targeting, even after employees raised concerns and TikTok reportedly changed its policy not to require an explicit admission of age, according to the FTC. To that end, we offer age-appropriate experiences with stringent safeguards, proactively remove suspected underage users, and have voluntarily launched features such as default screen time limits, Family Pairing, and additional privacy protections for minors.\u201d\n\nThe FTC and Justice Department propose fining TikTok and ByteDance civil penalties up to $51,744 per violation per day and a permanent injunction to prevent future COPPA violations."
    },
    {
        "title": "Acquiring AI talent wholesale",
        "text": "Welcome to Startups Weekly \u2014 your weekly recap of everything you can\u2019t miss from the world of startups.\n\nThis week we are looking at acquisitions of small startups, two new unicorns, wearable AI devices, and VCs who are supporting Kamala Harris. Let\u2019s get into it.\n\nMost interesting startup stories from the week\n\nImage Credits: Bloomberg / Getty Images\n\nWith the IPO market pretty much dead, we can\u2019t help but track what\u2019s going on with the other kind of exit: mergers and acquisitions. Even though they are not always the outcomes founders or investors were hoping for, we surely are hearing of more startups selling themselves.\n\nCanva\u2019s draws on Leonardo: Graphic design platform Canva has picked up generative AI-powered image creation startup Leonardo.ai, which raised nearly $39 million in venture capital since its founding two years ago. While we don\u2019t know how much Canva paid for Leonardo, we do know that the design giant is busy building out its AI stack, and Leonardo is another piece of that puzzle. Read more\n\nAirtable acquihires Dopt: There is a war for AI talent these days. That\u2019s why collaboration company Airtable decided to buy such talent wholesale. This week, it acquired Dopt, a startup specializing in AI-powered onboarding. At its new home, the Dopt team will be tasked with developing various AI capabilities and will perhaps work on Airtable\u2019s recently launched Airtable Cobuilder, an AI-driven app creation tool. Read more\n\nClutch grabs on to Plaiced: Four-year-old Clutch, a marketplace connecting creators with businesses, has raised $2 million from investors, including Precursor Ventures, and at one point had more than 200 creators on the platform and a 3,000-person waitlist. But the road eventually got tough. The startup restructured itself and laid off staff to reach profitability. Still, the startup\u2019s co-founder decided that Clutch\u2019s best path forward is to sell itself to online social network Plaiced. Read more\n\nBending Spoons scoops up WeTransfer: Bending Spoons, an Italy-based tech company known for acquiring well-known but struggling startups like Evernote and Meetup, has made another purchase \u2014 file transfer service WeTransfer. The 15-year-old WeTransfer was considering a public debut in 2021 but withdrew its plans when the IPO window closed in early 2022. Read more\n\nMost interesting fundraises this week\n\nImage Credits: Dhiraj Singh / Bloomberg / Getty Images\n\nIt\u2019s a bike, it\u2019s a taxi, it\u2019s a unicorn: Rapido, an Indian bike-taxi startup, has achieved unicorn status with a $120 million led by WestBridge Capital. The funding shows that Rapido is encroaching on India\u2019s long-standing mobility Uber and Ola duopoly. Read more\n\nFlo Health raises $200 million: The fertility-focused period tracking app has raised a Series C led by General Atlantic at a $1 billion valuation. TechCrunch chatted with Flo\u2019s co-founder and CEO Dmitry Gurski about the latest funding, women\u2019s health and things in between. Read more\n\nCombating loneliness with AI: It may feel like something out of a science-fiction book or a \u201cBlack Mirror\u201d episode, but Harvard dropout Avi Schiffmann is convinced that constant companionship is one of AI\u2019s killer use cases. He built a device called Friend, which is a necklace that always listens to a person and responds via SMS. Friend, which is priced at $99 and expected to be available in January 2025, has raised $2.5 million in VC funding at a $50 million valuation from investors, including Caffeinated Capital\u2019s Raymond Tonsing, Perplexity CEO Aravind Srinivas, and Solana founder Anatoly Yakovenko. Read more\n\nBee too: Wearable AI hardware that listens and interacts with its owner has yet another entrant, Bee. Founded by former Twitter employees, the company has raised $7 million to develop an AI assistant that can take notes, surface contextual reminders and build lists. Read more\n\nKnowde takes a cut: Sequoia-backed Knowde raised $60 million in a round that values it lower than the $500 million valuation it garnered in 2021. The company, a marketplace to buy chemicals and raw ingredients, founded by a former DuPont chemist, has now raised more than $150 million in total venture funding. Read more\n\nMost interesting VC and fund news this week\n\nImage Credits: Drew Hallowell / Getty Images, Maggie Stamets / Cody Corrall / TechCrunch\n\nVCs for Kamala: With the 2024 presidential election just months aways, many VCs are picking sides \u2014 publicly. This week, Reid Hoffman, Vinod Khosla and Mark Cuban have pledged to vote for Kamala Harris. They created a group called VCsForKamala and are using the website to solicit donations for the current vice president. As of this writing, 645 venture capitalists have pledged their support for Harris. Read more\n\nCook leaves Tiger: Over the last couple years, Tiger Global has had several high-profile departures, such as software investment lead John Curtius and Scott Shleifer, who moved on to the role of an adviser. The latest exodus comes from partner Alex Cook, who focused on many of Tiger\u2019s India investments. Read more\n\nMoxxie raises third fund: Fundraising is tough for emerging VC firms, but Moxxie Ventures defied the odds by easily surpassing its fundraising target for its third fund. The underrepresented founder-focused firm, which is led by Katie Jacobs Stanton, a seasoned investor with a strong network, has secured $95 million in fresh capital. Read more\n\nLast but not least\n\nImage Credits: Applied Intuition\n\nApplied Intuition, an autonomous vehicle software startup, raised a $250 million Series E a few months ago. Now the company has sold $300 million in a secondary sale, adding Fidelity Management & Research Company to its long list of existing investors, which include Lux Capital, Andreessen Horowitz, and Mary Meeker\u2019s growth fund Bond. Read more",
        "url": "https://techcrunch.com/2024/08/02/acquiring-ai-talent-wholesale/",
        "category": 3,
        "summary": "Now the company has sold $300 million in a secondary sale, adding Fidelity Management & Research Company to its long list of existing investors, which include Lux Capital, Andreessen Horowitz, and Mary Meeker\u2019s growth fund Bond. Friend, which is priced at $99 and expected to be available in January 2025, has raised $2.5 million in VC funding at a $50 million valuation from investors, including Caffeinated Capital\u2019s Raymond Tonsing, Perplexity CEO Aravind Srinivas, and Solana founder Anatoly Yakovenko. Read more\n\nMost interesting VC and fund news this week\n\nImage Credits: Drew Hallowell / Getty Images, Maggie Stamets / Cody Corrall / TechCrunch\n\nVCs for Kamala: With the 2024 presidential election just months aways, many VCs are picking sides \u2014 publicly."
    },
    {
        "title": "Character.AI CEO Noam Shazeer returns to Google",
        "text": "In a big move, Character.AI co-founder and CEO Noam Shazeer is returning to Google after leaving the company in October 2021 to found the a16z-backed chatbot startup. In his previous stint, Shazeer spearheaded the team of researchers that built LaMDA (Language Model for Dialogue Applications), a language model that was used for conversational AI tools.\n\nCharacter.AI co-founder Daniel De Freitas is also joining Google with some other employees from the startup. Dominic Perella, Character.AI\u2019s general counsel, is becoming an interim CEO at the startup. The company noted that most of the staff is staying at Character.AI.\n\nGoogle is also signing a non-exclusive agreement with Character.AI to use its tech.\n\n\u201cI am super excited to return to Google and work as part of the Google DeepMind team. I am so proud of everything we built at Character.AI over the last 3 years. I am confident that the funds from the non-exclusive Google licensing agreement, together with the incredible Character.AI team, positions Character.AI for continued success in the future,\u201d Shazeer said in a statement given to TechCrunch.\n\nGoogle said that Shazeer is joining the DeepMind research team but didn\u2019t specify his or De Freitas\u2019s exact roles.\n\n\u201cWe\u2019re particularly thrilled to welcome back Noam, a preeminent researcher in machine learning, who is joining Google DeepMind\u2019s research team, along with a small number of his colleagues,\u201d Google said in a statement. \u201cThis agreement will provide increased funding for Character.AI to continue growing and to focus on building personalized AI products for users around the world,\u201d a Google spokesperson said.\n\nCharacter.AI has raised over $150 million in funding, largely from a16z.\n\n\u201cWhen Noam and Daniel started Character.AI, our goal of personalized superintelligence required a full stack approach. We had to pre-train models, post-train them to power the experiences that make Character.AI special, and build a product platform with the ability to reach users globally,\u201d Character AI mentioned in its blog announcing the move.\n\n\u201cOver the past two years, however, the landscape has shifted; many more pre-trained models are now available. Given these changes, we see an advantage in making greater use of third-party LLMs alongside our own. This allows us to devote even more resources to post-training and creating new product experiences for our growing user base.\u201d\n\nThere is a possibility that different regulatory bodies, such as the Federal Trade Commission (FTC), and the Department of Justice (DoJ) in the U.S. and the EU will scrutinize these reverse acqui-hires closely. Last month. the U.K\u2019s Competition and Markets Authority (CMA) issued a notice saying that it is looking into Microsoft hiring key people from Inflection AI to understand if the tech giant is trying to avoid regulatory oversight. The FTC opened a similar investigation in June to look into Microsoft\u2019s $650 million deal.\n\nYou can reach out to this reporter at im@ivanmehta.com by email and on signal at ivan.42.",
        "url": "https://techcrunch.com/2024/08/02/character-ai-ceo-noam-shazeer-returns-to-google/",
        "category": 3,
        "summary": "I am confident that the funds from the non-exclusive Google licensing agreement, together with the incredible Character.AI team, positions Character.AI for continued success in the future,\u201d Shazeer said in a statement given to TechCrunch. the U.K\u2019s Competition and Markets Authority (CMA) issued a notice saying that it is looking into Microsoft hiring key people from Inflection AI to understand if the tech giant is trying to avoid regulatory oversight. This allows us to devote even more resources to post-training and creating new product experiences for our growing user base.\u201d\n\nThere is a possibility that different regulatory bodies, such as the Federal Trade Commission (FTC), and the Department of Justice (DoJ) in the U.S. and the EU will scrutinize these reverse acqui-hires closely."
    },
    {
        "title": "Adept Materials\u2019 dehumidifying paint was inspired by trees and semiconductors",
        "text": "The steam that condenses on your bathroom mirror may not seem like a big deal, but for architects and builders, it can be an enormous headache.\n\n\u201cMoisture control is something that is a major pain point,\u201d Derek Stein, founder and CEO of Adept Materials. \u201cIf you just google your favorite home builders\u2019 name and then \u2018lawsuit,\u2019 you\u2019ll see lots of examples.\u201d\n\nHomes and offices used to \u201cbreathe\u201d through cracks and crevices that were missed during construction. But in the quest for greater energy efficiency, builders are sealing things up. Tight buildings keep indoor temperatures more consistent, but they can also trap humidity.\n\n\u201cEssentially, buildings are being made more and more like beer coolers. It\u2019s great for energy efficiency, but it\u2019s pretty clear that people don\u2019t like living in beer coolers,\u201d Stein said. \u201cAnd it leads to all of these other problems, like moisture damage.\u201d\n\nRunning a dehumidifier is one option, but they can be noisy and expensive. Stein, who used to be a physics professor at Brown University, came up with another: a two-material system that helps homes self-regulate their internal humidity. His inspiration? Trees and semiconductor diodes.\n\nTrees and other plants regulate their temperature in part by transpiring water through small pores in their leaves. If they get too hot, they open those pores and let more water evaporate, just like sweat cools our skin. When the temperature drops, they can close the pores to slow the rate of transpiration. Stein figured that if he could find a way to similarly absorb and disperse water vapor at the right times, he could make buildings more comfortable and energy efficient.\n\nLots of materials can do that, but they\u2019re not very smart about where they disperse the moisture. Without something to help the moisture move in the desired direction \u2014 outside of a wall cavity, for example \u2014 mold and rot could result.\n\nThat\u2019s where the diode came in. As a physicist, Stein was intimately familiar with their operation. In a diode, electrons can flow freely in one direction but are resisted in the other. Essentially, they operate like a one-way door.\n\nWhat he devised was a system of two materials. One acts as a sponge to absorb water vapor and release it over time. The other is a more typical weather-resistive barrier, which helps block air flow while allowing water vapor to pass through it. Stein\u2019s sponge layer helps serve as traffic cop: When mounted to an exterior wall, the spongy layer will pull moisture away out of the house through the inward-facing barrier. It stays there until the sun warms the outside of the wall and evaporates the moisture.\n\nBuilders buy a lot of weather-resistive barriers, about $14 billion worth in 2022, according to Global Market Insights. But the construction industry tends to be cautious when it comes to new technologies, in part because fixing any problem they cause can be costly. \u201cIn construction, the valley of death is usually deep and wide,\u201d Stein said, referring to the gap between developing a product and actually getting customers to buy it.\n\nTo traverse the valley, Adept is designing its building wrap to look and feel like the old stuff. \u201cOne of the big barriers to adoption is that something looks and feels different,\u201d he said. \u201cPeople are resistant to change.\u201d\n\nWhile Adept refines its water-resistive barriers, the startup will sell another product, a paint and primer system aimed at bathrooms. The primer serves as the barrier layer, while the paint serves as the sponge. As humidity rises in the bathroom, the super-absorbent paint draws in moisture and doesn\u2019t release it until the humidity in the bathroom drops.\n\nTo test the paint\u2019s performance, Adept built a bathroom-sized room and boiled water to raise the humidity. The paint managed to keep the humidity down by 14% compared with conventional paint, Stein said. Adept\u2019s paint and primer will hit the market early next year.\n\nThe startup recently raised a $4 million seed round to help bring the paint to market while continuing development of the water-resistive barrier. The round was led by D.R. Horton with PulteGroup participating. Both are among the largest homebuilders in the U.S.\n\n\u201cAs a startup company, you want to pilot runs and stuff like that, but people might not give you the time of day,\u201d Stein said. \u201cBut if the biggest homebuilder in the U.S. says this is interesting to us, then it moves the needle.\u201d",
        "url": "https://techcrunch.com/2024/08/02/adept-materials-dehumidifying-paint-was-inspired-by-trees-and-semiconductors/",
        "category": 3,
        "summary": "\u201cIn construction, the valley of death is usually deep and wide,\u201d Stein said, referring to the gap between developing a product and actually getting customers to buy it. \u201cIf you just google your favorite home builders\u2019 name and then \u2018lawsuit,\u2019 you\u2019ll see lots of examples.\u201d\n\nHomes and offices used to \u201cbreathe\u201d through cracks and crevices that were missed during construction. Stein\u2019s sponge layer helps serve as traffic cop: When mounted to an exterior wall, the spongy layer will pull moisture away out of the house through the inward-facing barrier."
    },
    {
        "title": "Yelp\u2019s lack of transparency around API charges angers developers",
        "text": "On July 19, Yelp informed select indie developers that they would have to switch to paid accounts, due to high API usage. Developers were given four days to make the change, in a move that echoes recent communication bungles by Reddit and Twitter.\n\nWhen the developers replied to the July 19 email, Yelp sent a deck of pricing tiers with base pricing starting from $229 per month for a limit of 1,000 API calls per day.\n\nDevelopers were concerned that other, more affordable options weren\u2019t mentioned in the deck. Yelp said the pricing is equivalent and simply presented in different ways.\n\nThe method of communication and lack of transparency has angered developers, some of whom shuttered their services, even after Yelp gave them a 90-day leeway and apologized.\n\nWhat happened?\n\nThe email, which was viewed by TechCrunch, notes, \u201cWe appreciate you signing up for and trialing the Yelp Fusion API. Your API usage is higher than lots of other Yelp Fusion developers and we would like to learn more about how you\u2019re integrating the Fusion API into your platform.\n\n\u201cIf we don\u2019t hear back from you by 4:00 pm EST on 7/23/2024, we will temporarily disable your API key until we receive a response with the above-requested information.\u201d\n\nDavid Kopec, who developed a Mac app called Restaurants for finding local dining options, noted on his blog that Yelp initially offered him up to 25,000 daily API calls for free in 2014.\n\nOther startups have publicly voiced their own complaints about Yelp\u2019s handling of the situation.\n\nFood Genie is celebrating the end of an era. Thanks to a change in Yelp's API being pay to use\u2026.we are making it free until next week when the API makes its changes. Enjoy.https://t.co/ebmrN3Cc66 \u2014 Food Genie (@thefoodgenieapp) July 19, 2024\n\nFood Genie developer Nick Perkins told TechCrunch that he was surprised by Yelp\u2019s announcement, and the company didn\u2019t answer his questions about the announcement. Perkins said his 99-cent app, which launched in 2017, used only a few hundred calls per day.\n\nwarning to those using @Yelp fusion api \u2013 with little to no warning, they'reforcing developers to go paid with only a week to decide (or turn off api keys)\n\n\n\nseems like they are scrambling for a sustainable biz model and with AI trends, they will be rendered obsolete soon. \u2014 Roj Niyogi (@niyogi) July 24, 2024\n\nRoj Niyogi, co-founder of Enefits, which is a small startup built around a location-based rewards program, said that the company used Yelp\u2019s API for place data. He said Yelp\u2019s short notice and threatening to take away access were like a \u201cvirtual gun to the head.\u201d\n\nYelp responds\n\nYelp told TechCrunch that the company moved to a paid pricing model in 2019 and has been gradually budging developers to a paid plan. It also noted that since that move, many developers are still using the free version of the API.\n\n\u201cYelp sunsetted free, commercial, unlimited use of the Yelp Fusion API in 2019 and has been in the process of migrating developers to a paid program over the last several years. The developer community is important to Yelp, and we\u2019ve heard their feedback about the transition period from the free Yelp Fusion API to our paid program,\u201d a company spokesperson said in a statement.\n\nThe company apologized for its July communications. \u201cWe apologize for last week\u2019s abbreviated transition that impacted a small percentage of developers and have extended access to these users,\u201d the company spokesperson told TechCrunch.\n\nOn Thursday, Yelp sent an apology email to developers and extended their free usage by 90 days. \u201cEarlier this month, we sent you an email about your Yelp Fusion API usage. That email gave developers until July 23 to contact us if they want to continue using Yelp\u2019s data for use in their app. We realize you might need more time and are extending your free access for an additional 90 days starting today. Your access should be available now,\u201d according to the email, which was viewed by TechCrunch.\n\n\u201cWe\u2019re sorry for any inconvenience or frustration this abbreviated transition might have caused.\u201d\n\nPerkins told TechCrunch that he already pulled Food Genie from the App Store, due to Yelp\u2019s \u201cpoor execution\u201d of the transition to a paid API. He added that if he decided to bring back his app, he might look for a different API.\n\nKopec also decided to shutter his project. He said the company didn\u2019t respond to him about the price disparity between the deck sent to him and the website.\n\nAll the developers that TechCrunch talked to were upset about the four-day deadline and how the company handled the communication. They weren\u2019t necessarily upset over the transition to a paid version of API.\n\n\u201cRestaurants was a very low-selling app, and it would not have made sense either way to continue financially. But again, I do not begrudge them going to paid [version of API]. Only that they gave me four days\u2019 notice and sent an inaccurate and threatening email,\u201d Kopec said over email, referring to Yelp\u2019s note about disabling his API key.\n\nAs AI models increase in number, companies sitting on large sets of user-generated data have been limiting third-party access. Over the last year, Twitter/X and Reddit made it difficult for makers of third-party clients and tools to keep supporting development by changing their API terms.\n\nThese platforms alienated developers who had built popular tools and supported these social networks for years. Much like with Yelp, developers were frustrated by those platforms\u2019 lack of transparency, support and pricing for small developers. Eventually, a lot of them moved to developing apps for new platforms.\n\nMaybe there is a lesson for Yelp in this.",
        "url": "https://techcrunch.com/2024/08/02/yelps-lack-of-transparency-around-api-charges-angers-developers/",
        "category": 3,
        "summary": "warning to those using @Yelp fusion api \u2013 with little to no warning, they'reforcing developers to go paid with only a week to decide (or turn off api keys)\n\n\n\nseems like they are scrambling for a sustainable biz model and with AI trends, they will be rendered obsolete soon. He said Yelp\u2019s short notice and threatening to take away access were like a \u201cvirtual gun to the head.\u201d\n\nYelp responds\n\nYelp told TechCrunch that the company moved to a paid pricing model in 2019 and has been gradually budging developers to a paid plan. \u201cIf we don\u2019t hear back from you by 4:00 pm EST on 7/23/2024, we will temporarily disable your API key until we receive a response with the above-requested information.\u201d\n\nDavid Kopec, who developed a Mac app called Restaurants for finding local dining options, noted on his blog that Yelp initially offered him up to 25,000 daily API calls for free in 2014."
    },
    {
        "title": "OpenAI releases ChatGPT\u2019s hyperrealistic voice to some paying users",
        "text": "OpenAI began rolling out ChatGPT\u2019s Advanced Voice Mode on Tuesday, giving users their first access to GPT-4o\u2019s hyperrealistic audio responses. The alpha version will be available to a small group of ChatGPT Plus users today, and OpenAI says the feature will gradually roll out to all Plus users in the fall of 2024.\n\nWhen OpenAI first showcased GPT-4o\u2019s voice in May, the feature shocked audiences with quick responses and an uncanny resemblance to a real human\u2019s voice \u2013 one in particular. The voice, Sky, resembled that of Scarlett Johansson, the actress behind the artificial assistant in the movie \u201cHer.\u201d Soon after OpenAI\u2019s demo, Johansson said she refused multiple inquiries from CEO Sam Altman to use her voice, and after seeing GPT-4o\u2019s demo, hired legal counsel to defend her likeness. OpenAI denied using Johansson\u2019s voice, but later removed the voice shown in its demo. In June, OpenAI said it would delay the release of Advanced Voice Mode to improve its safety measures.\n\nOne month later, and the wait is over (sort of). OpenAI says the video and screensharing capabilities showcased during its Spring Update will not be part of this alpha, launching at a \u201clater date.\u201d For now, the GPT-4o demo that blew everyone away is still just a demo, but some premium users will now have access to ChatGPT\u2019s voice feature shown there.\n\nChatGPT can now talk and listen\n\nYou may have already tried out the Voice Mode currently available in ChatGPT, but OpenAI says Advanced Voice Mode is different. ChatGPT\u2019s old solution to audio used three separate models: one to convert your voice to text, GPT-4 to process your prompt, and then a third to convert ChatGPT\u2019s text into voice. But GPT-4o is multimodal, capable of processing these tasks without the help of auxiliary models, creating significantly lower latency conversations. OpenAI also claims GPT-4o can sense emotional intonations in your voice, including sadness, excitement or singing.\n\nIn this pilot, ChatGPT Plus users will get to see first hand how hyperrealistic OpenAI\u2019s Advanced Voice Mode really is. TechCrunch was unable to test the feature before publishing this article, but we will review it when we get access.\n\nOpenAI says it\u2019s releasing ChatGPT\u2019s new voice gradually to closely monitor its usage. People in the alpha group will get an alert in the ChatGPT app, followed by an email with instructions on how to use it.\n\nIn the months since OpenAI\u2019s demo, the company says it tested GPT-4o\u2019s voice capabilities with more than 100 external red teamers who speak 45 different languages. OpenAI says a report on these safety efforts is coming in early August.\n\nThe company says Advanced Voice Mode will be limited to ChatGPT\u2019s four preset voices \u2013 Juniper, Breeze, Cove and Ember \u2013 made in collaboration with paid voice actors. The Sky voice shown in OpenAI\u2019s May demo is no longer available in ChatGPT. OpenAI spokesperson Lindsay McCallum says \u201cChatGPT cannot impersonate other people\u2019s voices, both individuals and public figures, and will block outputs that differ from one of these preset voices.\u201d\n\nOpenAI is trying to avoid deepfake controversies. In January, AI startup ElevenLabs\u2019s voice cloning technology was used to impersonate President Biden, deceiving primary voters in New Hampshire.\n\nOpenAI also says it introduced new filters to block certain requests to generate music or other copyrighted audio. In the last year, AI companies have landed themselves in legal trouble for copyright infringement, and audio models like GPT-4o unleash a whole new category of companies that can file a complaint. Particularly, record labels, who have a history for being litigious, and have already sued AI song-generators Suno and Udio.",
        "url": "https://techcrunch.com/2024/07/30/openai-releases-chatgpts-super-realistic-voice-feature/",
        "category": 0,
        "summary": "OpenAI spokesperson Lindsay McCallum says \u201cChatGPT cannot impersonate other people\u2019s voices, both individuals and public figures, and will block outputs that differ from one of these preset voices.\u201d\n\nOpenAI is trying to avoid deepfake controversies. OpenAI says the video and screensharing capabilities showcased during its Spring Update will not be part of this alpha, launching at a \u201clater date.\u201d For now, the GPT-4o demo that blew everyone away is still just a demo, but some premium users will now have access to ChatGPT\u2019s voice feature shown there. The voice, Sky, resembled that of Scarlett Johansson, the actress behind the artificial assistant in the movie \u201cHer.\u201d Soon after OpenAI\u2019s demo, Johansson said she refused multiple inquiries from CEO Sam Altman to use her voice, and after seeing GPT-4o\u2019s demo, hired legal counsel to defend her likeness."
    },
    {
        "title": "Intel to lay off 15,000 employees",
        "text": "Intel announced it would lay off more than 15% of its staff, or 15,000 employees, in a memo to employees on Thursday. The massive headcount is part of a large plan to reduce spending by $10 billion in 2025, following a dismal second-quarter earnings report and outlook.\n\n\u201cOur revenues have not grown as expected \u2014 and we\u2019ve yet to fully benefit from powerful trends, like AI,\u201d said CEO Pat Gelsinger in a memo to employees. \u201cOur costs are too high, our margins are too low. We need bolder actions to address both \u2014 particularly given our financial results and outlook for the second half of 2024, which is tougher than previously expected.\u201d\n\nAs Gelsinger describes, Intel has struggled to capitalize on the AI boom in the same way other hardware companies, such as Nvidia, have. Intel led the tech industry\u2019s revolution around CPU chips roughly 25 years ago, but has been slow to embrace newer waves of computing such as smartphones and AI. Gelsinger says annual revenues at Intel fell $24 billion between 2020 and 2023, despite its workforce growing 10% in the same time frame. That\u2019s a stark contrast to other chipmakers during the AI boom, who have seen revenues and valuations soar to astronomical heights.\n\nIntel reported a 1% decline in revenues for the second quarter compared to the same period last year. The company attributed the loss to gross margin headwinds related to its AI PC products. The company is also suspending its shareholder dividend starting in the fourth quarter of 2024, and anticipates \u201cmore challenging\u201d second-half trends than it previously expected.\n\nBeyond the layoffs, Intel will broadly offer applications for a \u201cvoluntary departure\u201d program next week to employees at the company, according to the memo. The company is also announcing a companywide enhanced retirement offering for eligible employees.",
        "url": "https://techcrunch.com/2024/08/01/intel-to-lay-off-15000-employees/",
        "category": 3,
        "summary": "The massive headcount is part of a large plan to reduce spending by $10 billion in 2025, following a dismal second-quarter earnings report and outlook. Intel led the tech industry\u2019s revolution around CPU chips roughly 25 years ago, but has been slow to embrace newer waves of computing such as smartphones and AI. We need bolder actions to address both \u2014 particularly given our financial results and outlook for the second half of 2024, which is tougher than previously expected.\u201d\n\nAs Gelsinger describes, Intel has struggled to capitalize on the AI boom in the same way other hardware companies, such as Nvidia, have."
    },
    {
        "title": "How to enable Apple Intelligence on your iPhone",
        "text": "Apple is finally releasing some of the Apple Intelligence features it announced at its Worldwide Developers Conference in June.\n\nHowever, the rollout is currently restricted to developer beta versions of iOS 18.1. So if you don\u2019t want to deal with early-stage buggy software, you might want to wait for the Apple Intelligence feature release of public betas or the stable release later this year.\n\nIf you are on the developer beta, you can only use Apple Intelligence features if your language is set to U.S. English and your region is set to U.S. This doesn\u2019t affect your App Store regions or purchases.\n\nHere is how you can start using Apple Intelligence features:\n\nOpen the Settings app.\n\nGo to the Apple Intelligence & Siri menu.\n\nTap on the \u201cJoin the Apple Intelligence waitlist\u201d option.\n\nOnce your waitlist position is approved, you will get a notification. It might take a while for the system to download all models and data necessary to run Apple Intelligence. You can toggle off the Apple Intelligence feature from the menu at any point in time.\n\nImage Credits: Apple\n\nApple\u2019s AI suite features work through a combination of on-device and Apple Private Cloud requests. Apple said that the waitlist is to ensure sufficient service capacity.\n\nAt the moment, Apple Intelligence is only compatible with iPhone 15 Pro, iPhone 15 Pro Max, and iPads and Macs that run on M1 chips.\n\nAvailable features\n\nNew Siri: Apple Intelligence-powered Siri has a new animation. Plus, you can always double tap on the bottom bar to text Siri when you are in a loud place or a meeting. Siri can also handle stumbling words, so when you say, \u201cHey Siri, set a 10-minute, no, 15-minute timer,\u201d it will set a 15-minute timer.\n\nApple Intelligence-powered Siri has a new animation. Plus, you can always double tap on the bottom bar to text Siri when you are in a loud place or a meeting. Siri can also handle stumbling words, so when you say, \u201cHey Siri, set a 10-minute, no, 15-minute timer,\u201d it will set a 15-minute timer. How-to questions: You can also ask Siri about Apple\u2019s system-related how-tos such as \u201cHow do I take a screen recording?\u201d\n\nYou can also ask Siri about Apple\u2019s system-related how-tos such as \u201cHow do I take a screen recording?\u201d Writing tools: You can now reformat any text across the system. You can use \u201cProofread\u201d to check for spelling mistakes or grammatical errors and \u201cRewrite\u201d to rewrite the selected text without changing the meaning a lot. You can also choose to change the tone of the text through three options: \u201cFriendly,\u201d \u201cProfessional\u201d or \u201cConcise.\u201d You can summarize the text to generate a list, key points or a table.\n\nYou can now reformat any text across the system. You can use \u201cProofread\u201d to check for spelling mistakes or grammatical errors and \u201cRewrite\u201d to rewrite the selected text without changing the meaning a lot. You can also choose to change the tone of the text through three options: \u201cFriendly,\u201d \u201cProfessional\u201d or \u201cConcise.\u201d You can summarize the text to generate a list, key points or a table. Mail app: The Mail app now shows summaries of emails in one line without opening them. Apple Intelligence also shows important emails on top of the inbox. Plus, you can use AI-generated smart replies to quickly respond to emails.\n\nThe Mail app now shows summaries of emails in one line without opening them. Apple Intelligence also shows important emails on top of the inbox. Plus, you can use AI-generated smart replies to quickly respond to emails. Photos: You can now search for photos through natural language queries. Additionally, you can also create memories via prompts.\n\nYou can now search for photos through natural language queries. Additionally, you can also create memories via prompts. Notification summaries: Apple Intelligence also shows summaries of some mail and message notifications.\n\nApple Intelligence also shows summaries of some mail and message notifications. Call transcriptions: Apple Intelligence now powers call recording with the tap of a button. The recordings are stored under a new \u201cCall Recordings\u201d folder in the Notes app.\n\nApple Intelligence now powers call recording with the tap of a button. The recordings are stored under a new \u201cCall Recordings\u201d folder in the Notes app. Notes app audio support: You can also record and transcribe audio directly into the Notes app. Apple\u2019s AI suite will also automatically produce a summary.\n\nApple Intelligence doesn\u2019t yet have features such as the ability to remove unwanted objects in photos, emoji, image playground, and ChatGPT interactions. There is no fixed timeline for when we will get to test these features.",
        "url": "https://techcrunch.com/2024/07/31/how-to-enable-apple-intelligence-on-your-iphone/",
        "category": 4,
        "summary": "You can also choose to change the tone of the text through three options: \u201cFriendly,\u201d \u201cProfessional\u201d or \u201cConcise.\u201d You can summarize the text to generate a list, key points or a table. You can also choose to change the tone of the text through three options: \u201cFriendly,\u201d \u201cProfessional\u201d or \u201cConcise.\u201d You can summarize the text to generate a list, key points or a table. So if you don\u2019t want to deal with early-stage buggy software, you might want to wait for the Apple Intelligence feature release of public betas or the stable release later this year."
    },
    {
        "title": "iPad sales help bail out Apple amid a continued iPhone slide",
        "text": "Apple on Thursday announced that its third-quarter financials beat Wall Street expectations, as its overall revenue ticked up 5%. iPad, which had languished in recent years, saw the biggest category increase for the quarter, up from $5.8 billion to $7.2 billion year-over-year. Tablet sales, fueled by the line\u2019s largest refresh in years, helped counter slowed iPhone revenue, which dropped from $39.7 billion to $39.3 billion year-on-year.\n\nIn spite of a drop for the quarter, iPhone remained Apple\u2019s most important category by a wide margin, followed by service, which includes software offerings like iCloud, Apple TV+ and Apple Music. That category continued to grow, up to $24.2 billion from $21.2 billion over the same three-month period last year.\n\nMuch of the iPhone slowdown can be attributed to the greater China region. Overall, the region dropped from $15.8 billion to $14.7 billion for the quarter. Canalys figures from last week show a marked decline in iPhone sales, down 6.7% from 10.4 million to 9.7 million for the quarter, Reuters reported.\n\nThe drop in Apple\u2019s third-largest region (behind the Americas and Europe) had a clear impact on the company\u2019s bottom line. The company aggressively discounted iPhone prices in China starting in May, as competition intensified from domestic rivals. The strategy resulted in strong iPhone sales that month, up close to 40% from a year prior.\n\nHuawei had previously been sidelined by U.S. sanctions that cut off access to software and components from companies like Google and Qualcomm. After turning in-house to produce its own chips as well as an Android alternative, the company has seen a sizable rebound in its home country.\n\nCanalys figures show a 41% year-over-year growth spurt for the quarter, as the Huawei topped Apple\u2019s overall sales China sales at 10.6 million for the quarter.\n\nQ3 marked the second consecutive quarter decline for global iPhone sales. The news puts additional pressure on the generative AI strategy that the company laid out at WWDC in June.\n\nIn an interview with CNBC, CEO Tim Cook noted that the company has invested a good portion of resources into growing Apple Intelligence.\n\n\u201cWhat we\u2019ve done is we\u2019ve redeployed a lot of people on to AI that were working on other things,\u201d the executive noted. \u201cFrom a data center point of view, as you know, we have a hybrid approach. So we both have our own and we partner with people. And so that capex would be in the partners\u2019 financials, and we would be paying expense.\u201d\n\nSome of those resources reportedly arrived after Apple closed the door on its autonomous electric car effort, Project Titan.",
        "url": "https://techcrunch.com/2024/08/01/ipad-sales-help-bail-out-apple-amid-a-continued-iphone-slide/",
        "category": 4,
        "summary": "Tablet sales, fueled by the line\u2019s largest refresh in years, helped counter slowed iPhone revenue, which dropped from $39.7 billion to $39.3 billion year-on-year. And so that capex would be in the partners\u2019 financials, and we would be paying expense.\u201d\n\nSome of those resources reportedly arrived after Apple closed the door on its autonomous electric car effort, Project Titan. In spite of a drop for the quarter, iPhone remained Apple\u2019s most important category by a wide margin, followed by service, which includes software offerings like iCloud, Apple TV+ and Apple Music."
    },
    {
        "title": "Microsoft now lists OpenAI as a competitor in AI and search",
        "text": "Microsoft has a long and tangled history with OpenAI, having invested a reported $13 billion in the ChatGPT maker as part of a long-term partnership. As part of the deal, Microsoft runs OpenAI\u2019s models across its enterprise and consumer products and is OpenAI\u2019s exclusive cloud provider.\n\nHowever, the tech giant called the startup a \u201ccompetitor\u201d for the first time in an SEC filing on Tuesday.\n\nIn Microsoft\u2019s annual 10K, OpenAI joined a long list of competitors in AI, alongside Anthropic, Amazon, and Meta. OpenAI was also listed alongside Google as a competitor to Microsoft in search, thanks to OpenAI\u2019s new SearchGPT feature announced last week.\n\nIt\u2019s possible Microsoft is trying to change the narrative on its relationship with OpenAI in light of antitrust concerns \u2014 the FTC is currently looking into the relationship, alongside similar cloud provider investments into AI startups. Microsoft recently agreed to give up its board observer seat at the startup \u2014 a seat it gained after a kerfuffle last fall when OpenAI\u2019s board briefly fired CEO Sam Altman, prompting Microsoft CEO Satya Nadella to offer him and other top execs jobs at Microsoft.\n\nHowever, SEC filings like this are often places where corporations throw out hyper-cautious warnings to investors.\n\nPartners and competitors are certainly not mutually exclusive titles in Silicon Valley. In the year 2000, the dominant search engine at the time, Yahoo, announced an agreement to let Google\u2019s search results appear on its web page. The two companies were partners for a few years, until Google ate Yahoo\u2019s lunch in search and became the unofficial, but dominant, doorstep to the internet. The two companies were partners, but were still threats to each other. (Yahoo is the owner of TechCrunch.)\n\nThere\u2019s enough history of this kind of power-switch in tech that it\u2019s at least conceivable that Microsoft and OpenAI\u2019s relationship will take a similar route.\n\nRegardless, Microsoft is not putting all its eggs in one basket.\n\nIn March, Microsoft hired the co-founders of billion-dollar AI startup Inflection AI, Mustafa Suleyman and Kar\u00e9n Simonyan, to lead its new Microsoft AI division. The cloud provider is investing heavily into Microsoft Copilot and building out an AI future that\u2019s entirely separate from OpenAI.",
        "url": "https://techcrunch.com/2024/08/01/microsoft-now-lists-openai-as-a-competitor-in-ai-and-search/",
        "category": 0,
        "summary": "In March, Microsoft hired the co-founders of billion-dollar AI startup Inflection AI, Mustafa Suleyman and Kar\u00e9n Simonyan, to lead its new Microsoft AI division. It\u2019s possible Microsoft is trying to change the narrative on its relationship with OpenAI in light of antitrust concerns \u2014 the FTC is currently looking into the relationship, alongside similar cloud provider investments into AI startups. Microsoft recently agreed to give up its board observer seat at the startup \u2014 a seat it gained after a kerfuffle last fall when OpenAI\u2019s board briefly fired CEO Sam Altman, prompting Microsoft CEO Satya Nadella to offer him and other top execs jobs at Microsoft."
    },
    {
        "title": "A comprehensive list of 2024 tech layoffs",
        "text": "From major layoffs at Tesla, Amazon and Microsoft to small fintech startups and apps\n\nThe tech layoff wave is still going strong in 2024. Following significant workforce reductions in 2022 and 2023, this year has already seen 60,000 job cuts across 254 companies, according to independent layoffs tracker Layoffs.fyi. Companies like Tesla, Amazon, Google, TikTok, Snap and Microsoft have conducted sizable layoffs in the first months of 2024. Smaller-sized startups have also seen a fair amount of cuts, and in some cases, have shut down operations altogether.\n\nBy tracking these layoffs, we\u2019re able to understand the impact on innovation across companies large and small. We\u2019re also able to see the potential impact of businesses embracing AI and automation for jobs that had previously been considered safe. It also serves as a reminder of the human impact of layoffs and what could be at stake in regards to increased innovation.\n\nBelow you\u2019ll find a comprehensive list of all the known layoffs in tech that have occurred in 2024, to be updated regularly. If you have a tip on a layoff, contact us here. If you prefer to remain anonymous, you can contact us here.\n\nAugust 2024\n\nIntel\n\nIntel kicked off the month with substantial layoffs, with 15,000 employees accounting for 15% of its total staff affected by the company\u2019s cutbacks. \u201cOur revenues have not grown as expected \u2014 and we\u2019ve yet to fully benefit from powerful trends, like AI,\u201d CEO Pat Gelsinger said in a memo announcing the layoffs.\n\nJuly 2024\n\nRad Power Bikes\n\nThe e-bike startup that has raised more than $300 million from investors has also conducted five rounds of layoffs since April 2021, with TechCrunch exclusively learning that Red Power\u2019s most recent layoffs were conducted in July with an unknown number of Rad Power\u2019s roughly 394 employees impacted.\n\nMatch Group\n\nHas discontinued livestreaming services across its dating apps, specifically Plenty of Fish and BLK, as it shifts its focus to generative AI. The move will result in a 6% reduction in its total workforce.\n\nBungie\n\nWill cut 220 employees, representing around 17% of the game studio\u2019s total workforce. CEO Pete Parsons said the changes impact all levels of the company, including senior and executive leadership.\n\nPocket FM\n\nHas reportedly eliminated roles for nearly 200 U.S. writers a month after the company partnered with ElevenLabs to quickly convert scripts into audio content using AI.\n\nWayCool Foods\n\nHas reportedly laid off more than 200 employees across several departments. It would be the agritech company\u2019s third substantial layoff round in the past year.\n\nWebflow\n\nAnnounced it will eliminate roughly 8% of its workforce as the company works toward its \u201cnext phase of growth.\u201d\n\nCohere\n\nIs reportedly laying off about 20 employees, accounting for nearly 5% of its total workforce. The cuts came the day after the company announced it raised $500 million at a $5 billion valuation.\n\nMagic Leap\n\nReportedly eliminated around 75 of its workers. As part of the cuts, the augmented reality startup reportedly axed its sales and marketing departments entirely.\n\nMercari\n\nIs reportedly laying off nearly half of its employees in the U.S. as the Japan-based company struggles to compete with other e-commerce rivals like Temu.\n\nAqua\n\nIs eliminating 50 employees, accounting for 10% of its total workforce. Earlier this year, the cybersecurity company raised $60 million at a $1 billion valuation, making it a unicorn.\n\nEverC\n\nIs reportedly laying off 10% of its 165-person workforce. The company develops cyber intelligence software that helps prevent online fraud.\n\nLex\n\nHas laid off the majority of its roughly eight-person staff as the LGBTQ+ social networking site struggles to monetize its product. Last year, the company\u2019s third, Lex raised $5.6 million in seed funding and elevated co-founder Jennifer Lewis from COO to CEO.\n\nMonarch Tractor\n\nCut \u201cless than\u201d 15% of its 250- to 300-person workforce as part of a necessary reshuffling following a $133 million Series C funding round, TechCrunch has learned.\n\nKaspersky\n\nWill lay off dozens of employees and leave the U.S. market completely following a U.S. government order that banned the sale of the company\u2019s software due to security risks.\n\nSalesforce\n\nEliminated about 300 employees in its workforce as it rolls out a broader effort to cut costs and streamline its operations.\n\nIntuit\n\nWill cut 1,800 employees, impacting 10% of its workforce. The company says more than half were cut due to low performance and aims to hire approximately the same number of employees instead of cutting costs.\n\nUiPath\n\nPlans to cut 420 jobs, 10% of its total workforce, as the company undergoes a large restructuring effort.\n\nUKG\n\nCut an estimated 2,200 employees, amounting to nearly 14% of its workforce, as the software company attempts to redirect its resources into \u201ckey areas of product innovation.\u201d\n\nOpenText\u200b\u200b\n\nPlans to cut roughly 1,200 jobs, amounting to almost 2% of its total workforce, as the information management company plans to significantly reduce its expenses by 2025.\n\nUnacademy\n\nIs laying off about 250 employees in the latest in a series of job cuts after schools reopened across India following pandemic lockdowns.\n\nKoo\n\nIs ceasing its operations after its last-resort acquisition talks with Dailyhunt collapsed.\n\nUpside Foods\n\nHas cut its workforce by 26 people, CEO Uma Valeti wrote in an email to staff, as the lab-grown meat industry sees a decline in VC funding.\n\nSightful\n\nIs eliminating 20 employees, amounting to a third of its total workforce, as the company shifts its focus to software development.\n\nJune 2024\n\nRealPage\n\nWill cut approximately 4% of its workforce as part of a plan to boost growth, though the company is also one of many within its field facing a consolidated lawsuit alleging they engaged in price fixing.\n\nPlanet\n\nIntends to lay off roughly 180 employees, amounting to 17% of its workforce, according to an SEC filing that amounts to its second recent round of layoffs.\n\nMoxion Power\n\nIs laying off more than 100 employees, according to a WARN filing. The news of the cuts comes after the company launched a large office expansion in Richmond, California.\n\neBay\n\nIs reportedly conducting layoffs in Israel as it goes through a global restructuring.\n\nBeReal\n\nIs reportedly cutting a large number of its staff after being acquired by French gaming company Voodoo.\n\nFlutterwave\n\nHas laid off about 30 people, accounting for 3% of its workforce, as it refocuses its business to enterprise.\n\nGinkgo Bioworks\n\nTerminated 158 employees, with another batch of layoffs expected to come as the company aims to reduce its workforce by 25%.\n\nMoovit\n\nIs making cuts to 10% of its workforce, impacting around 20 to 25 employees.\n\nWex\n\nIs laying off 375 employees, accounting for 5% of its total workforce.\n\nPayPal\n\nWill eliminate up to 85 employees based in Ireland, the company announced.\n\nRapyd\n\nIs reportedly laying off around 30 employees in Israel and will move positions to other regions to cut costs.\n\nC2FO\n\nCut 16 employees in its supplier resource management department as it focuses on automation.\n\nChegg\n\nIs reducing its global headcount by 23% in a major restructuring effort as the online learning platform aims to become a \u201cleaner\u201d operation.\n\nStackPath\n\nIs closing up shop and liquidating its assets. The number of employees affected is currently unknown.\n\nUnit\n\nIs reducing its headcount by 15% as the company attempts to \u201cthink in longer time frames,\u201d the company announced in a blog post.\n\nLoop\n\nIs making more cuts, co-CEO Carey Anne Nadeau announced on LinkedIn. The number of employees impacted is currently unknown.\n\nCare/of\n\nWill lay off its 143 employees by July 3 due to a \u201cfunding loss,\u201d and will no longer be accepting new orders. The company has not shut down fully though, telling TechCrunch: \u201cWe are actively exploring options for the brand but do not have anything definitive to communicate at this time.\u201d\n\nRunning Tide\n\nShut down its operations and laid off its remaining employees after raising more than $50 million since its 2017 start.\n\nSatellogic\n\nIs laying off 70 employees, about 30% of its workforce, three weeks after an earlier round of cuts impacted 34 employees.\n\nByteDance\n\nIs slashing around 450 jobs at its Indonesian e-commerce division, accounting for 9% of the unit.\n\nVRChat\n\nHas eliminated around 30% of its total workforce, CEO Graham Gaylor confirmed in a statement.\n\nPaytm\n\nIs reportedly conducting large cuts across the company. The total number of employees impacted is currently unknown.\n\nKissflow\n\nHas cut around 45 jobs as part of a restructuring effort.\n\nCopia Global\n\nHas laid off at least 1,060 employees two weeks after the startup filed for administration.\n\nRevel\n\nIs laying off its 1,000+ staff drivers as it embraces a gig worker model similar to that of Lyft and Uber.\n\nSimpl\n\nHas cut 30 employees a month after the Bengaluru-based startup laid off 160 people.\n\nOda\n\nHas confirmed layoffs of 150 jobs as it drastically scales back its expansion ambitions to focus on its markets in Norway and Sweden.\n\nPagaya\n\nIs laying off 100 workers, or 20% of its staff, in another round of cuts.\n\nMoonPay\n\nIs reportedly laying off 10% of its workforce, amounting to around 30 people.\n\nMicrosoft\n\nIs reportedly cutting hundreds of employees working in its Azure cloud business, though the exact number of employees impacted is currently unknown.\n\nOrCam\n\nIs laying off 100 employees months after reducing its headcount by 50 workers.\n\nGoogle\n\nIs reportedly making large cuts globally across several of its Cloud teams, including teams focused on sustainability, consulting and partner engineering.\n\nTropic\n\nIs eliminating 40 employees as part of a restructuring effort, CEO David Campbell wrote in a post on LinkedIn.\n\nMay 2024\n\nGro Intelligence\n\nIs shutting down its operations after laying off 60% of its staff in March in an attempt to stay afloat.\n\nJasper Health\n\nHas laid off a substantial part of its workforce, TechCrunch learned. Engineering and product design departments were most impacted by the cuts at the cancer care platform startup.\n\nCirium\n\nIs laying off 37 tech workers at FlightStats, the flight tracking startup it acquired in 2016, as it plans to consolidate its operations in India and the U.K.\n\nWalnut\n\nIs cutting 15 employees in a round of layoffs, impacting 20% of the Israeli startup\u2019s total workforce.\n\nFisker\n\nHas laid off hundreds of employees in a bid to keep the EV startup alive. One current and one laid off employee told TechCrunch exclusively that an estimated 150 people remain at the company.\n\nCue Health\n\nIs shutting down its operations and laying off the rest of its staff. The COVID-19 test company laid off half of its workforce earlier this month to cut costs.\n\nFoursquare\n\nHas let go of 105 employees as the company seeks to \u201cstreamline\u201d its operations, according to an email to staffers from current CEO Gary Little.\n\nLucid Motors\n\nIs laying off about 400 employees, roughly 6% of its workforce, as part of a restructuring ahead of the launch of its first electric SUV later this year.\n\nTikTok\n\nWill reportedly make large cuts to its global operations and marketing teams. The amount of employees impacted is currently unknown.\n\nPixar\n\nWill reportedly cut 14% of its staff, impacting 175 employees, as the company shifts its focus from original Disney+ programming back to films.\n\nReplit\n\nLet go of 20% of its staff as the coding startup shifts its focus to enterprise sales.\n\nSeekOut\n\nCut about 30% of its total workforce. The recruiting startup that uses AI to find candidates was last valued at over $1.2 billion in January 2022.\n\nGopuff\n\nEliminated 6% of its staff in another round of layoffs as the fast-delivery startup attempts to become cash-flow positive by the end of 2024.\n\nAtmosphere\n\nPlans to lay off 106 employees, according to a WARN notice filed in Texas.\n\nMainvest\n\nHas shut down its operations. The number of employees affected is currently unknown.\n\nIndeed\n\nIs cutting roughly 1,000 jobs, impacting 8% of the company\u2019s headcount, CEO Chris Hyams wrote in a letter to staff.\n\nMotional\n\nCut around 40% of its workforce, impacting about 550 employees, sources told TechCrunch. The company\u2019s chief operating officer, Abe Ghabra, has also left the company.\n\nGoogle\n\nWill eliminate 57 positions in San Francisco, according to a WARN notice filed in California.\n\nVacasa\n\nIs eliminating 800 employees, accounting for 13% of its workforce, as part of a restructuring effort.\n\nBrilliant\n\nTold The Verge it has laid off most of its staff and is no longer selling its smart home controllers and light switches as it looks for a buyer.\n\nEnovix\n\nLaid off roughly 170 workers, impacting a third of its total headcount, in an effort to cut back on annual operating costs.\n\nMicrosoft\n\nClosed Arkane Austin, Tango Gameworks, and more game studios as part of cuts at Bethesda. It\u2019s currently unclear how many employees will be impacted.\n\nCue Health\n\nIs eliminating 230 employees, about 49% of its workforce, in a cost cutting measure laid out in documents filed with the U.S. SEC.\n\nLuminar\n\nIs slashing its workforce by 20%. The cuts will affect around 140 employees, and the company is also cutting ties with \u201cthe majority\u201d of its contract workers.\n\nSprinklr\n\nHas laid off about 3% of its workforce, impacting 116 people, the company confirmed to TechCrunch in a statement. The cuts come over a year after the company eliminated about 4% of its headcount.\n\nPeloton\n\nIs laying off 15% of its workforce, affecting about 400 people, as part of a cost-cutting effort. The company\u2019s CEO Barry McCarthy is also stepping down.\n\nApril 2024\n\nTesla\n\nHas gutted its charging team in a new round of layoffs, CEO Elon Musk announced in an overnight email to executives.\n\nGoogle\n\nHas laid off staff across key teams like Flutter, Dart and Python. It is currently unclear how many employees were let go.\n\nFisker\n\nIs laying off more employees to \u201cpreserve cash,\u201d according to an internal email viewed by TechCrunch. The number of cuts is currently unknown.\n\nGetir\n\nIs shutting down operations in the U.S., the U.K. and Europe, impacting at least 6,000 jobs across the closing markets.\n\nOla\n\nIs cutting about 180 jobs in a profitability push and has let go its chief executive Hemant Bakshi, a source familiar with the matter told TechCrunch.\n\nTrue Anomaly\n\nThe space and defense startup laid off nearly 30 people, accounting for about 25% of its workforce, due to \u201cduplication of roles and functions across the company,\u201d TechCrunch exclusively reported.\n\nExpedia\n\nIs expected to cut employees in its Austin office for the second time this year.\n\nNike\n\nPlans to eliminate 740 employees at its Oregon headquarters this summer, according to a WARN Act notice.\n\nStability AI\n\nIs eliminating 10% of its workforce following the exit of former CEO Emad Mostaque.\n\nGoogle\n\nIs laying off workers as part of continued cost cutting measures. The number of employees affected was at the time unknown.\n\nRivian\n\nIs reducing its total workforce by 1%. It\u2019s the second round of layoffs for the EV maker this year.\n\nTake-Two\n\nIs laying off 5% of its workforce, affecting around 579 employees. The GTA 6 publisher also announced the elimination of \u201cseveral projects\u201d in development.\n\nTome\n\nIs eliminating about 20% of its 59 employees in a restructuring effort.\n\nTesla\n\nIs cutting \u201cmore than 10%\u201d of its global workforce, per an internal email sent by CEO Elon Musk. That could impact more than 14,000 workers worldwide, as Tesla prepares itself \u201cfor our next phase of growth\u201d amid a challenging EV market.\n\nCriteo\n\nIs reducing its global workforce by nearly 4%, impacting up to 140 employees.\n\nTikTok\n\nIs laying off 250 employees based in Ireland as it restructures its Training and Quality team.\n\nHinge Health\n\nCut approximately 10% of its workforce, TechCrunch exclusively learned, as the company prepares for an IPO and aims to reach profitability.\n\nCheckr\n\nHas laid off 382 employees, amounting to 32% of its total workforce, TechCrunch exclusively learned. The background-screening platform was last valued at $5 billion in April of 2022.\n\nBolt.Earth\n\nReportedly laid off a sizable part of its staff in a restructuring effort. The number of employees impacted is currently unknown, but sources told Inc42 that it could be \u201cin the range of 70-100\u201d workers.\n\nApple\n\nIs laying off 614 employees in California after abandoning its electric car project, according to a WARN notice.\n\nAgility Robotics\n\nHas laid off a \u201csmall number\u201d of employees as part of a company-wide focus on commercialization efforts.\n\nGhost Autonomy\n\nShut down operations. The company, which was backed by OpenAI, employed about 100 people.\n\nWhirlpool\n\nIs shutting down Yummly, the recipe and cooking app it acquired in 2017.\n\nAWS\n\nWill cut hundreds of jobs across Sales, Marketing, Global Services and its Physical Stores Technology team.\n\nByju\u2019s\n\nIs laying off about 500 employees, accounting for 3% of its total workforce, as part of a restructuring effort.\n\nMarch 2024\n\nChowNow\n\nHas laid off 20% of its staff after acquiring point-of-sale platform Cuboh. The company previously laid off 100 people in 2022.\n\nNintendo of America\n\nIs restructuring its testing department, which is largely made up of contractors. A Nintendo spokesperson told Kotaku the changes will end some assignments but will lead to the creation of new full-time positions.\n\nDell\n\nCut its global workforce by about 6,000 jobs, according to a 10-K SEC filing. The filing reveals the company cut 13,000 jobs in the last year.\n\nSynctera\n\nHas made cuts to its staff, the company confirmed to TechCrunch. A report in Fintech Business Weekly estimates that 17 people, or about 15% of the company, were impacted.\n\nShopBack\n\nIs cutting 195 roles in an effort to become more sustainable, CEO Henry Chan wrote in a blog post. The layoffs impact nearly a quarter of its staff.\n\nAirmeet\n\nReportedly eliminated 20% of its total workforce in its second restructuring effort in the past year.\n\nChipper Cash\n\nConducted another round of layoffs impacting 20 employees, CEO Ham Serunjogi announced in a blog post.\n\nTextio\n\nHas reportedly cut 16% of its staff in a strategic move to support its Textio Lift product.\n\nStash\n\nIs reportedly laying off around 25% of its workforce. According to Axios, the cuts affect roughly 80 people.\n\nPhantom Auto\n\nIs shutting down after failing to secure new funding, TechCrunch has learned. The remote driving startup, which had cut staff last year, employed a little more than 100 people.\n\nIBM\n\nIs reportedly slashing its marketing and communications staff. The company previously announced a strategy to replace upwards of 8,000 jobs with AI.\n\nInscribe.ai\n\nCut just under 40% of its staff, equating to dozens of employees, the company confirmed to TechCrunch.\n\nTurnitin\n\nLaid off around 15 people earlier this year, following comments from CEO Chris Caren that the company would be able to reduce 20% of its headcount thanks to AI.\n\nSorare\n\nLaid off 13% of its staff based in its New York office as the web3 fantasy sports platform focuses on its Paris headquarters, a source familiar with the matter told TechCrunch.\n\nMelio\n\nIs eliminating roughly 7% of its workforce as part of organizational restructuring. The fintech unicorn last conducted layoffs in August 2022.\n\nONE\n\nIs cutting about 13% of its workforce, affecting 40 employees. It\u2019s the second round of layoffs for the battery startup in recent months.\n\nProject Ronin\n\nIs shutting down, resulting in a \u201cpermanent mass layoff\u201d impacting around 150 employees.\n\nFebruary 2024\n\nFisker\n\nPlans to lay off 15% of its workforce and says it likely does not have enough cash on hand to survive the next 12 months.\n\nEA\n\nCut 5% of its workforce, impacting 670 employees, as it moves away from the \u201cdevelopment of future licensed IP.\u201d\n\nBumble\n\nIs letting go of about 350 employees, accounting for 30% of its workforce.\n\nApple\n\nIs likely cutting hundreds of employees who worked on the company\u2019s autonomous electric car project now that the effort has stopped, TechCrunch has learned.\n\nSony\n\nIs laying off 900 employees from its PlayStation unit, affecting 8% of the division\u2019s workforce. Insomniac Games, Naughty Dog, Guerrilla and Firesprite studios will also be impacted.\n\nExpedia\n\nWill reportedly cut 1,500 roles in 2024, primarily in its Product & Technology division, accounting for more than 8% of the company\u2019s workforce.\n\nFinder\n\nEliminated roughly 60 employees, or 17% of its workforce. It\u2019s the financial startup\u2019s third major layoff round in the past 12 months.\n\nRivian\n\nIs laying off 10% of its salaried workforce in a bid to cut costs in an increasingly tough market for EVs.\n\nMeati Foods\n\nWill lay off 13% of its workforce as it works to \u201cbuild a financially sustainable business,\u201d CEO Phil Graves told TechCrunch exclusively.\n\nCisco\n\nAnnounced it will eliminate 5% of its employees, impacting more than 4,000 people.\n\nToast\n\nWill lay off about 550 workers in a move designed to promote \u201coperating expense efficiency.\u201d\n\nInstacart\n\nAnnounced in an SEC filing that it will lay off roughly 250 employees as part of a restructuring effort.\n\nMozilla\n\nIs scaling back its investment in a number of products, TechCrunch has learned, resulting in layoffs that will affect roughly 60 employees.\n\nGrammarly\n\nIs laying off 230 employees worldwide as part of the company\u2019s efforts to advance its focus on \u201cthe AI-enabled workplace of the future.\u201d\n\nGetaround\n\nIs cutting 30% of its North American workforce as part of a restructuring.\n\nAmazon\n\nIs reportedly cutting jobs in its healthcare businesses One Medical and Amazon Pharmacy. The number of impacted roles is currently unknown.\n\nDocuSign\n\nAnnounced plans to eliminate 6% of its workforce, largely impacting the company\u2019s sales and marketing divisions.\n\nSnap\n\nAnnounced plans to cut 10% of its workforce, impacting roughly 500-plus employees, in an effort to \u201creduce hierarchy.\u201d\n\nPolygon Labs\n\nHas laid off 60 employees, or about 19% of its staff, CEO Marc Boiron announced in a blog post.\n\nOkta\n\nIs laying off approximately 400 employees. The layoffs come almost exactly a year to the day after Okta announced plans to cut about 300 employees.\n\nJanuary 2024\n\nThinx\n\nWill lay off 95 workers in New York City, according to a filing with the New York Department of Labor.\n\nProofpoint\n\nIs laying off about 6% of its global workforce, or 280 employees, the company confirmed to TechCrunch.\n\nWattpad\n\nConducted another round of layoffs earlier this month, amounting to roughly 15% of its workforce, a source familiar with the situation told TechCrunch.\n\nBlock\n\nIs reportedly laying off around 1,000 people in the Cash App, foundational and Square arms of Block.\n\nPayPal\n\nHas reportedly begun company-wide layoffs. While it is unclear how many people will be affected, one source told TechCrunch it was expected to be in the \u201cthousands.\u201d\n\nAurora Solar\n\nHas laid off 20% of its staff of about 1,000 people, TechCrunch exclusively learned. The cuts to the software startup come despite record growth in the solar industry last year.\n\niRobot\n\nIs laying off 350 people, or one-third of its headcount, after Amazon\u2019s bid to acquire the Roomba-maker shuttered. Longtime CEO Colin Angle has also stepped down.\n\nSalesforce\n\nIs reportedly laying off 700 workers, or around 1% of its staff. This comes after the company had a significant reduction of 10% of its workforce in 2023.\n\nFlexport\n\nIs reportedly planning to cut around 20% of its staff in the next few weeks. The company announced similar cuts in October, when founder Ryan Petersen returned as CEO and slashed its workforce by 20%.\n\nMicrosoft\n\nIs laying off 1,900 employees across its gaming divisions following its acquisition of Activision Blizzard. Blizzard president Mike Ybarra announced he will also be stepping down.\n\nSwiggy\n\nIs cutting about 400 jobs, 7% of its workforce, as the food delivery startup seeks to bring further improvements to its finances ahead of a planned IPO later this year.\n\nAurora\n\nLaid off dozens of workers, according to sources familiar with the decision. The autonomous vehicle technology company has since confirmed that about 3% of its workforce has been laid off.\n\neBay\n\nWill lay off 9% of the company\u2019s workforce, affecting about 1,000 full-time employees. In a blog post, the company also plans to cut contract roles in the coming months.\n\nSAP\n\nAnnounced it intends to offer voluntary buyouts or job changes to 8,000 employees amid restructuring.\n\nBrex\n\nLaid off 20% of its staff, affecting 282 workers. In a blog post, Co-CEO Pedro Franceschi said that the company is prioritizing \u201clong-term thinking and ownership over short-term gains in our comp structure.\u201d\n\nTikTok\n\nEliminated around 60 jobs across the U.S. in Los Angeles, New York, and Austin in addition to layoffs in international markets. The affected roles, according to NPR\u2019s initial reporting, are largely in sales and advertising.\n\nVroom\n\nIs cutting 90% of its employees as it shuts down its online used car marketplace and shifts resources into two business units: one focused on auto financing and the other on AI-powered analytics.\n\nRiot Games\n\nIs laying off 11% of its workforce, affecting about 530 employees, as the company focuses on \u201cfewer, high-impact projects.\u201d The League of Legends maker is also sunsetting its five-year-old publishing group, Riot Forge.\n\nWayfair\n\nIs eliminating 13% of its global workforce, affecting 1,650 employees, in a restructuring effort aimed at cutting layers of management.\n\nYouTube\n\nWill eliminate 100 employees, a spokesperson confirmed to TechCrunch, as part of a restructuring effort in its creator management and operations teams.\n\nGoogle\n\nIs laying off \u201chundreds\u201d of employees in its advertising sales team, according to a leaked memo. The cuts come a week after the company did sweeping layoffs across its hardware teams. And more layoffs will come throughout the year, as CEO Sundar Pichai told the company in a memo obtained by the Verge.\n\nLost Boys Interactive\n\nReportedly laid off a \u201csizable\u201d number of employees January 12. The game developer studio was acquired by Borderlands maker Gearbox in 2022.\n\nPixar\n\nIs going to lay off employees in 2024, TechCrunch exclusively learned, with the total impacted employees potentially reaching as high as 20% of the animation studio\u2019s 1,300 person workforce. The cutbacks come as Disney looks to reduce the studio\u2019s output as it struggles to achieve profitability in streaming.\n\nAudible\n\nIs laying off 5% of its workforce, citing an \u201cincreasingly challenging landscape,\u201d according to a leaked memo obtained by Business Insider.\n\nDiscord\n\nIs laying off 17% of its staff, impacting 170 people. In an internal memo obtained by the Verge, Discord CEO Jason Citron blamed the cuts on the company growing too quickly.\n\nGoogle\n\nLaid off hundreds of employees across its Google Assistant division and the team that manages Pixel, Nest and Fitbit hardware. The company confirmed to TechCrunch that Fitbit co-founders James Park and Eric Friedman are also exiting.\n\nAmazon\n\nIs laying off \u201cseveral hundreds\u201d of employees at Prime Video and MGM Studios, according to a memo obtained by TechCrunch. The cuts come days after the 500 layoffs at Amazon\u2019s Twitch.\n\nTwitch\n\nIs reportedly laying off 500 employees, 35% of its current staff, amid a continued struggle to achieve profitability in the face of rising costs and community backlash. The pending layoffs come after hundreds more employees were laid off in 2023.\n\nTreasure Financial\n\nConfirmed to TechCunch that layoffs, conducted in December, had impacted 14 employees, accounting for 60% to 70% of the company, according to multiple sources.\n\nDuolingo\n\nConfirmed it cut 10% of its contractor workforce at the end of 2023 as it turns to AI to streamline content production and translations previously handled by humans.\n\nRent the Runway\n\nWill cut about 10% of corporate roles as it goes through a restructuring plan following Anushka Salinas\u2019 planned resignation as operating chief and president at the end of January.\n\nUnity\n\nIs reducing its workforce by about 25%, or 1,800 people. The video game engine maker went through three rounds of layoffs in 2023.\n\nPitch\n\nLaid off two-thirds of its employees as the German startup, which built collaborative presentation software, looks to pursue a \u201ccompletely different path.\u201d CEO and co-founder Christian Reber also stepped down.\n\nBenchSci\n\nThe AI and biomedical startup reportedly cut 17% of its workforce January 8, citing \u201cshifts in the economic environment,\u201d in a LinkedIn post announcing the layoffs.\n\nFlexe\n\nEliminated 38% of its staff January 8 as the online retail logistics company follows up after conducting layoffs in September 2023.\n\nNuScale\n\nAnnounced January 8 it is laying off 28% of its staff, or 154 workers, as the small modular nuclear reactor company shifts its focus to \u201ckey strategic areas.\u201d\n\nTrigo\n\nIs reportedly laying off 15% of its workforce focused on computer vision for retailers.\n\nInVision\n\nIs shutting down at the end of 2024 after a 12 year run. The design collaboration startup was once valued at nearly $2B.\n\nVideoAmp\n\nIs laying off nearly 20% of its workforce as it tries to maintain its battle with Nielsen over media measurement. CEO Ross McCray stepped down from the company.\n\nOrca Security\n\nIs laying off roughly 15% of its staff, totaling 60 employees. The Israel-based unicorn reportedly plans to move some impacted employees into other positions at the company.\n\nFrontdesk\n\nLaid off its entire 200-person workforce January 2 after attempts to raise more capital failed, TechCrunch exclusively learned. The mass layoff comes just seven months after the startup acquired rival Zencity.",
        "url": "https://techcrunch.com/2024/07/31/tech-layoffs-2024-list/",
        "category": 3,
        "summary": "NuScale\n\nAnnounced January 8 it is laying off 28% of its staff, or 154 workers, as the small modular nuclear reactor company shifts its focus to \u201ckey strategic areas.\u201d\n\nTrigo\n\nIs reportedly laying off 15% of its workforce focused on computer vision for retailers. In a blog post, Co-CEO Pedro Franceschi said that the company is prioritizing \u201clong-term thinking and ownership over short-term gains in our comp structure.\u201d\n\nTikTok\n\nEliminated around 60 jobs across the U.S. in Los Angeles, New York, and Austin in addition to layoffs in international markets. UKG\n\nCut an estimated 2,200 employees, amounting to nearly 14% of its workforce, as the software company attempts to redirect its resources into \u201ckey areas of product innovation.\u201d\n\nOpenText\u200b\u200b\n\nPlans to cut roughly 1,200 jobs, amounting to almost 2% of its total workforce, as the information management company plans to significantly reduce its expenses by 2025."
    },
    {
        "title": "ChatGPT: Everything you need to know about the AI chatbot",
        "text": "ChatGPT, OpenAI\u2019s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to hyper-charge productivity through writing essays and code with short text prompts has evolved into a behemoth used by more than 92% of Fortune 500 companies.\n\nThat growth has propelled OpenAI itself into becoming one of the most-hyped companies in recent memory. And its latest partnership with Apple for its upcoming generative AI offering, Apple Intelligence, has given the company another significant bump in the AI race.\n\n2024 also saw the release of GPT-4o, OpenAI\u2019s new flagship omni model for ChatGPT. GPT-4o is now the default free model, complete with voice and vision capabilities. But after demoing GPT-4o, OpenAI paused one of its voices, Sky, after allegations that it was mimicking Scarlett Johansson\u2019s voice in \u201cHer.\u201d\n\nOpenAI is facing internal drama, including the sizable exit of co-founder and longtime chief scientist Ilya Sutskever as the company dissolved its Superalignment team. OpenAI is also facing a lawsuit from Alden Global Capital-owned newspapers, including the New York Daily News and the Chicago Tribune, for alleged copyright infringement, following a similar suit filed by The New York Times last year.\n\nHere\u2019s a timeline of ChatGPT product updates and releases, starting with the latest, which we\u2019ve been updating throughout the year. And if you have any other questions, check out our ChatGPT FAQ here.\n\nTimeline of the most recent ChatGPT updates\n\nJuly 2024\n\nChatGPT\u2019s advanced Voice Mode starts rolling out to some users\n\nOpenAI is giving users their first access to GPT-4o\u2019s updated realistic audio responses. The alpha version is now available to a small group of ChatGPT Plus users, and the company says the feature will gradually roll out to all Plus users in the fall of 2024. The release follows controversy surrounding the voice\u2019s similarity to Scarlett Johansson, leading OpenAI to delay its release.\n\nWe\u2019re starting to roll out advanced Voice Mode to a small group of ChatGPT Plus users. Advanced Voice Mode offers more natural, real-time conversations, allows you to interrupt anytime, and senses and responds to your emotions. pic.twitter.com/64O94EhhXK \u2014 OpenAI (@OpenAI) July 30, 2024\n\nOpenAI announces new search prototype, SearchGPT\n\nOpenAI is testing SearchGPT, a new AI search experience to compete with Google. SearchGPT aims to elevate search queries with \u201ctimely answers\u201d from across the internet, as well as the ability to ask follow-up questions. The temporary prototype is currently only available to a small group of users and its publisher partners, like The Atlantic, for testing and feedback.\n\nWe\u2019re testing SearchGPT, a temporary prototype of new AI search features that give you fast and timely answers with clear and relevant sources.\n\n\n\nWe\u2019re launching with a small group of users for feedback and plan to integrate the experience into ChatGPT. https://t.co/dRRnxXVlGh pic.twitter.com/iQpADXmllH \u2014 OpenAI (@OpenAI) July 25, 2024\n\nOpenAI could lose $5 billion this year, report claims\n\nA new report from The Information, based on undisclosed financial information, claims OpenAI could lose up to $5 billion due to how costly the business is to operate. The report also says the company could spend as much as $7 billion in 2024 to train and operate ChatGPT.\n\nOpenAI unveils GPT-4o mini\n\nOpenAI released its latest small AI model, GPT-4o mini. The company says GPT-4o mini, which is cheaper and faster than OpenAI\u2019s current AI models, outperforms industry leading small AI models on reasoning tasks involving text and vision. GPT-4o mini will replace GPT-3.5 Turbo as the smallest model OpenAI offers.\n\nOpenAI partners with Los Alamos National Laboratory for bioscience research\n\nOpenAI announced a partnership with the Los Alamos National Laboratory to study how AI can be employed by scientists in order to advance research in healthcare and bioscience. This follows other health-related research collaborations at OpenAI, including Moderna and Color Health.\n\nOpenAI and Los Alamos National Laboratory announce partnership to study AI for bioscience research https://t.co/WV4XMZsHBA \u2014 OpenAI (@OpenAI) July 10, 2024\n\nJune 2024\n\nOpenAI makes CriticGPT to find mistakes in GPT-4\n\nOpenAI announced it has trained a model off of GPT-4, dubbed CriticGPT, which aims to find errors in ChatGPT\u2019s code output so they can make improvements and better help so-called human \u201cAI trainers\u201d rate the quality and accuracy of ChatGPT responses.\n\nWe\u2019ve trained a model, CriticGPT, to catch bugs in GPT-4\u2019s code. We\u2019re starting to integrate such models into our RLHF alignment pipeline to help humans supervise AI on difficult tasks: https://t.co/5oQYfrpVBu \u2014 OpenAI (@OpenAI) June 27, 2024\n\nOpenAI inks content deal with TIME\n\nOpenAI and TIME announced a multi-year strategic partnership that brings the magazine\u2019s content, both modern and archival, to ChatGPT. As part of the deal, TIME will also gain access to OpenAI\u2019s technology in order to develop new audience-based products.\n\nWe\u2019re partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on https://t.co/LgvmZUae9M: https://t.co/xHAYkYLxA9 \u2014 OpenAI (@OpenAI) June 27, 2024\n\nOpenAI delays ChatGPT\u2019s new Voice Mode\n\nOpenAI planned to start rolling out its advanced Voice Mode feature to a small group of ChatGPT Plus users in late June, but it says lingering issues forced it to postpone the launch to July. OpenAI says Advanced Voice Mode might not launch for all ChatGPT Plus customers until the fall, depending on whether it meets certain internal safety and reliability checks.\n\nChatGPT releases app for Mac\n\nChatGPT for macOS is now available for all users. With the app, users can quickly call up ChatGPT by using the keyboard combination of Option + Space. The app allows users to upload files and other photos, as well as speak to ChatGPT from their desktop and search through their past conversations.\n\nThe ChatGPT desktop app for macOS is now available for all users.\n\n\n\nGet faster access to ChatGPT to chat about email, screenshots, and anything on your screen with the Option + Space shortcut: https://t.co/2rEx3PmMqg pic.twitter.com/x9sT8AnjDm \u2014 OpenAI (@OpenAI) June 25, 2024\n\nApple brings ChatGPT to its apps, including Siri\n\nApple announced at WWDC 2024 that it is bringing ChatGPT to Siri and other first-party apps and capabilities across its operating systems. The ChatGPT integrations, powered by GPT-4o, will arrive on iOS 18, iPadOS 18 and macOS Sequoia later this year, and will be free without the need to create a ChatGPT or OpenAI account. Features exclusive to paying ChatGPT users will also be available through Apple devices.\n\nApple is bringing ChatGPT to Siri and other first-party apps and capabilities across its operating systems #WWDC24\n\n\n\nRead more: https://t.co/0NJipSNJoS pic.twitter.com/EjQdPBuyy4 \u2014 TechCrunch (@TechCrunch) June 10, 2024\n\nHouse Oversight subcommittee invites Scarlett Johansson to testify about \u2018Sky\u2019 controversy\n\nScarlett Johansson has been invited to testify about the controversy surrounding OpenAI\u2019s Sky voice at a hearing for the House Oversight Subcommittee on Cybersecurity, Information Technology, and Government Innovation. In a letter, Rep. Nancy Mace said Johansson\u2019s testimony could \u201cprovide a platform\u201d for concerns around deepfakes.\n\nChatGPT experiences two outages in a single day\n\nChatGPT was down twice in one day: one multi-hour outage in the early hours of the morning Tuesday and another outage later in the day that is still ongoing. Anthropic\u2019s Claude and Perplexity also experienced some issues.\n\nYou're not alone, ChatGPT is down once again. pic.twitter.com/Ydk2vNOOK6 \u2014 TechCrunch (@TechCrunch) June 4, 2024\n\nMay 2024\n\nThe Atlantic and Vox Media ink content deals with OpenAI\n\nThe Atlantic and Vox Media have announced licensing and product partnerships with OpenAI. Both agreements allow OpenAI to use the publishers\u2019 current content to generate responses in ChatGPT, which will feature citations to relevant articles. Vox Media says it will use OpenAI\u2019s technology to build \u201caudience-facing and internal applications,\u201d while The Atlantic will build a new experimental product called Atlantic Labs.\n\nI am delighted that @theatlantic now has a strategic content & product partnership with @openai. Our stories will be discoverable in their new products and we'll be working with them to figure out new ways that AI can help serious, independent media : https://t.co/nfSVXW9KpB \u2014 nxthompson (@nxthompson) May 29, 2024\n\nOpenAI signs 100K PwC workers to ChatGPT\u2019s enterprise tier\n\nOpenAI announced a new deal with management consulting giant PwC. The company will become OpenAI\u2019s biggest customer to date, covering 100,000 users, and will become OpenAI\u2019s first partner for selling its enterprise offerings to other businesses.\n\nOpenAI says it is training its GPT-4 successor\n\nOpenAI announced in a blog post that it has recently begun training its next flagship model to succeed GPT-4. The news came in an announcement of its new safety and security committee, which is responsible for informing safety and security decisions across OpenAI\u2019s products.\n\nFormer OpenAI director claims the board found out about ChatGPT on Twitter\n\nOn the The TED AI Show podcast, former OpenAI board member Helen Toner revealed that the board did not know about ChatGPT until its launch in November 2022. Toner also said that Sam Altman gave the board inaccurate information about the safety processes the company had in place and that he didn\u2019t disclose his involvement in the OpenAI Startup Fund.\n\nSharing this, recorded a few weeks ago. Most of the episode is about AI policy more broadly, but this was my first longform interview since the OpenAI investigation closed, so we also talked a bit about November.\n\n\n\nThanks to @bilawalsidhu for a fun conversation! https://t.co/h0PtK06T0K \u2014 Helen Toner (@hlntnr) May 28, 2024\n\nChatGPT\u2019s mobile app revenue saw biggest spike yet following GPT-4o launch\n\nThe launch of GPT-4o has driven the company\u2019s biggest-ever spike in revenue on mobile, despite the model being freely available on the web. Mobile users are being pushed to upgrade to its $19.99 monthly subscription, ChatGPT Plus, if they want to experiment with OpenAI\u2019s most recent launch.\n\nOpenAI to remove ChatGPT\u2019s Scarlett Johansson-like voice\n\nAfter demoing its new GPT-4o model last week, OpenAI announced it is pausing one of its voices, Sky, after users found that it sounded similar to Scarlett Johansson in \u201cHer.\u201d\n\nOpenAI explained in a blog post that Sky\u2019s voice is \u201cnot an imitation\u201d of the actress and that AI voices should not intentionally mimic the voice of a celebrity. The blog post went on to explain how the company chose its voices: Breeze, Cove, Ember, Juniper and Sky.\n\nWe\u2019ve heard questions about how we chose the voices in ChatGPT, especially Sky. We are working to pause the use of Sky while we address them.\n\n\n\nRead more about how we chose these voices: https://t.co/R8wwZjU36L \u2014 OpenAI (@OpenAI) May 20, 2024\n\nChatGPT lets you add files from Google Drive and Microsoft OneDrive\n\nOpenAI announced new updates for easier data analysis within ChatGPT. Users can now upload files directly from Google Drive and Microsoft OneDrive, interact with tables and charts, and export customized charts for presentations. The company says these improvements will be added to GPT-4o in the coming weeks.\n\nWe're rolling out interactive tables and charts along with the ability to add files directly from Google Drive and Microsoft OneDrive into ChatGPT. Available to ChatGPT Plus, Team, and Enterprise users over the coming weeks. https://t.co/Fu2bgMChXt pic.twitter.com/M9AHLx5BKr \u2014 OpenAI (@OpenAI) May 16, 2024\n\nOpenAI inks deal to train AI on Reddit data\n\nOpenAI announced a partnership with Reddit that will give the company access to \u201creal-time, structured and unique content\u201d from the social network. Content from Reddit will be incorporated into ChatGPT, and the companies will work together to bring new AI-powered features to Reddit users and moderators.\n\nWe\u2019re partnering with Reddit to bring its content to ChatGPT and new products: https://t.co/xHgBZ8ptOE \u2014 OpenAI (@OpenAI) May 16, 2024\n\nOpenAI debuts GPT-4o \u201comni\u201d model now powering ChatGPT\n\nOpenAI\u2019s spring update event saw the reveal of its new omni model, GPT-4o, which has a black hole-like interface, as well as voice and vision capabilities that feel eerily like something out of \u201cHer.\u201d GPT-4o is set to roll out \u201citeratively\u201d across its developer and consumer-facing products over the next few weeks.\n\nOpenAI demos real-time language translation with its latest GPT-4o model. pic.twitter.com/pXtHQ9mKGc \u2014 TechCrunch (@TechCrunch) May 13, 2024\n\nOpenAI to build a tool that lets content creators opt out of AI training\n\nThe company announced it\u2019s building a tool, Media Manager, that will allow creators to better control how their content is being used to train generative AI models \u2014 and give them an option to opt out. The goal is to have the new tool in place and ready to use by 2025.\n\nOpenAI explores allowing AI porn\n\nIn a new peek behind the curtain of its AI\u2019s secret instructions, OpenAI also released a new NSFW policy. Though it\u2019s intended to start a conversation about how it might allow explicit images and text in its AI products, it raises questions about whether OpenAI \u2014 or any generative AI vendor \u2014 can be trusted to handle sensitive content ethically.\n\nOpenAI and Stack Overflow announce partnership\n\nIn a new partnership, OpenAI will get access to developer platform Stack Overflow\u2019s API and will get feedback from developers to improve the performance of their AI models. In return, OpenAI will include attributions to Stack Overflow in ChatGPT. However, the deal was not favorable to some Stack Overflow users \u2014 leading to some sabotaging their answer in protest.\n\nApril 2024\n\nU.S. newspapers file copyright lawsuit against OpenAI and Microsoft\n\nAlden Global Capital-owned newspapers, including the New York Daily News, the Chicago Tribune, and the Denver Post, are suing OpenAI and Microsoft for copyright infringement. The lawsuit alleges that the companies stole millions of copyrighted articles \u201cwithout permission and without payment\u201d to bolster ChatGPT and Copilot.\n\nOpenAI inks content licensing deal with Financial Times\n\nOpenAI has partnered with another news publisher in Europe, London\u2019s Financial Times, that the company will be paying for content access. \u201cThrough the partnership, ChatGPT users will be able to see select attributed summaries, quotes and rich links to FT journalism in response to relevant queries,\u201d the FT wrote in a press release.\n\nOpenAI opens Tokyo hub, adds GPT-4 model optimized for Japanese\n\nOpenAI is opening a new office in Tokyo and has plans for a GPT-4 model optimized specifically for the Japanese language. The move underscores how OpenAI will likely need to localize its technology to different languages as it expands.\n\nSam Altman pitches ChatGPT Enterprise to Fortune 500 companies\n\nAccording to Reuters, OpenAI\u2019s Sam Altman hosted hundreds of executives from Fortune 500 companies across several cities in April, pitching versions of its AI services intended for corporate use.\n\nOpenAI releases \u201cmore direct, less verbose\u201d version of GPT-4 Turbo\n\nPremium ChatGPT users \u2014 customers paying for ChatGPT Plus, Team or Enterprise \u2014 can now use an updated and enhanced version of GPT-4 Turbo. The new model brings with it improvements in writing, math, logical reasoning and coding, OpenAI claims, as well as a more up-to-date knowledge base.\n\nOur new GPT-4 Turbo is now available to paid ChatGPT users. We\u2019ve improved capabilities in writing, math, logical reasoning, and coding.\n\nSource: https://t.co/fjoXDCOnPr pic.twitter.com/I4fg4aDq1T \u2014 OpenAI (@OpenAI) April 12, 2024\n\nChatGPT no longer requires an account \u2014 but there\u2019s a catch\n\nYou can now use ChatGPT without signing up for an account, but it won\u2019t be quite the same experience. You won\u2019t be able to save or share chats, use custom instructions, or other features associated with a persistent account. This version of ChatGPT will have \u201cslightly more restrictive content policies,\u201d according to OpenAI. When TechCrunch asked for more details, however, the response was unclear:\n\n\u201cThe signed out experience will benefit from the existing safety mitigations that are already built into the model, such as refusing to generate harmful content. In addition to these existing mitigations, we are also implementing additional safeguards specifically designed to address other forms of content that may be inappropriate for a signed out experience,\u201d a spokesperson said.\n\nMarch 2024\n\nOpenAI\u2019s chatbot store is filling up with spam\n\nTechCrunch found that the OpenAI\u2019s GPT Store is flooded with bizarre, potentially copyright-infringing GPTs. A cursory search pulls up GPTs that claim to generate art in the style of Disney and Marvel properties, but serve as little more than funnels to third-party paid services and advertise themselves as being able to bypass AI content detection tools.\n\nThe New York Times responds to OpenAI\u2019s claims that it \u201chacked\u201d ChatGPT for its copyright lawsuit\n\nIn a court filing opposing OpenAI\u2019s motion to dismiss The New York Times\u2019 lawsuit alleging copyright infringement, the newspaper asserted that \u201cOpenAI\u2019s attention-grabbing claim that The Times \u2018hacked\u2019 its products is as irrelevant as it is false.\u201d The New York Times also claimed that some users of ChatGPT used the tool to bypass its paywalls.\n\nOpenAI VP doesn\u2019t say whether artists should be paid for training data\n\nAt a SXSW 2024 panel, Peter Deng, OpenAI\u2019s VP of consumer product dodged a question on whether artists whose work was used to train generative AI models should be compensated. While OpenAI lets artists \u201copt out\u201d of and remove their work from the datasets that the company uses to train its image-generating models, some artists have described the tool as onerous.\n\nA new report estimates that ChatGPT uses more than half a million kilowatt-hours of electricity per day\n\nChatGPT\u2019s environmental impact appears to be massive. According to a report from The New Yorker, ChatGPT uses an estimated 17,000 times the amount of electricity than the average U.S. household to respond to roughly 200 million requests each day.\n\nChatGPT can now read its answers aloud\n\nOpenAI released a new Read Aloud feature for the web version of ChatGPT as well as the iOS and Android apps. The feature allows ChatGPT to read its responses to queries in one of five voice options and can speak 37 languages, according to the company. Read aloud is available on both GPT-4 and GPT-3.5 models.\n\nChatGPT can now read responses to you. On iOS or Android, tap and hold the message and then tap \u201cRead Aloud\u201d. We\u2019ve also started rolling on web \u2013 click the \"Read Aloud\" button below the message. pic.twitter.com/KevIkgAFbG \u2014 OpenAI (@OpenAI) March 4, 2024\n\nFebruary 2024\n\nOpenAI partners with Dublin City Council to use GPT-4 for tourism\n\nAs part of a new partnership with OpenAI, the Dublin City Council will use GPT-4 to craft personalized itineraries for travelers, including recommendations of unique and cultural destinations, in an effort to support tourism across Europe.\n\nA law firm used ChatGPT to justify a six-figure bill for legal services\n\nNew York-based law firm Cuddy Law was criticized by a judge for using ChatGPT to calculate their hourly billing rate. The firm submitted a $113,500 bill to the court, which was then halved by District Judge Paul Engelmayer, who called the figure \u201cwell above\u201d reasonable demands.\n\nChatGPT experienced a bizarre bug for several hours\n\nChatGPT users found that ChatGPT was giving nonsensical answers for several hours, prompting OpenAI to investigate the issue. Incidents varied from repetitive phrases to confusing and incorrect answers to queries. The issue was resolved by OpenAI the following morning.\n\nMatch Group announced deal with OpenAI with a press release co-written by ChatGPT\n\nThe dating app giant home to Tinder, Match and OkCupid announced an enterprise agreement with OpenAI in an enthusiastic press release written with the help of ChatGPT. The AI tech will be used to help employees with work-related tasks and come as part of Match\u2019s $20 million-plus bet on AI in 2024.\n\nChatGPT will now remember \u2014 and forget \u2014 things you tell it to\n\nAs part of a test, OpenAI began rolling out new \u201cmemory\u201d controls for a small portion of ChatGPT free and paid users, with a broader rollout to follow. The controls let you tell ChatGPT explicitly to remember something, see what it remembers or turn off its memory altogether. Note that deleting a chat from chat history won\u2019t erase ChatGPT\u2019s or a custom GPT\u2019s memories \u2014 you must delete the memory itself.\n\nWe\u2019re testing ChatGPT's ability to remember things you discuss to make future chats more helpful. This feature is being rolled out to a small portion of Free and Plus users, and it's easy to turn on or off. https://t.co/1Tv355oa7V pic.twitter.com/BsFinBSTbs \u2014 OpenAI (@OpenAI) February 13, 2024\n\nOpenAI begins rolling out \u201cTemporary Chat\u201d feature\n\nInitially limited to a small subset of free and subscription users, Temporary Chat lets you have a dialogue with a blank slate. With Temporary Chat, ChatGPT won\u2019t be aware of previous conversations or access memories but will follow custom instructions if they\u2019re enabled.\n\nBut, OpenAI says it may keep a copy of Temporary Chat conversations for up to 30 days for \u201csafety reasons.\u201d\n\nUse temporary chat for conversations in which you don\u2019t want to use memory or appear in history. pic.twitter.com/H1U82zoXyC \u2014 OpenAI (@OpenAI) February 13, 2024\n\nJanuary 2024\n\nChatGPT users can now invoke GPTs directly in chats\n\nPaid users of ChatGPT can now bring GPTs into a conversation by typing \u201c@\u201d and selecting a GPT from the list. The chosen GPT will have an understanding of the full conversation, and different GPTs can be \u201ctagged in\u201d for different use cases and needs.\n\nYou can now bring GPTs into any conversation in ChatGPT \u2013 simply type @ and select the GPT. This allows you to add relevant GPTs with the full context of the conversation. pic.twitter.com/Pjn5uIy9NF \u2014 OpenAI (@OpenAI) January 30, 2024\n\nChatGPT is reportedly leaking usernames and passwords from users\u2019 private conversations\n\nScreenshots provided to Ars Technica found that ChatGPT is potentially leaking unpublished research papers, login credentials and private information from its users. An OpenAI representative told Ars Technica that the company was investigating the report.\n\nChatGPT is violating Europe\u2019s privacy laws, Italian DPA tells OpenAI\n\nOpenAI has been told it\u2019s suspected of violating European Union privacy, following a multi-month investigation of ChatGPT by Italy\u2019s data protection authority. Details of the draft findings haven\u2019t been disclosed, but in a response, OpenAI said: \u201cWe want our AI to learn about the world, not about private individuals.\u201d\n\nOpenAI partners with Common Sense Media to collaborate on AI guidelines\n\nIn an effort to win the trust of parents and policymakers, OpenAI announced it\u2019s partnering with Common Sense Media to collaborate on AI guidelines and education materials for parents, educators and young adults. The organization works to identify and minimize tech harms to young people and previously flagged ChatGPT as lacking in transparency and privacy.\n\nOpenAI responds to Congressional Black Caucus about lack of diversity on its board\n\nAfter a letter from the Congressional Black Caucus questioned the lack of diversity in OpenAI\u2019s board, the company responded. The response, signed by CEO Sam Altman and Chairman of the Board Bret Taylor, said building a complete and diverse board was one of the company\u2019s top priorities and that it was working with an executive search firm to assist it in finding talent.\n\nOpenAI drops prices and fixes \u2018lazy\u2019 GPT-4 that refused to work\n\nIn a blog post, OpenAI announced price drops for GPT-3.5\u2019s API, with input prices dropping to 50% and output by 25%, to $0.0005 per thousand tokens in, and $0.0015 per thousand tokens out. GPT-4 Turbo also got a new preview model for API use, which includes an interesting fix that aims to reduce \u201claziness\u201d that users have experienced.\n\nExpanding the platform for @OpenAIDevs: new generation of embedding models, updated GPT-4 Turbo, and lower pricing on GPT-3.5 Turbo. https://t.co/7wzCLwB1ax \u2014 OpenAI (@OpenAI) January 25, 2024\n\nOpenAI bans developer of a bot impersonating a presidential candidate\n\nOpenAI has suspended AI startup Delphi, which developed a bot impersonating Rep. Dean Phillips (D-Minn.) to help bolster his presidential campaign. The ban comes just weeks after OpenAI published a plan to combat election misinformation, which listed \u201cchatbots impersonating candidates\u201d as against its policy.\n\nOpenAI announces partnership with Arizona State University\n\nBeginning in February, Arizona State University will have full access to ChatGPT\u2019s Enterprise tier, which the university plans to use to build a personalized AI tutor, develop AI avatars, bolster their prompt engineering course and more. It marks OpenAI\u2019s first partnership with a higher education institution.\n\nWinner of a literary prize reveals around 5% her novel was written by ChatGPT\n\nAfter receiving the prestigious Akutagawa Prize for her novel The Tokyo Tower of Sympathy, author Rie Kudan admitted that around 5% of the book quoted ChatGPT-generated sentences \u201cverbatim.\u201d Interestingly enough, the novel revolves around a futuristic world with a pervasive presence of AI.\n\nSam Altman teases video capabilities for ChatGPT and the release of GPT-5\n\nIn a conversation with Bill Gates on the Unconfuse Me podcast, Sam Altman confirmed an upcoming release of GPT-5 that will be \u201cfully multimodal with speech, image, code, and video support.\u201d Altman said users can expect to see GPT-5 drop sometime in 2024.\n\nOpenAI announces team to build \u2018crowdsourced\u2019 governance ideas into its models\n\nOpenAI is forming a Collective Alignment team of researchers and engineers to create a system for collecting and \u201cencoding\u201d public input on its models\u2019 behaviors into OpenAI products and services. This comes as a part of OpenAI\u2019s public program to award grants to fund experiments in setting up a \u201cdemocratic process\u201d for determining the rules AI systems follow.\n\nOpenAI unveils plan to combat election misinformation\n\nIn a blog post, OpenAI announced users will not be allowed to build applications for political campaigning and lobbying until the company works out how effective their tools are for \u201cpersonalized persuasion.\u201d\n\nUsers will also be banned from creating chatbots that impersonate candidates or government institutions, and from using OpenAI tools to misrepresent the voting process or otherwise discourage voting.\n\nThe company is also testing out a tool that detects DALL-E generated images and will incorporate access to real-time news, with attribution, in ChatGPT.\n\nSnapshot of how we\u2019re preparing for 2024\u2019s worldwide elections: \u2022 Working to prevent abuse, including misleading deepfakes\n\n\u2022 Providing transparency on AI-generated content\n\n\u2022 Improving access to authoritative voting informationhttps://t.co/qsysYy5l0L \u2014 OpenAI (@OpenAI) January 15, 2024\n\nOpenAI changes policy to allow military applications\n\nIn an unannounced update to its usage policy, OpenAI removed language previously prohibiting the use of its products for the purposes of \u201cmilitary and warfare.\u201d In an additional statement, OpenAI confirmed that the language was changed in order to accommodate military customers and projects that do not violate their ban on efforts to use their tools to \u201charm people, develop weapons, for communications surveillance, or to injure others or destroy property.\u201d\n\nChatGPT subscription aimed at small teams debuts\n\nAptly called ChatGPT Team, the new plan provides a dedicated workspace for teams of up to 149 people using ChatGPT as well as admin tools for team management. In addition to gaining access to GPT-4, GPT-4 with Vision and DALL-E3, ChatGPT Team lets teams build and share GPTs for their business needs.\n\nOpenAI\u2019s GPT store officially launches\n\nAfter some back and forth over the last few months, OpenAI\u2019s GPT Store is finally here. The feature lives in a new tab in the ChatGPT web client, and includes a range of GPTs developed both by OpenAI\u2019s partners and the wider dev community.\n\nTo access the GPT Store, users must be subscribed to one of OpenAI\u2019s premium ChatGPT plans \u2014 ChatGPT Plus, ChatGPT Enterprise or the newly launched ChatGPT Team.\n\nthe GPT store is live!https://t.co/AKg1mjlvo2 fun speculation last night about which GPTs will be doing the best by the end of today. \u2014 Sam Altman (@sama) January 10, 2024\n\nDeveloping AI models would be \u201cimpossible\u201d without copyrighted materials, OpenAI claims\n\nFollowing a proposed ban on using news publications and books to train AI chatbots in the U.K., OpenAI submitted a plea to the House of Lords communications and digital committee. OpenAI argued that it would be \u201cimpossible\u201d to train AI models without using copyrighted materials, and that they believe copyright law \u201cdoes not forbid training.\u201d\n\nOpenAI claims The New York Times\u2019 copyright lawsuit is without merit\n\nOpenAI published a public response to The New York Times\u2019s lawsuit against them and Microsoft for allegedly violating copyright law, claiming that the case is without merit.\n\nIn the response, OpenAI reiterates its view that training AI models using publicly available data from the web is fair use. It also makes the case that regurgitation is less likely to occur with training data from a single source and places the onus on users to \u201cact responsibly.\u201d\n\nWe build AI to empower people, including journalists. Our position on the @nytimes lawsuit:\n\n\u2022 Training is fair use, but we provide an opt-out\n\n\u2022 \"Regurgitation\" is a rare bug we're driving to zero\n\n\u2022 The New York Times is not telling the full storyhttps://t.co/S6fSaDsfKb \u2014 OpenAI (@OpenAI) January 8, 2024\n\nOpenAI\u2019s app store for GPTs planned to launch next week\n\nAfter being delayed in December, OpenAI plans to launch its GPT Store sometime in the coming week, according to an email viewed by TechCrunch. OpenAI says developers building GPTs will have to review the company\u2019s updated usage policies and GPT brand guidelines to ensure their GPTs are compliant before they\u2019re eligible for listing in the GPT Store. OpenAI\u2019s update notably didn\u2019t include any information on the expected monetization opportunities for developers listing their apps on the storefront.\n\nGPT Store launching next week \u2013 OpenAI pic.twitter.com/I6mkZKtgZG \u2014 Manish Singh (@refsrc) January 4, 2024\n\nOpenAI moves to shrink regulatory risk in EU around data privacy\n\nIn an email, OpenAI detailed an incoming update to its terms, including changing the OpenAI entity providing services to EEA and Swiss residents to OpenAI Ireland Limited. The move appears to be intended to shrink its regulatory risk in the European Union, where the company has been under scrutiny over ChatGPT\u2019s impact on people\u2019s privacy.\n\nFAQs:\n\nWhat is ChatGPT? How does it work?\n\nChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.\n\nWhen did ChatGPT get released?\n\nNovember 30, 2022 is when ChatGPT was released for public use.\n\nWhat is the latest version of ChatGPT?\n\nBoth the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.\n\nCan I use ChatGPT for free?\n\nThere is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.\n\nWho uses ChatGPT?\n\nAnyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.\n\nWhat companies use ChatGPT?\n\nMultiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.\n\nMost recently, Microsoft announced at it\u2019s 2023 Build conference that it is integrating it ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT. And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.\n\nWhat does GPT mean in ChatGPT?\n\nGPT stands for Generative Pre-Trained Transformer.\n\nWhat is the difference between ChatGPT and a chatbot?\n\nA chatbot can be any software/system that holds dialogue with you/a person but doesn\u2019t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they\u2019ll give canned responses to questions.\n\nChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.\n\nCan ChatGPT write essays?\n\nYes.\n\nCan ChatGPT commit libel?\n\nDue to the nature of how these models work, they don\u2019t know or care whether something is true, only that it looks true. That\u2019s a problem when you\u2019re using it to do your homework, sure, but when it accuses you of a crime you didn\u2019t commit, that may well at this point be libel.\n\nWe will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.\n\nDoes ChatGPT have an app?\n\nYes, there is a free ChatGPT mobile app for iOS and Android users.\n\nWhat is the ChatGPT character limit?\n\nIt\u2019s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.\n\nDoes ChatGPT have an API?\n\nYes, it was released March 1, 2023.\n\nWhat are some sample everyday uses for ChatGPT?\n\nEveryday examples include programing, scripts, email replies, listicles, blog ideas, summarization, etc.\n\nWhat are some advanced uses for ChatGPT?\n\nAdvanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.\n\nHow good is ChatGPT at writing code?\n\nIt depends on the nature of the program. While ChatGPT can write workable Python code, it can\u2019t necessarily program an entire app\u2019s worth of code. That\u2019s because ChatGPT lacks context awareness \u2014 in other words, the generated code isn\u2019t always appropriate for the specific context in which it\u2019s being used.\n\nCan you save a ChatGPT chat?\n\nYes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.\n\nAre there alternatives to ChatGPT?\n\nYes. There are multiple AI-powered chatbot competitors such as Together, Google\u2019s Gemini and Anthropic\u2019s Claude, and developers are creating open source alternatives.\n\nHow does ChatGPT handle data privacy?\n\nOpenAI has said that individuals in \u201ccertain jurisdictions\u201d (such as the EU) can object to the processing of their personal information by its AI models by filling out this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression \u201cin accordance with applicable laws\u201d.\n\nThe web form for making a deletion of data about you request is entitled \u201cOpenAI Personal Data Removal Request\u201d.\n\nIn its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on \u201clegitimate interest\u201d (LI), pointing users towards more information about requesting an opt out \u2014 when it writes: \u201cSee here for instructions on how you can opt out of our use of your information to train our models.\u201d\n\nWhat controversies have surrounded ChatGPT?\n\nRecently, Discord announced that it had integrated OpenAI\u2019s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.\n\nAn Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT\u2019s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.\n\nCNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.\n\nSeveral major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.\n\nThere have also been cases of ChatGPT accusing individuals of false crimes.\n\nWhere can I find examples of ChatGPT prompts?\n\nSeveral marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.\n\nCan ChatGPT be detected?\n\nPoorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they\u2019re inconsistent at best.\n\nAre ChatGPT chats public?\n\nNo. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users\u2019 conversations to other people on the service.\n\nWhat lawsuits are there surrounding ChatGPT?\n\nNone specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.\n\nAre there issues regarding plagiarism with ChatGPT?\n\nYes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.",
        "url": "https://techcrunch.com/2024/07/31/chatgpt-everything-to-know-about-the-ai-chatbot/",
        "category": 0,
        "summary": "We\u2019re partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on https://t.co/LgvmZUae9M: https://t.co/xHAYkYLxA9 \u2014 OpenAI (@OpenAI) June 27, 2024\n\nOpenAI delays ChatGPT\u2019s new Voice Mode\n\nOpenAI planned to start rolling out its advanced Voice Mode feature to a small group of ChatGPT Plus users in late June, but it says lingering issues forced it to postpone the launch to July. OpenAI and Los Alamos National Laboratory announce partnership to study AI for bioscience research https://t.co/WV4XMZsHBA \u2014 OpenAI (@OpenAI) July 10, 2024\n\nJune 2024\n\nOpenAI makes CriticGPT to find mistakes in GPT-4\n\nOpenAI announced it has trained a model off of GPT-4, dubbed CriticGPT, which aims to find errors in ChatGPT\u2019s code output so they can make improvements and better help so-called human \u201cAI trainers\u201d rate the quality and accuracy of ChatGPT responses. Snapshot of how we\u2019re preparing for 2024\u2019s worldwide elections: \u2022 Working to prevent abuse, including misleading deepfakes\n\n\u2022 Providing transparency on AI-generated content\n\n\u2022 Improving access to authoritative voting informationhttps://t.co/qsysYy5l0L \u2014 OpenAI (@OpenAI) January 15, 2024\n\nOpenAI changes policy to allow military applications\n\nIn an unannounced update to its usage policy, OpenAI removed language previously prohibiting the use of its products for the purposes of \u201cmilitary and warfare.\u201d In an additional statement, OpenAI confirmed that the language was changed in order to accommodate military customers and projects that do not violate their ban on efforts to use their tools to \u201charm people, develop weapons, for communications surveillance, or to injure others or destroy property.\u201d\n\nChatGPT subscription aimed at small teams debuts\n\nAptly called ChatGPT Team, the new plan provides a dedicated workspace for teams of up to 149 people using ChatGPT as well as admin tools for team management."
    },
    {
        "title": "How TripleTen bootcamps successfully empower career changes",
        "text": "Change is an inevitable part of any profession. It\u2019s normal to switch jobs every few years\u2014Americans hold an average of 12 jobs across their lifetime\u2014because changing roles is the fastest way for a worker to progress their career and earn higher wages.\n\nBut what about a brand-new career change? For many, that can seem more daunting than just finding a new job, especially if you\u2019ve spent your entire career in one industry, honing a specific set of skills. Fortunately, it\u2019s getting easier to make the leap. In fact, labor experts believe that career pivots will only become more prevalent as people seek new opportunities for growth.\n\nAmong the various sectors that offer promising prospects for career changers, the tech industry stands out for its competitive wages and benefits. Yet tech employers are currently contending with a shortage of skilled talent. Over the next decade, the tech workforce could grow at twice the rate of the overall U.S. workforce, but by 2030, more than 85 million jobs could remain unfilled because there aren\u2019t enough qualified employees to be hired for them. Recruiting talent might be one of the biggest ongoing problems for tech employers, but for career changers, the lack of skilled workers is an opportunity to upskill and pivot into high-demand roles.\n\nWhy skills from TripleTen bootcamps matter more than degrees\n\nWhat matters to hiring managers isn\u2019t whether candidates have a degree, but whether they have the hard and soft skills to succeed in the role. An overwhelming majority of employers (87%) are open to hiring candidates from non-STEM backgrounds for tech-focused roles, according to a survey from TripleTen, the online, part-time bootcamp designed to help students begin careers in tech. This sentiment holds true across various industries, from transportation to hospitality to healthcare: For employers in the IT/tech industry, a majority are either confident (44%) or very confident (49%) in recruiting bootcamp graduates.\n\nIn other words, you don\u2019t always need a bachelor\u2019s or a master\u2019s degree to get a tech job in today\u2019s market. A bootcamp background, coupled with a strong portfolio, is sufficient evidence that a candidate has the knowledge to be a suitable hire\u2014as long as the bootcamp is designed to teach the right hard and soft skills.\n\n\u201cWhat differentiates TripleTen bootcamps from others is that we\u2019re constantly having conversations with employers in our network to figure out what hard skills are in demand,\u201d said Jordan van Leesten, Employer Partnerships Manager at TripleTen. \u201cBut there is just as much of an emphasis on the soft skills, such as teamwork, communication, and time management, as there is on a hard skill like coding.\u201d\n\nTripleTen offers skills-specific programs in software engineering, data science, business intelligence analytics, quality assurance, and most recently, cybersecurity\u2014areas of expertise that employers are actively hiring for. According to TripleTen\u2019s employer survey, the most sought-after professionals in the industry are data analysts and web developers, followed by software engineers. TripleTen bootcamps provide the valuable skills that more effectively empower career changes into these fields.\n\nTripleTen will be launching a cybersecurity program on September 26 to address the increasing demand for skilled security analysts. In addition to being one of the fastest-growing jobs in the country, the prevalence of corporate cyberattacks across various industries highlights the need for these roles. To ensure graduates will have industry-ready skills, TripleTen engaged subject matter experts with almost 70 years of cyber security experience ranging from government, private, and educational contexts in roles from entry-level to CISO.\n\nTripleTen\u2019s bootcamp programs are beginner-friendly and can range anywhere from five to ten months. The coursework is split into two- or three-week-long \u201csprints\u201d for students to dive deep into technical topics. Throughout, they are paired with tutors, experienced engineers and data analysts currently working in those roles, who give them feedback on their work.\n\nHow hands-on experience is a metric for expertise\n\n\u201cWe really hone our program to make sure that each student can emerge as a top candidate during the hiring process,\u201d van Leesten said. \u201cThe course design simulates real working environments. At the end of the day, we want students to have a strong portfolio to demonstrate the depth of their knowledge.\u201d\n\nAbout 80% of TripleTen students don\u2019t have any tech experience: They enter as healthcare workers, school teachers, service industry professionals, lab techs, or administrators. Graduates also qualify for a money-back guarantee if they don\u2019t secure a job within their field of study within those first six months\u2014a \u201csecurity blanket,\u201d as van Leesten put it, for their career pivot. As programs are offered on a part-time basis, students don\u2019t have to quit their existing jobs.\n\nSome of TripleTen\u2019s graduates even return to a similar field of work, albeit in a higher-paying, more tech-focused role. Take Evgeniia Unzhakova, who used to be a math teacher in Russia. After immigrating to the US in 2019 with her family, she knew she couldn\u2019t keep teaching and decided to seek out an alternate career path. Unzhakova enrolled into TripleTen\u2019s data science program in 2021. After graduating, Unzhakova returned to education as a research analyst at the University of North Carolina at Chapel Hill, where she\u2019s applying her data skills to increase enrollment for the college.\n\nCentral to TripleTen\u2019s curriculum is the opportunity for students to build their portfolio and get work experience while they are studying. Every graduate has the opportunity to work on at least one externship with companies in TripleTen\u2019s network. \u201cWe\u2019re aware that our students want a career switch to be quick and cost-effective,\u201d said van Leesten. \u201cAnd key to that is experiential learning\u2014the ability to work with career coaches and externship managers to determine the scope of a real-world project.\u201d\n\nRecent students from TripleTen\u2019s data science program, for example, spent five weeks developing and training machine learning models for DataSpeak, using the Python Questions from Stack Overflow dataset to generate prompt answers based on user queries. Others from the software engineering cohort were tasked with creating a support widget for edTonomy\u2019s mobile app, adding elements to allow for customer feedback.\n\n\u201cWe see a lot of value in partnering with small and medium-sized businesses,\u201d said van Leesten. \u201cAnd that\u2019s often where students secure their first jobs, before eyeing a move into Big Tech. Here, students have the chance to interact with company stakeholders and fellow developers, and apply both hard and soft skills beyond the classroom environment.\u201d\n\n\n\nTake the leap to change your career today. Learn how TripleTen\u2019s online bootcamp can help you break into tech, no matter where you are in life.",
        "url": "https://techcrunch.com/sponsor/tripleten/how-tripleten-bootcamps-successfully-empower-career-changes/",
        "category": 1,
        "summary": "At the end of the day, we want students to have a strong portfolio to demonstrate the depth of their knowledge.\u201d\n\nAbout 80% of TripleTen students don\u2019t have any tech experience: They enter as healthcare workers, school teachers, service industry professionals, lab techs, or administrators. \u201cBut there is just as much of an emphasis on the soft skills, such as teamwork, communication, and time management, as there is on a hard skill like coding.\u201d\n\nTripleTen offers skills-specific programs in software engineering, data science, business intelligence analytics, quality assurance, and most recently, cybersecurity\u2014areas of expertise that employers are actively hiring for. \u201cAnd key to that is experiential learning\u2014the ability to work with career coaches and externship managers to determine the scope of a real-world project.\u201d\n\nRecent students from TripleTen\u2019s data science program, for example, spent five weeks developing and training machine learning models for DataSpeak, using the Python Questions from Stack Overflow dataset to generate prompt answers based on user queries."
    },
    {
        "title": "Accelerate Your Sales Performance with Ai Sales",
        "text": "Accelerate Your Sales Performance with Ai Sales\n\nWatch this deep-dive webinar on Ai Sales with Jim Lynch, Dialpad Senior Product Manager, and Mallory VonRohn, VP of Technology at Nolan Transportation Group. This all-in-one, Ai-powered sales platform improves sales readiness, simplifies coaching, and helps you nail revenue targets. Learn how to: \u2022 Use Ai Playbooks to expedite onboarding \u2022 Guide reps live with Real-Time Assist Cards \u2022 Up your coaching game with Ai Scorecards, Ai Coaching Hub, and more\n\nThis article is presented by TC Brand Studio. This is paid content, TechCrunch editorial was not involved in the development of this article. Reach out to learn more about partnering with TC Brand Studio.\n\nMore TechCrunch",
        "url": "https://techcrunch.com/sponsor/dialpad/accelerate-your-sales-performance-with-ai-sales/",
        "category": 3,
        "summary": "This all-in-one, Ai-powered sales platform improves sales readiness, simplifies coaching, and helps you nail revenue targets. Accelerate Your Sales Performance with Ai Sales\n\nWatch this deep-dive webinar on Ai Sales with Jim Lynch, Dialpad Senior Product Manager, and Mallory VonRohn, VP of Technology at Nolan Transportation Group. Learn how to: \u2022 Use Ai Playbooks to expedite onboarding \u2022 Guide reps live with Real-Time Assist Cards \u2022 Up your coaching game with Ai Scorecards, Ai Coaching Hub, and more\n\nThis article is presented by TC Brand Studio."
    },
    {
        "title": "Visa Everywhere Initiative: Empowering Fintech Start-ups to Unlock Opportunities",
        "text": "With fintech innovation on the rise in the CEMEA region, the Visa Everywhere Initiative is connecting start-ups to the broader ecosystem\n\nFor years, fintech has succeeded in disrupting markets and advancing financial inclusion by designing modern solutions that speak to the ecosystem\u2019s most pressing needs. For many early-stage start-ups, however, acquiring capital is a common challenge. Nearly 50% of start-ups surveyed in a recent study cited a lack of financing as the top reason for failure, highlighting a need to provide entrepreneurs with more sustainable avenues for growth, innovation, and success.\n\nFor nearly a decade, the Visa Everywhere Initiative (VEI) has empowered start-ups to unlock opportunities and bolster their credibility, helping them take a step closer to fulfilling their potential. This open innovation program provides start-ups with a global platform to present their novel ideas while connecting them to Visa\u2019s vast network of clients, investors, and partners, and offering them access to Visa\u2019s extensive suite of solutions.\n\nSince launching in 2015, VEI has helped more than 15,000 start-ups from over 100 countries \u2013 many of whom still work with Visa and its clients today. These start-ups have gone on to secure more than $48 billion in funding, showcasing the remarkable impact of cultivating a supportive, uplifting, and interconnected ecosystem.\n\nToday, VEI is more than a competition; it serves as a launching pad for lasting connections.\n\nDemonstrating ongoing support for start-ups beyond VEI, Visa recently announced a new partnership with former global and regional VEI winner ThriveAgric as part of their expansion into Kenya, where they plan to empower an additional 10,000 farmers to participate in the digital economy. Visa previously worked with the Nigerian fintech to provide smallholder farmers with access to vital tools and services such as cards, bank accounts, and Visa Direct disbursements.\n\nGodfrey Sullivan, Head of Product, Partnerships and Digital Solutions, CEMEA at Visa said: \u201cFintech is among the most competitive start-up segments globally, fueling economic growth and facilitating broader financial inclusion by helping to serve the underserved. The Visa Everywhere Initiative is dedicated to helping them take their next step forward onto the global stage, enabling them to benefit from Visa\u2019s diverse network of partners, substantial suite of solutions, and globally trusted name.\u201d\n\nTune in to TechCrunch on July 23, 2024, at 1:30 p.m. UAE/9:30 a.m. GMT to catch the VEI CEMEA Finals\n\nFinalists from Central Europe, the Middle East, and Africa (CEMEA) will compete at this year\u2019s regional VEI finals, which will be live-streamed on TechCrunch on July 23 at 1:30 p.m. UAE time (9:30 a.m. GMT).\n\nSub-regional competitions leading up to this event included an inaugural Levant edition across Jordan, Lebanon, Iraq, and Palestine, as well as events spanning Saudi Arabia, Bahrain, Oman, Qatar, and Kuwait. Winners from the CEMEA chapter will share a total prize pool of $350 million, with individual prizes of up to $40,000.\n\nThe regional winner will compete for the global win during the TechCrunch Disrupt event in San Francisco on October 28, for the chance to receive a grand prize of $100,000.\n\nMeet this year\u2019s CEMEA VEI finalists\n\nFive regional fintech finalists will present innovative payment solutions across gaming, digital wallets, e-commerce, and other critical sub-sectors on July 23, 2024.",
        "url": "https://techcrunch.com/sponsor/visa-everywhere-initiative/visa-everywhere-initiative-empowering-fintech-start-ups-to-unlock-opportunities/",
        "category": 2,
        "summary": "Godfrey Sullivan, Head of Product, Partnerships and Digital Solutions, CEMEA at Visa said: \u201cFintech is among the most competitive start-up segments globally, fueling economic growth and facilitating broader financial inclusion by helping to serve the underserved. Demonstrating ongoing support for start-ups beyond VEI, Visa recently announced a new partnership with former global and regional VEI winner ThriveAgric as part of their expansion into Kenya, where they plan to empower an additional 10,000 farmers to participate in the digital economy. The Visa Everywhere Initiative is dedicated to helping them take their next step forward onto the global stage, enabling them to benefit from Visa\u2019s diverse network of partners, substantial suite of solutions, and globally trusted name.\u201d\n\nTune in to TechCrunch on July 23, 2024, at 1:30 p.m. UAE/9:30 a.m. GMT to catch the VEI CEMEA Finals\n\nFinalists from Central Europe, the Middle East, and Africa (CEMEA) will compete at this year\u2019s regional VEI finals, which will be live-streamed on TechCrunch on July 23 at 1:30 p.m. UAE time (9:30 a.m. GMT)."
    },
    {
        "title": "ByMyCell Founder Q&A: Building a biotech startup in Brazil for healthier crops",
        "text": "ByMyCell, a Brazilian startup that applies modern genomics research to agriculture, is using Oracle Cloud Infrastructure (OCI) to help farmers and their suppliers maximize crop production sustainably.\n\nLeo Leung, Vice President of Oracle Tech and OCI talks with ByMyCell founder and CTO Rafael Silva-Rocha about how technology can help. The interview was edited for length and clarity.\n\nLeo Leung: What\u2019s the startup environment like there?\n\nRafael Silva-Rocha: We are in S\u00e3o Paulo state, which accounts for about 40% of the Brazilian economy. A number of unicorns were born here. But one difference here is that if a Brazilian company wants venture capital, it must generate revenue from the beginning. It can\u2019t say, \u201cOh, I have this nice technology, but no clients.\u201d\n\nLeo Leung: What problem is ByMyCell taking on? Who are your customers?\n\nRafael Silva-Rocha: We are a biotech company focused on simplifying genomics for agribusiness. My co-founder and I come from academic backgrounds dedicated to teaching and research. We started ByMyCell as we saw a way to build a technology solution to help Brazilian farms produce healthier crops. We target two kinds of customers \u2013 farmers and their suppliers. Farmers face challenges with inclement weather and in replacing chemicals with biologicals. Additionally, depending on the soil, certain combinations of soil and biologicals may not result in the expected crop yield. We provide a precision agriculture solution based on genomics microbiome analysis, which lists the microorganisms in the soil. With that information, farmers can make decisions based on data, not experimentation.\n\nSecond, our reports enable suppliers to tailor products to specific soil types. They can build products based on what is most appropriate for the soil, which helps the farmers grow healthier crops that yield higher growth. It is also good for the long-term health of the land.\n\nBy running genomics through our platform, they can select new microbes and deliver a new product up to six times faster than before. Also, our tests also show which biologicals will be most effective given each farm\u2019s conditions.\n\nLeo Leung: Before diving in, tell me more about the Brazil market?\n\nRafael Silva-Rocha: Agribusiness is one of the largest industries in Brazil, currently representing more than 20% of GDP and one-third of employment. Farmers are trying to reduce the amount of chemicals they use as they lead to soil degradation and impact plant growth. Switching from chemicals to biologicals\u2014derived from naturally occurring materials\u2014has the opposite effect, because it enhances soil fertility and promotes healthy development for a more sustainable and long-term solution, while also decreasing their carbon footprint. Our tests can show which biologicals will be more effective for their conditions. However, they can be trickier because it isn\u2019t a broad-based approach and requires a farm to know the biological condition beforehand to correctly map to what products they use.\n\nLeo Leung: What challenges do you see in terms of infrastructure or cloud services?\n\nRafael Silva-Rocha: The unfortunate side of working with AI and GPUs is that there are sometimes shortages\u2014companies often compete for cloud resources. With Oracle it only takes 24 hours to release orders for new computing resources while with other cloud providers it can take a week. This speed is essential for delivering projects at the speed demanded by the customer. Additionally, Oracle offers superior price performance compared to other cloud vendors.\n\nWe decided to mix local and cloud. We generate the data and do the processing immediately; it reduces complexity and puts a lot of GPU computation there. And then we continue in the cloud. Having a hybrid infrastructure is okay for this stage, but more difficult to manage.\n\nLeo Leung: I believe that you are using AI Infrastructure and HPC Compute. Can you share more?\n\nRafael Silva-Rocha: In the lab, the type of genomic sequence data in the machine gets data from an electrical signal, not the classical ATGC sequence. We convert the noisy electrical signal into a DNA sequence into text. To do that, we have models trained by specialized companies, and we must run them on GPUs. I may get 30GB of data for a small farm, and I must compress that 10x coming from this very noisy signal into a DNA sequence like text. We then upload that to the cloud and run the pipeline to convert the mix of sequencing into structured data, where we can see which kind of microbes we have and the relative abundance.\n\nThe first part is on GPUs in the lab right now, and then the final turn runs in the cloud on an Oracle HeatWave database. That second part, which is also high-performance computing, is done with CPUs on the cloud.\n\nLeo Leung: What other OCI products are you using?\n\nRafael Silva-Rocha: We are starting to play with the Oracle HeatWave database and should expand usage shortly. Now, we must integrate this data in a more accessible and scalable way. And then, we must train new models to make predictions because, at the end of the day, our clients don\u2019t want a report, they want a decision: \u201cOkay, this is the picture of my land. What should I do? And if I do that, how much more can I gain in productivity?\u201d\n\nLeo Leung: Did you develop applications on OCI?\n\nRafael Silva-Rocha: It\u2019s entirely OCI. We have one app that is an automatic proposal generator that lets users calculate samples. Another is a lab information management app that provides the infrastructure to track and process samples.\n\nLearn more about the ISV AI service offerings on OCI to help innovators accelerate the development and deployment of production-ready AI here.\n\nFor more information on OCI\u2019s AI services, GenAI, and cloud applications\u2014all on a best-in-class AI infrastructure, click here.",
        "url": "https://techcrunch.com/sponsor/oracle/bymycell-founder-qa-building-a-biotech-startup-in-brazil-for-healthier-crops/",
        "category": 2,
        "summary": "Leo Leung, Vice President of Oracle Tech and OCI talks with ByMyCell founder and CTO Rafael Silva-Rocha about how technology can help. ByMyCell, a Brazilian startup that applies modern genomics research to agriculture, is using Oracle Cloud Infrastructure (OCI) to help farmers and their suppliers maximize crop production sustainably. Switching from chemicals to biologicals\u2014derived from naturally occurring materials\u2014has the opposite effect, because it enhances soil fertility and promotes healthy development for a more sustainable and long-term solution, while also decreasing their carbon footprint."
    },
    {
        "title": "Confidential GPUs for AI are the future of secure computing",
        "text": "Efficiency and innovation are often touted as hallmark attributes of generative AI. But as more enterprise businesses look to integrate the technology into their workflows, confidentiality \u2014 in data processing and sharing \u2014 is of utmost importance.\n\nThe recent introduction of AI-specific policies, such as the U.S. Executive Order on the Safe, Secure and Trustworthy AI and the European Union\u2019s AI Act, is a regulatory step forward for developers and users alike. These policies set compliance standards for AI developers to ensure that sensitive, proprietary, or confidential data is protected. They also nod to the inherent value of AI models as intellectual property, wherein training data, algorithms, model architecture, and weights should be secured against unauthorized access.\n\nHow confidential computing protects data at scale\n\nCloud services providers (CSPs) have been helping their customers keep their sensitive code and data secure in transit on the network using TLS and HTTPS encryption, and secure at rest on disk using encryption with customer managed keys. However, one area of data protection that has not been addressed until more recently is the protection of data in use in server memory. This changed in 2019 when Microsoft and other industry leaders founded the Confidential Computing Consortium (CCC), a project community at the Linux Foundation, to accelerate the development and adoption of confidential computing. The CCC defines confidential computing as the protection of data in use by performing computations in a hardware-based and attested Trusted Execution Environment (TEE).\n\nAs a pioneer in this space, Microsoft Azure became one of the first CSPs to introduce confidential virtual machines, which are virtual machines running on confidential computing enabled CPUs. With confidential VMs, only the CPU hardware and the contents of the confidential VM are trusted\u2014all other components of the software stack, including the hypervisor and host OS, are considered outside of this trust boundary and can be breached without exposing sensitive data in memory. And, in compliance with the CCC definition of confidential computing, Microsoft provides attestation tools to allow the user to verify the good state of the CPU and their VM before disk encryption keys are released and sensitive data is loaded into the VM.\n\nThe need for confidential GPUs\n\n\u201cWe\u2019ve worked very closely with customers to get their feedback on what types of AI models they hope to run, what security posture they are looking for, what use cases they want to enable,\u201d said Vikas Bhatia, Head of Product for Azure Confidential Computing. \u201cWith answers including AI models such as Stable Diffusion, Zephyr, Llama2, and GPT2, it became very clear that GPU-enhanced confidential computing would be needed. Our introduction of Azure confidential VMs with NVIDIA H100 Tensor Core GPUs is our first step at addressing this market.\u201d\n\n\u201cOur collaboration with NVIDIA has been a multi-year effort,\u201d said Bhatia, \u201cbut this has been necessary to ensure that the TEE of the confidential VM can be securely extended to include the GPU and the communications channel that connects the two. Any AI applications uploaded, built, and deployed on this stack will remain protected from end to end.\u201d\n\nWith these new GPU-enhanced confidential VMs, existing Azure customers can redeploy their CUDA models and the code that they\u2019ve written already in an AI ML space in a confidential GPU environment to achieve what Bhatia calls a \u201cunified confidentiality.\u201d This establishes a secure channel with the GPU, wherein all subsequent data transfers between the VM and GPU are protected. Furthermore, the attestation process will verify that the VMs and GPUs are running a correctly configured TEE before any sensitive applications are launched.\n\nThe diverse applications of confidential GPUs\n\nThe effectiveness of generative AI models hinges on two factors: quality and quantity in training data. Despite training progress made with publicly available datasets, access to proprietary data is essential to leveraging the full potential of enterprise models. Through confidential GPUs computing, businesses can securely authorize the use of specialized data to perform more complex and targeted tasks, such as private data analysis, joint modeling, secure voting, or multi-party computation.\n\nBhatia identified three major use-cases for confidential GPUs:\n\nConfidential multi-party computation: Organizations can collaborate to train and run inferences on models without sharing proprietary data. Only the final result of a computation would be revealed to the participants.\n\nOrganizations can collaborate to train and run inferences on models without sharing proprietary data. Only the final result of a computation would be revealed to the participants. Confidential inferencing: Inferencing occurs when a query or input is sent to a machine learning model to obtain a prediction or response. Confidential GPUs protect data in all stages of the inferencing process from clients, the model developer, service operations, and cloud providers.\n\nInferencing occurs when a query or input is sent to a machine learning model to obtain a prediction or response. Confidential GPUs protect data in all stages of the inferencing process from clients, the model developer, service operations, and cloud providers. Confidential training: Model algorithms and weights won\u2019t be visible outside of TEEs set up by AI developers. Models can be securely trained on encrypted, distributed datasets that remain confidential to each party within a hardware-enforced boundary.\n\nAzure\u2019s healthcare customers, for example, are interested in employing confidential inferencing to analyze medical images, like X-rays, CT scans, and MRIs, without disclosing sensitive patient data or proprietary algorithms. Advanced image processing can improve the likelihood of diagnosis and treatment in identifying tumors, fractures, or anomalies in scans \u2014 without placing patient data at risk.\n\nAs an example, confidential GPUs are valuable in scenarios where data privacy is crucial but collaborative computation is still necessary. Researchers can run simulations of sensitive data (e.g. government data, scientific data) without sharing datasets or code to unauthorized parties. In the finance sector, confidential multi-party computation can be useful in fraud prevention work. Finance institutions can perform analyses or computations in a protected data clean room without disclosing individual financial details.\n\n\u201cBefore confidential computing, companies struggled to securely implement this kind of data-sharing technology,\u201d Bhatia said. \u201cWhile in preview, clients have tested the VMs and found that the security enhancements help to address some of the challenges they\u2019re facing with respect to compliance, governance and security.\u201d\n\nA new security standard for the AI era\n\nAs a leader in confidential computing, Azure\u2019s robust security platform caters to the privacy needs of businesses worldwide. Innovative hardware is essential to maintaining a confidential GPU ecosystem of applications and AI models, which Azure is building towards. Bhatia\u2019s hope is that this level of confidentiality will one day be standard across all industries. Data privacy and AI confidentiality should be a convention of everyday computing.\n\n\u201cOur initial offering is best suited for use with smaller language models,\u201d Bhatia said. \u201cAnd while work is underway to scale this technology to support LLMs, we know customers will benefit from the current version by discovering the possibilities this technology will bring.\u201d\n\nSimilar to how the early internet was once run on unsecure HTTP sites, security standards are always evolving. With more organizations processing sensitive data for AI models, there\u2019s a great need for confidential NVIDIA GPU-powered AI. Azure\u2019s latest VMs are a necessary, innovative introduction to secure GPU computing, which Azure is working to scale up to multiple GPUs.\n\n\u201cWe want to set a new security standard with our confidential VMs,\u201d Bhatia said. \u201cWe build from the mindset that a rising tide lifts all boats.\u201d\n\nCurious about Azure confidential VMs with NVIDIA H100 Tensor Core GPUs? Sign up to preview Azure\u2019s hardware-based security enhancements and protect your GPU data-in-use.",
        "url": "https://techcrunch.com/sponsor/microsoft-azure/confidential-gpus-for-ai-are-the-future-of-secure-computing/",
        "category": 2,
        "summary": "The need for confidential GPUs\n\n\u201cWe\u2019ve worked very closely with customers to get their feedback on what types of AI models they hope to run, what security posture they are looking for, what use cases they want to enable,\u201d said Vikas Bhatia, Head of Product for Azure Confidential Computing. Our introduction of Azure confidential VMs with NVIDIA H100 Tensor Core GPUs is our first step at addressing this market.\u201d\n\n\u201cOur collaboration with NVIDIA has been a multi-year effort,\u201d said Bhatia, \u201cbut this has been necessary to ensure that the TEE of the confidential VM can be securely extended to include the GPU and the communications channel that connects the two. Any AI applications uploaded, built, and deployed on this stack will remain protected from end to end.\u201d\n\nWith these new GPU-enhanced confidential VMs, existing Azure customers can redeploy their CUDA models and the code that they\u2019ve written already in an AI ML space in a confidential GPU environment to achieve what Bhatia calls a \u201cunified confidentiality.\u201d This establishes a secure channel with the GPU, wherein all subsequent data transfers between the VM and GPU are protected."
    },
    {
        "title": "DataStax Beats the Drum on Simplifying GenAI App Development",
        "text": "DataStax Chairman and CEO Chet Kapoor, LangChain co-founder and CEO Harrison Chase, and Unstructured founder and CEO Brian Raymond (credit: Regent Pictures)\n\nGetting generative AI applications to production is hard, but a host of new integrations and solutions makes life easier for developers\n\nFrom CIOs looking for new organizational efficiencies, to end users who\u2019ve begun to expect intuitive and relevant results from shopping apps, customer service agents, and even web searches, generative AI seems to be on everyone\u2019s mind. But getting a scalable GenAI app\u2014one that an enterprise would rely on to produce accurate, relevant results\u2014to production is a complicated affair. Developers have a dizzying array of tools, models, and platforms to choose from, along with a laundry list of tests and component-swapping to improve the relevance and accuracy of their results. It\u2019s a lot to manage.\n\nDataStax, the GenAI data company, threw a party in the San Francisco Dogpatch neighborhood Monday night to unveil several new offerings that help to create a more unified, easier-to-navigate, and faster path to help developers eliminate the noise and focus on the creative part of building GenAI apps. The RAG++ AI Hack Night helped to show how all of these puzzle pieces fit together to make it easier for developers to get GenAI apps to production.\n\nPriceline distinguished architect Rajy Tanneeru, SupPlant CTO Revital Kremer, and NVIDIA senior director of generative AI data Jane Scowcroft (credit: Regent Pictures)\n\nSeveral DataStax partners, including NVIDIA, Microsoft, Unstructured, LangChain, Upstage, and Voyage AI, along with customers including Priceline and SupPlant, shared their experiences working with DataStax and other GenAI technologies.\n\nDataStax developer relations leader Carter Rabasa took the stage and rolled up his sleeves to demonstrate how the DataStax AI platform, LangChain, and Unstructured enabled him to build a GenAI movie search app in under 20 minutes with minimal code (here\u2019s a recorded version of his demo).\n\nHere\u2019s a quick rundown of the news DataStax unveiled Monday.\n\nAn integrated Langflow offering\n\nDataStax acquired Langflow, a popular, open source visual framework for building RAG applications, back in April. The offering simplifies the development process by letting developers drag and drop different application building blocks to help them set up, swap, compare, and test out all the major large language model (LLM) and embedding providers. With the absorption of the acquisition complete, DataStax on Monday announced that Langflow 1.0 is generally available, hosted within the DataStax Cloud platform, and it delivers the fundamental building blocks required to create, customize, and share reusable AI components.\n\nThe Unstructured.io integration\n\nUnstructured enables developers to convert any document, file type, or layout into LLM-ready data. It\u2019s a no-code cloud service that stands up GenAI data pipelines, from transformation and cleaning to generating embeddings for a vector database.\n\nIn our new partnership with Unstructured, the platform is integrated with DataStax Astra DB, the NoSQL and vector database for GenAI, to help developers build RAG pipelines to quickly convert the most common document types into vector data for highly relevant GenAI similarity searches.\n\nDataStax Vectorize\n\nConverting all kinds of data into vectors is a key part of preparing it for GenAI. DataStax Vectorize simplifies vector generation by letting developers pick an embedding service, configure it with Astra DB, and start building right away. Most embedding is currently handled \u201cclient-side\u201d- meaning that developers need to learn many different APIs. With Vectorize, vector embedding now happens on the server; meaning developers only need to learn one API to now access the eight most popular embedding providers: Azure OpenAI, Hugging Face, Jina AI, Mistral AI, NVIDIA, OpenAI, Upstage AI, and Voyage AI.\n\n\u201cWe\u2019re excited to partner with DataStax Vectorize for its ease of use and the ability to build sophisticated RAG applications on premises,\u201d said Kasey Roh, head of business, U.S., at Upstage AI.\n\nRAGStack 1.0\n\nRetrieval-augmented generation (RAG) is a key piece of the GenAI app puzzle. It optimizes the output of LLMs by enabling them to access custom and proprietary data for more accurate and relevant responses. DataStax on Monday unveiled the latest release of RAGStack, an end-to-end solution that helps remove the many complexities that developers face when implementing RAG. The 1.0 release offers new and enhanced integrations, new tools, and simpler embedding techniques, all in the name of getting GenAI apps to production much faster.\n\nLearn more about how DataStax simplifies and accelerates GenAI app development.",
        "url": "https://techcrunch.com/sponsor/datastax/datastax-beats-the-drum-on-simplifying-genai-app-development/",
        "category": 2,
        "summary": "DataStax, the GenAI data company, threw a party in the San Francisco Dogpatch neighborhood Monday night to unveil several new offerings that help to create a more unified, easier-to-navigate, and faster path to help developers eliminate the noise and focus on the creative part of building GenAI apps. Priceline distinguished architect Rajy Tanneeru, SupPlant CTO Revital Kremer, and NVIDIA senior director of generative AI data Jane Scowcroft (credit: Regent Pictures)\n\nSeveral DataStax partners, including NVIDIA, Microsoft, Unstructured, LangChain, Upstage, and Voyage AI, along with customers including Priceline and SupPlant, shared their experiences working with DataStax and other GenAI technologies. DataStax Chairman and CEO Chet Kapoor, LangChain co-founder and CEO Harrison Chase, and Unstructured founder and CEO Brian Raymond (credit: Regent Pictures)\n\nGetting generative AI applications to production is hard, but a host of new integrations and solutions makes life easier for developers\n\nFrom CIOs looking for new organizational efficiencies, to end users who\u2019ve begun to expect intuitive and relevant results from shopping apps, customer service agents, and even web searches, generative AI seems to be on everyone\u2019s mind."
    },
    {
        "title": "How EcoFlow\u2019s X-Core system streamlines home energy storage",
        "text": "EcoFlow\u2019s X-Core system brings performance and simplicity to the whole-home energy space\n\nIf you ask the average consumer for the most cost-effective, off-grid power solution to run individual appliances, whether it be a laptop, hair dryer, refrigerator, central AC, most won\u2019t know where to begin. Now scale that up and ask for the right solution to power their entire household and you really begin to lose an audience.\n\nFor EcoFlow CTO Thomas Chan, who leads the company\u2019s hundreds of researchers and engineers, this is one of the biggest challenges he\u2019s looking to address. And it\u2019s a challenge, he believes, that\u2019s becoming increasingly important to more Americans.\n\nThat\u2019s because extreme weather events and natural disasters are wreaking havoc on the U.S. power grid, causing more frequent and longer power outages than ever. To deal with this, Americans are increasingly turning toward whole-home energy storage systems using batteries as a safe, eco-friendly solution \u2014 including those made by EcoFlow.\n\nInstalling batteries to run entire households, however, is a new phenomenon driven by technological improvements and improved energy storage supply chains, much of which was born in the electric vehicle industry. Because of the need to understand a bit of power-related jargon, many buyers skew toward early adopters and the tech savvy.\n\nTo reach the wider swath of people impacted by power outages from Florida to California, Chan believes performance, safety and system intelligence need to be so good that the end user doesn\u2019t think about them. To that end, EcoFlow is systematically bundling these improvements within its X-Core 3.0 technology platform, which will fully debut in its new DELTA Pro 3 portable power station launching June 25.\n\n\u201cIf you think about the very start of the EV industry, most buyers were early adopters fluent in the engineering language of car and battery companies,\u201d Chan said. \u201cAs vehicle performance improved, more mainstream customers bought in. They were less concerned about specs like inverter efficiency and voltage architecture. They just want to know if they can make the trip from LA to Vegas with the AC running all on a single charge.\u201d\n\n\u201cSimilarly, we are removing the entry barrier and bringing that improved, simpler experience to whole-home energy storage. We want to make it more accessible to everyone, and we\u2019re doing that with X-Core 3.0 under the hood,\u201d he said. \u201cIt\u2019s no coincidence the DELTA Pro 3 design aesthetic looks like something from the automotive industry.\u201d\n\nMaximizing battery efficiency and performance\n\nAs more consumers make the switch towards clean energy, developments in battery technology \u2014 specifically charging speed, design, and safety \u2014 are essential to optimizing energy use.\n\nOne of X-Core\u2019s battery performance features, X-Boost, originated early on in the company\u2019s history from a conversation Chan had with his wife, after her hair dryer couldn\u2019t be powered by one of EcoFlow\u2019s portable stations.\n\nThis sparked a realization for Chan: Consumers shouldn\u2019t worry about technical details; they just want products that can perform. With that, he worked to develop X-Boost, allowing people to power high-wattage appliances that can exceed rated output limits of a portable power station.\n\nThis solutions-oriented approach has been reflected throughout X-Core\u2019s development and also addressed one of the bigger obstacles to widespread adoption of portable energy storage in the early days: charging speed.\n\nEcoflow developed X-Stream in 2019, which reduced the charging time of a 1300Wh battery from 10 hours to just 1.6 hours. Now with X-Core 3.0, DELTA Pro 3\u2019s larger 4kWh battery can charge up to 80% capacity in under an hour through its advanced power management systems.\n\n\u201cDELTA Pro 3\u2019s increased battery cell capacity has a 20% improvement in charging capacity compared to the previous Delta Pro,\u201d Chan said. \u201cBecause the battery is also more durable, the lifespan increased from 3,000 to 4,000 cycles before it can only be recharged to 80% of its original capacity. That\u2019s over 11 years for a heavily used power station.\u201d\n\nBolstered by X-Boost, X-Stream and X-Quiet, a soundproofing and cooling technology lowering noise levels under high-power outputs, these high-performance features expand the range of applications for DELTA Pro 3 \u2014 a capability that makes it ideal for both everyday use and emergency backup.\n\nEcoFlow has also looked to the EV industry for more than design, but also developments in battery safety, so users can charge up with peace of mind. Safety is the foundation of the X-Core 3.0 system, Chan said, resulting from thousands of interactions and conversations with users over the years. A new innovation to the DELTA Pro 3 is its PACK module, which employs cell-to-chassis integration technology.\n\nOriginally developed for electric vehicles, cell-to-chassis integration was adapted by EcoFlow to enhance space utilization, structural stability and overall performance of its portable power stations. By integrating battery cells directly into the product chassis, the design eliminates the need for separate battery housing and complex wiring, leading to a more compact and efficient design.\n\nThis integration streamlines product assembly, improves shock resistance, and optimizes internal layout for better heat dissipation and waterproofing. EcoFlow earned an industry-first IP65 rating for these modules, certifying their airtight and water-resistant capabilities.\n\n\u201cAdopting cell-to-chassis tech from EVs into our world presented a number of engineering hurdles we had to overcome,\u201d Chan said. \u201cFor example, there are weight penalties involved when you make batteries more robust and weatherproof that are acceptable in a vehicle but not for a portable device. Everything we developed had to operate on a much smaller scale.\u201d\n\nCombining state-of-the-art hardware with responsive software\n\nFinally, software is a driving force behind the DELTA Pro 3, which consists of X-Core\u2019s cloud-based battery management system and its Oasis dynamic home energy hub.\n\n\u201cHardware has been the principal focus of the portable power station industry,\u201d he said. \u201cBut by Incorporating the latest developments from software technologies like AI, cloud and IoT, it allows us to significantly expand what our hardware can do to bring an improved user experience.\u201d\n\nCloud battery management powered via AWS offers predictive performance analysis and safety alerts by continuously monitoring everything the battery is doing in real time. Together with Oasis, a smart home integration that works with third-party devices like smart thermostats or solar power systems, these features help consumers make better energy choices. Oasis is further equipped with AI capabilities that optimize power usage through intelligent scheduling and adaptive learning.\n\nFor example, an EcoFlow home energy system can use weather data to optimize battery charge and discharge cycles if you have solar panels to maximize efficiency. It can also keep all your energy in reserve if a storm is expected, just in case it\u2019s needed for a power outage. The system can even use local utility prices to maximize cost savings in areas with different rates throughout the day.\n\n\u201cThese software-based features allow you to get the most with your energy storage investment,\u201d Chan said. \u201cWith X-Core, the system does more and the user worries less. Ultimately, it\u2019s our job to ensure the hair dryer will work.\u201d\n\nKeep your home and appliances running smoothly with EcoFlow\u2019s DELTA Pro 3. Order today and get exclusive benefits worth up to $3,000.",
        "url": "https://techcrunch.com/sponsor/ecoflow/how-ecoflows-x-core-system-streamlines-home-energy-storage/",
        "category": 2,
        "summary": "EcoFlow\u2019s X-Core system brings performance and simplicity to the whole-home energy space\n\nIf you ask the average consumer for the most cost-effective, off-grid power solution to run individual appliances, whether it be a laptop, hair dryer, refrigerator, central AC, most won\u2019t know where to begin. That\u2019s over 11 years for a heavily used power station.\u201d\n\nBolstered by X-Boost, X-Stream and X-Quiet, a soundproofing and cooling technology lowering noise levels under high-power outputs, these high-performance features expand the range of applications for DELTA Pro 3 \u2014 a capability that makes it ideal for both everyday use and emergency backup. \u201cBut by Incorporating the latest developments from software technologies like AI, cloud and IoT, it allows us to significantly expand what our hardware can do to bring an improved user experience.\u201d\n\nCloud battery management powered via AWS offers predictive performance analysis and safety alerts by continuously monitoring everything the battery is doing in real time."
    },
    {
        "title": "EDB\u2019s Next Move: From a Postgres Database Company to a Postgres Data & AI Platform Company",
        "text": "By: Jozef de Vries, Chief Product Engineering Officer, EDB\n\n20 years ago this year, the original founders of EDB made two bets; one that more and more people would want to use Postgres, and another that more and more people would want to stop using Oracle.\n\nThese bets have generally paid off. Postgres has skyrocketed in popularity over the years, and EDB\u2019s sustained focus in Oracle compatibility, regular and significant contributions to the PostgreSQL community project, and the development of database tooling to run Postgres at enterprise scale have made it possible for the company to experience continuous growth.\n\nThrough the 20 years that EDB has been around, or the nearly 30 that Postgres as a technology has been around, the industry has gone through some notable changes, and through it all, users return (or turn) to just use Postgres to tackle their most complex data challenges.\n\nPostgres\u2019 popularity is a win, but it\u2019s not a finish line. It\u2019s a catalyst for EDB to continue innovating, experimenting, and raising the bar for what\u2019s possible with Postgres.\n\nNow we\u2019re making a new bet, and in this bet, EDB is focused on solving three new problems.\n\nProliferation of systems and users: Decades of disparate data systems, technologies, geographies, and increase in users have created a fragmented landscape that\u2019s increasingly hard to manage. Fragmented data systems leave value on the table: That same massive data estate holds immense potential for insights, but given the significant administrative overhead and complexity of these data estates that value is not being realized. Users still have to work too hard to perform their job: The advent of AI has shown the potential to make it easier to both perform tasks and build solutions for customers. Not realizing the value puts any company at risk faster than you can say dot-com.\n\nSo what is this next big bet?\n\nEDB is transforming from a Postgres database company to a Postgres Data and AI Platform company. This expansion enables the company to build upon our transactional workload expertise and deliver capabilities that meet customers\u2019 evolving needs in data analysis and intelligence generation. Developers love to use Postgres, and EDB is enabling them to stay in the Postgres ecosystem as their use cases expand.\n\nEDB is making this possible with EDB Postgres\u00ae AI.\n\nEDB Postgres AI: An Intelligent Platform for Transactional, Analytical and AI Workloads\n\nFoundationally and fundamentally EDB is still focused on transactional workloads. It has to. Transactional data represents the digital footprint of our lived experiences and interactions within our society. Gaining insight into user interactions with digital systems requires analyzing the data created through those interactions. Providing technologies that aid in developing knowledge, creating solutions, and augmenting daily life challenges involves training models with data that represents the various ways society interacts with itself, both positively and negatively.\n\nAt its core, EDB will continue to be a company that builds Postgres, tooling to run Postgres at enterprise scale, and now also a company that builds a Postgres ecosystem that enables value across all the ways that our customers and their users seek to gain value out of their data.\n\nLet\u2019s get into how we\u2019re starting to solve those three problems mentioned above.\n\n1. Data estate management and intelligent observability wherever you run Postgres.\n\nEDB Postgres AI sets out to begin solving this by providing an estate management platform that aggregates representation across self-managed, cloud-hosted, and third-party Postgres systems. Administrators can view key health metrics, engage with system owners to address issues, and access metadata like type, version, and region to ensure compliance.\n\nLooking ahead, we plan to introduce support for non-Postgres database systems, provide capabilities for lifecycle management, and point to point migration to name a few capabilities.\n\nImage: EDB Postgres AI login view\n\n2. Run rapid analytics inside Postgres \u2013 without sacrificing performance.\n\nA couple of years ago, EDB surveyed customers and found that approximately 60% were deploying some portion of their Postgres subscription for analytical use cases. Despite the running view that Postgres is not optimized for analytics, which really it is not, this survey more indicated that our customers were willing to make compromises in performance and scale to bring analytics closer to their transactional systems, and to execute those analytical use cases through a Postgres interface.\n\nWe are removing that compromise. The EDB Postgres AI Lakehouse capabilities enable our customers to run their analytical workload through the standard Postgres interface while a) not impacting their operational workloads, and b) achieving greater performance and scale than in a traditional Postgres system.\n\nIn its first iteration, we are already benchmarking our Lakehouse at 30x faster on average for analytical queries, 5x smaller on disk tables, 18x more cost effective on storage than a traditional Postgres system.\n\nLooking ahead, our ultimate goal is to enable analytical workloads directly on the Postgres clusters themselves and provide a more near-real time analytical experience through an HTAP style architecture. More to come on this in the near future.\n\nImage: EDB Postgres AI overview\n\n3. Realize the near-infinite potential of Postgres with AI.\n\nWith the recent boom around AI, there is a meaningful opportunity for EDB to enhance our customer\u2019s data management experiences with AI. Our strategy on this front is two prong \u2013 we want to bring AI to Postgres, and bring Postgres to AI.\n\nOn the former, migrating databases is hard. With EDB Postgres AI, we\u2019re continuing our commitment to help customers break free of legacy systems by releasing an AI-driven migration co-pilot. The co-pilot is trained on EDB\u2019s vast knowledge base and decades of experience to help users quickly understand and address any incompatibility issues they encounter as they migrate off their Oracle systems.\n\nOn the latter, our investment here is to make it possible to build AI applications directly with Postgres. Much like what we saw with the noSQL wave, the introduction of vector database technology is requiring developers to leave their Postgres ecosystem to build AI applications. This is effectively a new wave of \u2018data system proliferation\u2019.\n\nThe first step is to provide support for pgvector, which enables users to store, retrieve, and query vector embeddings \u2013 the backbone for similarity search and classification of AI data. In addition is a tech preview for a Postgres extension we refer to as pgai. This extension enables applications to interact directly with AI data, abstracting the complexities of vector embeddings, and extends capabilities for data preparation, LLM-based data generation, support for storing AI data in Postgres tables, and real time AI data retrieval through automatic vector embedding and indexing management. Finally, the solution also leverages our Lakehouse capabilities to store and process large volumes of AI data on Object Storage.\n\nConclusion\n\nUltimately, EDB is making transformative investments in our product capabilities that empower our customers to tackle enterprise-scale data challenges. By harnessing the power of Postgres, we aim to extend its value across the data landscape, ensuring its future as the leading data management platform in the industry.\n\nTo learn more about how EDB Postgres AI can transform your data strategy, visit www.enterprisedb.com.",
        "url": "https://techcrunch.com/sponsor/enterprise-db/edbs-next-move-from-a-postgres-database-company-to-a-postgres-data-ai-platform-company/",
        "category": 2,
        "summary": "Despite the running view that Postgres is not optimized for analytics, which really it is not, this survey more indicated that our customers were willing to make compromises in performance and scale to bring analytics closer to their transactional systems, and to execute those analytical use cases through a Postgres interface. This extension enables applications to interact directly with AI data, abstracting the complexities of vector embeddings, and extends capabilities for data preparation, LLM-based data generation, support for storing AI data in Postgres tables, and real time AI data retrieval through automatic vector embedding and indexing management. Postgres has skyrocketed in popularity over the years, and EDB\u2019s sustained focus in Oracle compatibility, regular and significant contributions to the PostgreSQL community project, and the development of database tooling to run Postgres at enterprise scale have made it possible for the company to experience continuous growth."
    },
    {
        "title": "Adaptive Hiring Breaks Software Development Roadblocks",
        "text": "Mastercard Foundry, the hub for new product development at Mastercard, needed to rapidly expand its engineering teams to scale up promising global products.\n\nBut Mastercard faced a huge problem that practically all companies face today: it couldn\u2019t hire the right engineers fast enough. It was taking 8 to 12 weeks to find and hire candidates and project needs kept changing at the same time.\n\nSo Mastercard tapped a new hiring model as part of its strategy to grow and maintain a competitive and high-quality tech team: Adaptive Hiring.\n\nAdaptive hiring marks a shift from fixed to variable cost hiring models and differs from traditional hiring, outsourcing, and freelance marketplaces. How? Adaptive hiring focuses on flexible, skills-based hiring that is borderless and grounded on specific project requirements. This means companies get the right talent at the right time for the right amount of time.\n\nBy leaning into adaptive hiring, Andela engineers were quickly sourced and placed with Mastercard Foundry within 2\u20134 weeks. The embedded engineers successfully built and scaled agriculture, education, and small business solutions with partners. Mastercard Foundry was able to mature products while maintaining a flexible structure. Adaptive hiring and a continued partnership with Andela allow Mastercard Foundry the flexibility to ramp talent up or down seamlessly. Andela engineers have continued to partner with Mastercard engineering colleagues on various global initiatives, including loyalty, point-of-sale solutions, and more.\n\nAs business scaling needs shift up and down in a particular moment in time, adaptive hiring leverages untapped markets to tap into the right skills when needed.\n\nThat\u2019s why leading companies such as Mastercard Foundry, GitHub, Goldman Sachs, ViacomCBS, Seismic, and many more partner with 10-year-old Andela for their adaptive hiring model. The companies get quick access to Andela\u2019s vetted and qualified global marketplace of digital talent, numbering 150,000 and providing a diverse range of skills and perspectives that are flexible and continually improving.\n\n\u201cWhen taking on any project, there are always three constraints, commonly known as the Iron Triangle \u2013 time, cost, scope. And the saying goes that you can pick two. With Andela\u2019s adaptive hiring model, we get all three,\u201d says Ed Donner, Co-Founder and CTO of AI-powered recruitment platform Nebula.io. \u201cWe were able to reach our development initiatives 6-to-9 months faster, largely due to our partnership with Andela. They met every sprint milestone \u2014 there\u2019s a spotless execution track record. I joke that Andela helped us break the Iron Triangle.\u201d\n\nOld Models No Longer Work\n\nGlobal economic and geopolitical uncertainty over the last few years has created challenges for IT leaders. As leaders navigate these waters, they are also faced with determining how to leverage disruptive new technologies, such as Generative AI and large language models (LLMs) like ChatGPT, and meet the demands for speed, flexibility, reliability, security, and value with the acceleration for digital.\n\nThe old models once used to overcome these hurdles are no longer efficient or cost-effective. Time, cost, scope \u2014the iron triangle \u2013 fluctuate more rapidly, while the landscape for talent acquisition has dramatically changed post-pandemic.\n\nAnd the challenges are only going to get worse.\n\nAs of the start of 2024, the unemployment rate for US tech workers was just 2.3%, even tighter than the historically low overall unemployment rate of 3.7%, according to a recent analysis of U.S. Bureau of Labor Statistics data. This means that almost every company seeking tech talent faces the same problem: it\u2019s difficult to hire and super costly if you don\u2019t hire effectively. Without the right talent at the right time, key projects can lose momentum, get put on hold or end up canceled. Large-scale organizational transformations fail about 70% of the time, according to McKinsey research.\n\nWith a razor-thin number of tech workers available, plus growing demand for certain skills like GenAI and data science, it will be increasingly difficult for companies to innovate if they only hire locally.\n\nAdaptive hiring offers a new approach to traditional software development constraints.\n\nAndela operates a global, private marketplace so enterprises can access digital talent in more than 136 countries. It sources, screens, and onboards the engineers, handling nearly the entire process from start to finish. Using AI/ML in its platform, Andela Talent Cloud, it matches the right talent\u2019s skills for the right roles \u2014 at the right speed and cost. The company has a 96%+ talent match success rate and a speed to hire up to 70% faster than traditional recruiting. Over the last 10 years, Andela has trained a learning community of almost 110,000 African digital talent \u2013 that represents 15% of the total engineering population in Africa -\u2013 the fastest growing continent for tech talent in the world.\n\nExpanding influence in a global market\n\nRather than compete for the same limited, local network of engineers, organizations that take a borderless approach can hire from a global pool of talent and gain competitive advantage with more choice, value, scale, quality, and flexibility in terms of who they hire.\n\n\u201cOur global client footprint requires us to deliver to anywhere from anywhere. To accomplish this, we need a balanced, global talent strategy,\u201d said Ikechi Okoronkwo, Executive Vice President, Analytics & Data Science at Choreograph. \u201cWith Andela, we scale up or down easily as business needs change. They help us quickly find talent that is highly motivated, highly skilled and that embodies a culture of excellence and delivery. Talent hits the ground running which drives maximum value for our clients. Andela de-risks global hiring, so businesses can grow and be competitive.\u201d\n\nThe 2022 Gartner Borderless IT Workforce Survey found that 58% of enterprises surveyed had some technology talent working in a fully remote borderless arrangement. Yet that represented only 11% of the technology talent among those enterprises.\n\nSome companies are moving far faster into borderless, adaptive hiring mode.\n\nKinship has worked with Andela for almost three years, spanning 14 different countries with a concentration in Africa and Latin America. \u201cAndela talent makes up a significant portion of our engineering team depending on what projects we are working on,\u201d said Eddie King, head of B2B Engineering at Kinship. \u201cAndela has been a strategic partner, helping us rapidly hire for short-term projects, as well as grow and maintain relationships with the engineers who continue to work on long-term projects.\n\nAdaptive Hiring accelerates digital transformation initiatives\n\nA global presence offers companies opportunities for growth, innovation, and resilience in an increasingly interconnected and competitive world economy. Going forward, adaptive hiring will play a big role in giving companies a much better chance of pulling off whatever digital transformations they seek to make.\n\nWith Andela, it\u2019s much easier to establish dedicated teams for digital transformation projects that don\u2019t always require full-time employees. Andela can stand up tech talent in a matter of days, not weeks, and every team is onboarded with skills specific to the job they\u2019re hired for, so they can drive greater progress in a short period of time. Given the need for ever more GenAI skills across companies in all industries, adaptive hiring will play an even larger role in enabling companies to pursue digital initiatives.\n\n\u201cWith data at the forefront, I think we\u2019re seeing a lot of demand for skills related to data engineering. We obviously have a lot of demand from our clients looking for solutions built on top of data. Being able to scale the team to meet that demand and to do so with the best and the brightest from around the world is something that we continually try to do,\u201d said Todd Mansfield, Managing Director at Goldman Sachs\n\nAs customers like Goldman Sachs continue to sustainably scale, they can utilize Andela\u2019s adaptive hiring marketplace to tap into its remote-fluent talent anywhere in the world.\n\nLearn how Andela\u2019s borderless marketplace is reshaping the future of tech talent.",
        "url": "https://techcrunch.com/sponsor/andela/the-tech-talent-shortage-isnt-a-problem-if-you-go-borderless/",
        "category": 1,
        "summary": "Expanding influence in a global market\n\nRather than compete for the same limited, local network of engineers, organizations that take a borderless approach can hire from a global pool of talent and gain competitive advantage with more choice, value, scale, quality, and flexibility in terms of who they hire. As leaders navigate these waters, they are also faced with determining how to leverage disruptive new technologies, such as Generative AI and large language models (LLMs) like ChatGPT, and meet the demands for speed, flexibility, reliability, security, and value with the acceleration for digital. Being able to scale the team to meet that demand and to do so with the best and the brightest from around the world is something that we continually try to do,\u201d said Todd Mansfield, Managing Director at Goldman Sachs\n\nAs customers like Goldman Sachs continue to sustainably scale, they can utilize Andela\u2019s adaptive hiring marketplace to tap into its remote-fluent talent anywhere in the world."
    },
    {
        "title": "Lucid Software\u2019s product capabilities drive productivity and innovation for teams",
        "text": "For years, organizations have been actively navigating how to improve hybrid work for all employees. While going back to the office on a hybrid schedule is more common today, a majority of workers, including 58% of executives, 55% of managers and 43% of entry-level workers, identify balancing productivity as the biggest challenge of hybrid work.\n\nWith this being the top concern, Lucid Software\u2019s Hybrid Workplace Whiplash Survey of more than 2,500 knowledge workers discovered that companies have tried to address productivity concerns by expanding their tech stacks, with 45% of workers using five or more tools to complete assignments and get their jobs done. But nearly half (44%) of workers aren\u2019t satisfied with the tools their company offers when it comes to collaboration.\n\nThe survey also sheds light on why workers aren\u2019t satisfied and the clear disconnect between the tools companies have in their tech stacks and the tools employees want. For example, only 22% of workers currently report using visual collaboration software, but 73% of workers believe visuals are important for effective collaboration.\n\nFor more than a decade, Lucid has been putting visuals at the center of collaboration, powering teams, whether in-office, hybrid, or fully remote, to collaborate, stay aligned and build across workflows. Lucid\u2019s newest capabilities address a lot of the needs employees have in order to work more effectively and boost productivity in a hybrid environment.\n\nSupercharge team alignment with enhanced AI capabilities\n\nAI has proven itself a mainstay in today\u2019s business operations, with 75% of organizational leaders whose teams use AI say it has improved their collaborative abilities. When incorporating AI became a mainstream focus for companies and teams, Lucid was ahead of the curve. For over a decade, Lucid has provided an intelligent and comprehensive visual collaboration platform that supports workers at every phase of a project. And with Lucid\u2019s latest AI features and plugins, workers can get more done faster by generating new visuals and summaries of their Lucid documents.\n\nFor instance, Lucid\u2019s Collaborative AI will quickly suggest ideas and summarize content. Taking these AI capabilities further, teams can now use AI prompts in Lucidchart to auto-generate a flowchart, sequence diagram, class diagram, or entity relationship diagram. Through these user-generated prompts, users can also iterate and update each specific aspect of their AI-generated diagram until they have the exact visual they need.\n\nAs an example, UX/UI teams can auto-generate a flowchart for unique customer support systems by personalizing their prompts with the specific steps and visuals they need the end product to include. This could include adding terms like \u201cassign support ticket\u201d or \u201cescalate complex issues\u201d to the prompt. Lucid\u2019s generate a diagram functionality will automatically build out the flowchart to account for those steps, saving the team valuable time to start executing.\n\nThe introduction of the Microsoft Copilot plugin with Lucid also brings AI right into a teams\u2019 collaboration workflows. This integration allows teams to retrieve Lucid documents and create AI-generated summaries of those documents. For example, suppose a couple of teammates can\u2019t join an important brainstorm. In that case, they can access relevant Lucid documents directly on Copilot and ask for AI-generated summaries to help them understand where projects are at, what their team is thinking, and what next steps are.\n\nCoordinate in a shared space with team hubs\n\nAccording to Lucid\u2019s recent survey, 75% of employees say ineffective communication or collaboration is a barrier to innovation within their organization. To overcome that, Lucid brings teams together into a shared, centralized place called team hubs, a new team experience that allows team members to easily track progress, initiate and discuss work, and make decisions faster.\n\nTeam hubs offer a one-stop shop to access all team documentation. A team manager can create a team hub and add their direct reports to provide them with full access to critical documentation and helpful resources needed to move projects forward and get the latest updates more easily. Users can even create team hubs for specific project groups or scrum teams to improve cross-functional collaboration.\n\nWithin the team hub, users can also pin a team space, the team\u2019s home base for coordination. For example, a scrum team might pin their sprint planning board since the team would regularly return to and collaborate on that document to understand what goals they will accomplish during the sprint.\n\nBy powering AI-enabled collaboration and streamlining team communication, Lucid is leading the way in determining what effective collaboration looks like for hybrid teams by building the advanced capabilities teams need today to stay aligned, innovative, and productive across their workflows.\n\n\n\nTo learn more about how Lucid helps teams align to build the future faster, visit lucid.co.\n\nThis article is brought to you by TechCrunch Brand Studio. Contact us here to get your sponsored content on TechCrunch.",
        "url": "https://techcrunch.com/sponsor/lucid-software/lucid-softwares-product-capabilities-drive-productivity-and-innovation-for-teams/",
        "category": 1,
        "summary": "To overcome that, Lucid brings teams together into a shared, centralized place called team hubs, a new team experience that allows team members to easily track progress, initiate and discuss work, and make decisions faster. With this being the top concern, Lucid Software\u2019s Hybrid Workplace Whiplash Survey of more than 2,500 knowledge workers discovered that companies have tried to address productivity concerns by expanding their tech stacks, with 45% of workers using five or more tools to complete assignments and get their jobs done. By powering AI-enabled collaboration and streamlining team communication, Lucid is leading the way in determining what effective collaboration looks like for hybrid teams by building the advanced capabilities teams need today to stay aligned, innovative, and productive across their workflows."
    },
    {
        "title": "Middle-Mile Infrastructure Is the Next Frontier for Digital and AI Equity",
        "text": "When you picture the internet landscape in America, you probably see a map of millions of high-speed internet \u201croads\u201d connecting to every business, household, and individual. Now, take that image and remove 40% of the roads and endpoints. That represents the digital divide, the percentage of businesses, households, and individuals\u2014largely in rural communities\u2014that do not have access to reliable internet connectivity.\n\nThis paradox is further heightened by the rapid rise of AI. The AI revolution is promising to lead us into a period of abundance\u2014a time when anyone can come up with any idea and make it happen. And yet, the digital divide means that not only will this promise not truly be available to all, but AI may also not be able to reach its full potential.\n\nLuckily, middle-mile infrastructure holds the power to solve both of those challenges.\n\nWhat is Middle-Mile Infrastructure?\n\nStill have that mental image of the internet in America? Zoom in on the points of connection between the massive metropolitan highways and the smaller country roads that extend out to rural areas. These points of connection are the middle-mile.\n\nMiddle-mile infrastructure is any broadband infrastructure that does not connect directly to an end-user location. It is the \u201cinterstate highways of the Internet, carrying large amounts of data at high speeds to connect entire communities.\u201d\n\nThese middle-mile connections are critical in extending the reach of high-speed internet in rural areas, where the last-mile connections may be sparse and challenging to establish. So critical, in fact, that the federal government has allocated $980 million to fund projects for the construction, improvement, or acquisition of middle-mile infrastructure to connect areas that are unserved or underserved to the Internet backbone.\n\nSimultaneously, we\u2019re seeing additional interest in rural communities from hyperscalers \u2014 the Googles and Amazons of the world responsible for ushering in the first wave of AI. Why? Because AI workloads require a massive amount of data, and hyperscalers need somewhere to put it.\n\nHyperscalers are investing millions in data center campuses to house this data, but the space and power requirements for these campuses are pushing them out of the large metropolitan areas and into more rural locations\u2014where space and power are plenty and cheap. But, these data centers also need high-speed internet\u2014and lots of it.\n\nSo what does this mean? Middle-mile infrastructure will be the next frontier for providing equitable access to unserved and underserved rural areas while enabling the next wave of the AI revolution.\n\nWhat Does Middle-Mile Infrastructure Mean for Digital and AI Equity?\n\nWe know that the internet is the gateway to societal progress. It enables access to critical daily needs like education, healthcare, and emergency services. It also supports significant economic opportunities. With the promise of AI, the internet has the potential to bring even greater benefits to communities \u2014 forecasting climate risk, eliminating fraud, improving disease detection, and more. But enabling any of this starts first with the middle mile.\n\nBy investing in the middle-mile infrastructure, we can drive:\n\n1. Faster deployment of AI.\n\nAI has the potential to transform our digital economy at an order of magnitude reminiscent of the Cloud and the early days of the internet itself. But these transformations require infrastructure that is robust and sophisticated enough to support\u2014and that infrastructure isn\u2019t built overnight.\n\nEven today, during the third industrial revolution, widespread internet availability is still behind pace\u2014illustrated by the 40% of Americans still lacking access. In order to capture the unique benefits of the fourth industrial revolution \u2014 i.e., AI \u2014 digital infrastructure has some catching up to do.\n\nConsider this: At the pace AI is growing, compared to the pace digital infrastructure is typically deployed, we will run out of capacity before AI is able to actually take flight. Now consider that the AI revolution will rely on connectivity in rural America, and we\u2019ll find ourselves even further behind.\n\nBy prioritizing investment in the middle-mile backbone, we are providing the critical runway to accelerate the deployment of AI and ensure we have ample infrastructure in place to allow this technology to scale and be accessible to all Americans.\n\n2. Less bias for the future of AI\n\nWhile many expect AI to be available to the masses tomorrow, it is going to take years of training AI language learning models (LLMs) to ensure they can deliver the impact expected of them. However, to ensure accurate modeling, AI needs access to diverse populations.\n\nAI, outside of the promise of superintelligence, is still a human construct and requires diverse inputs to be accurate and equitable. Enabling access to AI tools in rural communities will help these LLMs to be trained without bias.\n\n3. More economic opportunity for rural America\n\nThe COVID-19 pandemic highlighted the importance of participation in the digital economy for today\u2019s workforce. Access to high-speed and reliable internet at home and for local businesses is no longer a luxury but a necessity. Critical applications like email and Zoom are now ubiquitous in daily life.\n\nMiddle-mile infrastructure will make access to the digital economy possible for rural America and bring more jobs for local communities to build this infrastructure. Further, it has the potential to stimulate economic growth by attracting businesses and supporting local enterprises.\n\nWhile the impacts of delivering universal internet access are clear, no single entity can do it alone. It is a collective effort requiring participation, partnership, and collaboration between governments, infrastructure providers, businesses, and communities.\n\nAs aforementioned, connectivity is the cornerstone of societal, economic, and technological progress. By prioritizing this collaboration and expanding equitable connectivity, we can accelerate the advancement of (and most importantly, access to) AI and other next-generation technologies that will positively impact our world.\n\nZayo Group is at the forefront of this transformative effort, providing robust connectivity solutions that are essential for bridging the digital divide and fostering technological equity. Join us in empowering communities across the nation by learning more about how Zayo\u2019s initiatives in middle-mile infrastructure can drive societal progress and economic growth. Together, we can build a more connected and technologically inclusive future. Learn more about our efforts here.\n\nBill Long is the Chief Product & Strategy Officer at Zayo, a leading global communications infrastructure provider. With an extensive background in telecommunications infrastructure, Bill excels in driving significant digital transformations while delivering cutting-edge technology solutions.",
        "url": "https://techcrunch.com/sponsor/zayo-group/middle-mile-infrastructure-is-the-next-frontier-for-digital-and-ai-equity/",
        "category": 1,
        "summary": "By prioritizing investment in the middle-mile backbone, we are providing the critical runway to accelerate the deployment of AI and ensure we have ample infrastructure in place to allow this technology to scale and be accessible to all Americans. So critical, in fact, that the federal government has allocated $980 million to fund projects for the construction, improvement, or acquisition of middle-mile infrastructure to connect areas that are unserved or underserved to the Internet backbone. It is the \u201cinterstate highways of the Internet, carrying large amounts of data at high speeds to connect entire communities.\u201d\n\nThese middle-mile connections are critical in extending the reach of high-speed internet in rural areas, where the last-mile connections may be sparse and challenging to establish."
    },
    {
        "title": "Is your browser a massive vulnerability for cyberattacks?",
        "text": "The rise of SaaS-based applications, cloud infrastructure, and remote work have accelerated the significance of the browser in the workplace. Today, it\u2019s the most used business application by far\u2014but it\u2019s also the most vulnerable, raising an important question for CIOs, enterprise leaders, and IT ops teams across countless industries.\n\nIf the browser is essential to business, can it also become enterprise-competent?\n\nEnterprise businesses, especially finance, healthcare, and government entities that handle highly sensitive information cannot afford to risk the financial and reputational costs of crippling cyberattacks. And now, they don\u2019t have to: CyberArk Secure Browser provides secure access to SaaS and cloud-based apps on any device, going beyond login security to safeguard enterprises at every step.\n\n\n\nBrowsers are today\u2019s greatest attack vector\n\n\n\nIt\u2019s no surprise why browsers are a business-critical component: Its versatility makes it a no-brainer for improving productivity, with 83% of employees saying they can accomplish most or all of their work within a browser.\n\nBut as the shift to disparate, browser-based workplaces became the new normal, enterprises were forced to address a new security perimeter to manage. Company information used to be stored locally, on-site, disconnected from the rest of the world, giving CIOs and IT teams peace of mind that their data was locked away in safe, segregated locations. Now, much of that information is stored online. \u201cTraditional endpoint and network-based controls are lacking to adapt to the new business norm, where all of the organization\u2019s data is in SaaS and the cloud,\u201d says Gil Rapaport, Chief Solutions Officer, CyberArk.\n\nBrowsers are typically separate from the rest of an organization\u2019s identity security infrastructure, which compounds the problem by creating difficult-to-manage blind spots. This makes browsers a primary target for attackers to infiltrate business systems: In the past year, there\u2019s been a 354% increase in account takeover attacks, as well as a 50% increase in cyberattacks targeting Google Chrome.\n\nIt\u2019s even worse for businesses with virtual desktop infrastructures and bring-your-own-device policies. Unmanaged devices, like personal phones and laptops, are an easy gateway for bad actors to steal sensitive data\u2014especially because 78% of US office workers say they use the same device to access confidential information as they do for personal browsing.\n\nOrganizations need a stronger, purpose-built security solution. \u201cThey need to treat the browser as a core piece of their identity security infrastructure, and it can\u2019t be just another standalone tool for overwhelmed IT teams to manage,\u201d Rapaport says. That\u2019s exactly why CyberArk created the Secure Browser\u2014because enterprises need to protect every endpoint without sacrificing the benefits of the browser. CyberArk Secure Browser sets a new standard for enterprise-level security by prioritizing productivity and protection, offering professionals a safe and seamless way to get their work done.\n\nConsumer browsers don\u2019t meet enterprise security needs\n\n\n\nInfostealer attacks, which often use browsers to steal logins and other data, skyrocketed 266% in 2023. Most attacks were done using cookie stealing tactics, in which attackers swipe files websites use to remember users. This is less surprising when we consider the fact that consumer browsers were made to access the internet, not access and work with sensitive information. \u201cWe\u2019re seeing an increase in post-authentication attacks, which traditional identity and access management is incapable of recognizing and stopping,\u201d Rapaport explains. \u201cBy monitoring the complete identity lifecycle, including every action performed by the browser, you can see and stop these threats.\u201d\n\n\n\nConsumer browsers prioritize convenience and data collection over robust security, conflicting with enterprise-level data protection standards. Plus, they\u2019re notoriously difficult to integrate with other security tools, leaving unmanaged devices open for attack\u2014unlike in an enterprise setting where, by default, no data should be shared. CyberArk Secure Browser eliminates this risk with a unified browser setting with all the security tools necessary and fully integrated to run an enterprise.\n\n\n\nWith end-to-end security that adapts to the user, CyberArk offers a contrasting approach to typical browser-based work environments. \u201cCyberArk\u2019s Identity Security Platform is agile, responding to actual behavior for true protection. Nobody wants an enterprise to be a Big Brother monitoring their every move,\u201d Rapaport says. \u201cThe CyberArk Secure Browser, specifically, provides the optimal balance between security, productivity, and privacy for both the user and enterprise data.\u201d\n\nImage Credits: Yuichiro Chino (opens in a new window) / Getty Images\n\nThe balance between security and comfort reflects the benefits of an always-on tool. Enterprises need to know they\u2019re safe from attacks occurring pre- and post-authentication across the complete identity lifecycle, and employees don\u2019t want to be weighed down by cumbersome protection measures. CyberArk Secure Browser intelligently collects behavioral data to flag threats like compromised devices or potential IP theft, ensuring security is present when and where it\u2019s needed, delivered with a familiar interface for a smooth user experience and ease of adoption.\n\n\n\nOf course, the need for protection is even greater for high-risk users. C-level executives have elevated access to their business\u2019s most sensitive resources and information\u2014information that, if in the hands of attackers, could pose massive costs to the business. CyberArk Secure Browser prioritizes end-user privacy by blocking third-party data sharing and facilitates a passwordless experience for high-risk users. CyberArk solutions can even be used alongside consumer browsers to secure high-risk access, ensuring safety without having to reshape companies\u2019 current security tools.\n\n\n\nConsumer browsers streamline work, but often leave sensitive data exposed. Enterprises need security woven into every workflow aspect, especially within the browser. CyberArk Secure Browser addresses these concerns with integrated protection. It prevents cookie theft, replaces passwords with dynamic tokens, blocks unauthorized data transfers, grants one-click access to critical resources, and tightly integrates with your existing identity security solutions. Using a purpose-built browser like CyberArk Secure Browser offers enterprises a powerful tool to proactively secure their most valuable assets and workflows.\n\n\n\nLearn how CyberArk Secure Browser can protect your organization\u2019s most critical data.",
        "url": "https://techcrunch.com/sponsor/cyberark/is-your-browser-a-massive-vulnerability-for-cyberattacks/",
        "category": 2,
        "summary": "Unmanaged devices, like personal phones and laptops, are an easy gateway for bad actors to steal sensitive data\u2014especially because 78% of US office workers say they use the same device to access confidential information as they do for personal browsing. \u201cThe CyberArk Secure Browser, specifically, provides the optimal balance between security, productivity, and privacy for both the user and enterprise data.\u201d\n\nImage Credits: Yuichiro Chino (opens in a new window) / Getty Images\n\nThe balance between security and comfort reflects the benefits of an always-on tool. CyberArk Secure Browser intelligently collects behavioral data to flag threats like compromised devices or potential IP theft, ensuring security is present when and where it\u2019s needed, delivered with a familiar interface for a smooth user experience and ease of adoption."
    },
    {
        "title": "Unleash the Full Potential of Your Time Series Data",
        "text": "Businesses of all sizes are generating massive amounts of real-time data across all their systems, devices, and services. All of this time-stamped data needs real-time analysis to identify patterns and insights. A purpose-built time series database is a powerful tool for achieving this, providing valuable and actionable insights on trends over time.\n\nIn this recent session, two time series data industry leaders \u2013 InfluxData Founder and CTO, Paul Dix, and AWS General Manager for Amazon Timestream and Amazon Neptune, Brad Bebee \u2013 are joined by moderator Andrew Lamb, Staff Engineer at InfluxData, to discuss:",
        "url": "https://techcrunch.com/sponsor/influxdata/unleash-the-full-potential-of-your-time-series-data/",
        "category": 2,
        "summary": "Businesses of all sizes are generating massive amounts of real-time data across all their systems, devices, and services. A purpose-built time series database is a powerful tool for achieving this, providing valuable and actionable insights on trends over time. In this recent session, two time series data industry leaders \u2013 InfluxData Founder and CTO, Paul Dix, and AWS General Manager for Amazon Timestream and Amazon Neptune, Brad Bebee \u2013 are joined by moderator Andrew Lamb, Staff Engineer at InfluxData, to discuss:"
    },
    {
        "title": "What happens when virtual worlds impact the real?",
        "text": "Scenes showing how virtual worlds affect real life splashed Europe\u2019s largest advertising display during Dassault Syst\u00e8mes\u2019 weeklong campaign at London\u2019s Piccadilly Circus.\n\nA human heart beating inside the rib cage. An assembly line\u2019s robotic arm carrying a curved pane of glass. An eVTOL circling a city of tomorrow. An astronaut exploring outside a lunar base. What do these disparate scenes have in common?\n\nFor one thing, they were all part of a recent display at London\u2019s Piccadilly Circus showcasing Dassault Syst\u00e8mes\u2019 virtual twin experiences. For another, they\u2019re present and future examples of how virtual worlds affect real life.\n\nThe scenes, in a 3D-effect immersive video, introduce Dassault Syst\u00e8mes\u2019 solutions in ways they\u2019re actually utilized to drive sustainable innovation across industries that impact daily life around the world.\n\nWhat does Dassault Syst\u00e8mes actually do?\n\nFor more than 40 years, Dassault Syst\u00e8mes been developing the enabling technology for the science-based digital replicas we call virtual twins. It\u2019s a continuous mission to harmonize product, nature and life.\n\nVirtual twins let you visualize, model and simulate the entire environment of sophisticated experience. They facilitate sustainable business innovation across the full product lifecycle.\n\nEmpowered by virtual twins, designers don\u2019t just design anymore; they can design for disassembly. Thanks to powerful features like lifecycle assessment, they\u2019re able to understand the environmental and economic impact of every decision they make \u2013 from sourcing materials to packaging and distribution to recyclability.\n\nIt\u2019s not just products. In manufacturing industries, the twins are able to feedback data from deployed products, creating a constant cycle of improvement, which helps improve not only the products but the equipment and processes used to produce the goods. Simply put: They help companies make better decisions.\n\nForward thinking companies have used virtual twins to inform predictive maintenance and ergonomic improvements. They\u2019ve even used computational fluid dynamics to figure out how to safely re-open their cafeterias during the COVID-19 pandemic.\n\nIn the life sciences and healthcare sector, combining virtual technologies, analytics and artificial intelligence creates the conditions to revolutionize how the human body is treated. From clinical trials to patient care, virtual twins can be applied to imagine, test and manufacture better medical devices to help practitioners prepare for and execute new surgical techniques.\n\nDuring the pandemic, a host of hospitals used virtual twins to understand the computational fluid dynamics of how airborne disease spread through the facility, allowing them to design safer conditions for patients, staff and visitors. The drug discovery world is in the midst of a major transformation.\n\nWhen it comes to cities, some of the most forward-thinking are using virtual twins to think like businesses. In other words, they\u2019re using virtual twins to make data-based decisions that should improve operations while trying to improve the user experience.\n\nWe can help major European cities understand how a temporary HOV (high occupancy vehicles) lane would impact traffic, pollution dispersion and noise prior to implementing a plan.\n\nMoving off planet: For years we\u2019ve been helping \u201cNew Space,\u201d companies entering the space that\u2019s no longer the exclusive domain of national governments. Now, we\u2019re in position to help New Space players accelerate In-space Servicing, Assembly and Manufacturing (ISAM) development, building capabilities to remove debris and repurpose spacecraft materials for new uses.\n\nHow Piccadilly\u2019s virtual scenes affect real life\n\nThose scenes displayed at Piccadilly Circus were dramatic. They were designed to be attention grabbing. What they weren\u2019t is unrealistic.\n\nThe beating heart offers a glimpse of The Living Heart Project, a pioneering research initiative using realistic modeling and simulation to revolutionize cardiovascular science. The robotic arm on the assembly line is a real example of the factory virtual twins automakers and OEMs from the aerospace industry have been using for decades. The city scene reflects a range of applications for virtual twins to harmonize product, nature and life in an urban environment \u2013 from flight plans for flying cars to understanding the environmental impact of adding an HOV lane to a main thoroughfare.\n\nAnd space. Thanks to virtual twins, we\u2019re prepared for the erstwhile \u201cfinal frontier\u201d to become \u201cSpace: The Farming Frontier.\u201d That structure in the background behind the spaceman? It\u2019s a biopod, similar to the ones companies like Interstellar Lab are developing to grow food in space and preserve biodiversity here on Earth.\n\nAnd taking a step back it\u2019s clear that our 3D experiences touch every aspect of daily life. We offer solutions that empower businesses and individuals to create sustainable products and services to accelerate sustainable innovation and help humanity thrive.\n\nThis article was created by TechCrunch Brand Studio. Learn more about partnering with TechCrunch Brand Studio to promote your content.",
        "url": "https://techcrunch.com/sponsor/dassault-systemes/what-happens-when-virtual-worlds-impact-the-real/",
        "category": 1,
        "summary": "The scenes, in a 3D-effect immersive video, introduce Dassault Syst\u00e8mes\u2019 solutions in ways they\u2019re actually utilized to drive sustainable innovation across industries that impact daily life around the world. During the pandemic, a host of hospitals used virtual twins to understand the computational fluid dynamics of how airborne disease spread through the facility, allowing them to design safer conditions for patients, staff and visitors. The city scene reflects a range of applications for virtual twins to harmonize product, nature and life in an urban environment \u2013 from flight plans for flying cars to understanding the environmental impact of adding an HOV lane to a main thoroughfare."
    },
    {
        "title": "It\u2019s More Than GPUs: Suno Founder Talks Infrastructure Choices for Generative AI Startups",
        "text": "Startup Suno AI helps consumers generate their own music online with a very simple interface. Unlike many startups that focus on text-based generative AI, Suno takes on the very different problem of building, testing, and serving models for audio. The Cambridge, Mass. company employs Oracle Cloud Infrastructure (OCI) AI infrastructure and other services to create and run these models.\n\nBelow, Leo Leung, Vice President, Oracle Tech and OCI chats with Mikey Shulman CEO of Suno AI, about what generative AI startups want and need from their providers. The interview was edited for length and clarity.\n\nLeung: What should AI startup founders be thinking about when it comes to foundational technology and infrastructure?\n\nShulman: The first thing would be picking very carefully where you want to innovate and that really means picking very carefully where you don\u2019t want to innovate. Before Suno, we learned that things like system administration aren\u2019t really places where you move the needle. So, we focus all day and all night on figuring out the right way to model audio and plugging that in. We are open about the fact that we borrow so much from the open-source community for things like making transformer models on text and it\u2019s lovely to not have to reinvent the wheel there. We don\u2019t just think about models that map A to B since that\u2019s not how most humans think about interacting with these things. Ultimately, we are trying to build products that people love to use and figuring out what the foundational technology is to help ensure a pleasurable experience for the user.\n\n\n\nLeung: It would be interesting to hear more about the data of music and the different types of workloads music represents. Can you talk a bit more about that and how that maybe influenced your choice of infrastructure or technology underneath?\n\nShulman: Music, or audio in general, is very far behind images and text in terms of modeling. The key problem is how to represent audio in a way that should be intelligible to transformers? There are hiccups, one being transformers work on what are called tokens, but they\u2019re discreet things and audio is not a discreet signal, it\u2019s a continuous wave. Furthermore, the problem for audio, especially high-quality audio, is it\u2019s sampled at either 44 kilohertz or 48 kilohertz \u2014one second of audio will have roughly 50,000 samples. That\u2019s just way too many samples and we need some way to take this very high frequency signal and kind of smush it down into something more manageable. We spend a lot of time innovating on what is the right way to take this very quickly sampled continuous signal and represent it as a much more slowly sampled discreet signal.\n\nLeung: Did that influence the kind of infrastructure you needed or are you thinking about the same infrastructure but again trying to reduce the data to a place where you could put it into those models?\n\nShulman: Definitely. Just like any other machine learning model, these things aren\u2019t super cheap to run. You want to do things quickly both in production, but also even when you\u2019re just experimenting. We are constantly trying to make things better so having some elasticity of compute, having availability of compute is important.\n\nLeung: That is a good lead into my next question, which is what needs have changed for you and the company that you couldn\u2019t have predicted as you scaled?\n\nShulman: When we started the company, the first thing we did was buy the biggest GPU box that you can safely plug into a home outlet and start to train the initial models there. That box sits unplugged in the next room. We did not really anticipate just how much scale matters for your models, your experiment throughput, and the way you roll things out to people. This is a cliche, but humans are very bad at reasoning about exponential growth. And so, despite having a PhD in physics, I too am very bad about reasoning about exponential growth. That certainly caught us by surprise. We also did not realize the extent to which products can come to market that take care of some of these concerns. For example, when we first logged into our Oracle cluster, it was like you just had everything we needed there. It was kind of a weird moment because it was not just a machine that you\u2019re starting to do everything. It is a cluster. It is like this was a product built for people like me. I get all the creature comforts that I need to do really good work.\n\nLeung: When I talk infrastructure, everyone gravitates just towards the GPUs, but there\u2019s more than just processors. From your perspective, what other important components of AI infrastructure do you leverage?\n\nShulman: I think one concentric circle out from GPUs is all the fit and finish that is on our cluster. Whether that is the ability to add users, launch jobs, have network-attached storage, have fast SSDs, all the things that let us utilize the GPUs, that\u2019s amazing. Storage buckets for larger bits of data or user-generated content, etc. We need all kinds of things to make the products run smoothly without GPUs on the training side. Whether that\u2019s a service to deliver content quickly, whether it\u2019s user management and queue management and lots of building blocks\u2013some of them we build, some of them we buy.\n\nLeung: What are those special problems and solutions that you feel are specific to generative AI?\n\nShulman: This is an area that is quickly evolving and things that you can take for granted today, you\u2019re not necessarily sure you can take for granted tomorrow. Can I fit my model on one card today? Maybe I can and in a month I can\u2019t which would screw everything up. Something like Modal is amazing. It lets us launch workers on GPUs extremely easily.\n\nLook, generative AI is very compute intensive, and GPUs are annoying for software developers. They break a very sacred hardware-software abstraction barrier, and that has a way of rearing its head everywhere. I think that\u2019s why a lot of this stack can be a little difficult to navigate.\n\nBut it\u2019s not all GPUs, there\u2019s also a ton of CPU work that goes into these things. There\u2019s audio processing in general. When I daydream, it\u2019s like maybe my cloud provider has made me not really care what cards I\u2019m using. That would be swell the same way I don\u2019t necessarily care if I get spun up on an Intel CPU or an AMD CPU in my cloud machine. Why should I care exactly what card it is?\n\nLeung: Going beyond the tech, what other support should AI startups be looking for from their service providers?\n\nShulman: We\u2019re always asking: \u201cHow much pain can my provider take away so I can focus on the stuff that is my comparative advantage?\u201d Every company\u2019s answer here is going to be different. In a more research-heavy company, there\u2019s going to be a lot of research tooling and experiment management and job management, etc. In a less research-heavy company, maybe it\u2019s the world\u2019s fastest CDN because I need to deliver content to people. I\u2019m always thinking about what are we doing that we shouldn\u2019t be doing and how do we stop doing that? And very often there are solutions out there, you just have to know where to look.\n\nLeung: My final question is how should fast-growth AI companies think about costs?\n\nShulman: For AI companies, a big fraction of your spend is compute, so that\u2019s something you have to think about judiciously. Sometimes you can find some slightly cheaper solutions, but the cost savings can be far outweighed by the reliability and the flexibility of going with a real provider. There\u2019s a lot of things popping up and going away, and we want to be around in 10 years so that means we should probably be trying to do business with companies that are also going to be around in 10 years. If you have a plan to start using somebody and then get off them in a year, that needs to be a very conscious decision and not one that we should make lightly. That\u2019s part of why we picked OCI \u2013 trust.\n\nAre you building your company and evaluating cloud provider options? Learn more about OCI\u2019s broad selection of ISVs that offer AI services to help accelerate your development and deployment here.",
        "url": "https://techcrunch.com/sponsor/oracle/its-more-than-gpus-suno-founder-talks-infrastructure-choices-for-generative-ai-startups/",
        "category": 1,
        "summary": "Unlike many startups that focus on text-based generative AI, Suno takes on the very different problem of building, testing, and serving models for audio. Shulman: When we started the company, the first thing we did was buy the biggest GPU box that you can safely plug into a home outlet and start to train the initial models there. Below, Leo Leung, Vice President, Oracle Tech and OCI chats with Mikey Shulman CEO of Suno AI, about what generative AI startups want and need from their providers."
    },
    {
        "title": "How to Evolve Your Tech and Staff Strategies for Future Rounds",
        "text": "TechCrunch was proud to host Sand Technologies at Early Stage in Boston on April 25, 2024. Here\u2019s an overview of their breakout session.\n\nIn this session, Sand Technologies Managing Director, Brad Stanton, discussed how to be an operational unicorn, not just a commercial one, even when your team and tech feel strapped. This session also explored practical but meaningful strategies early-stage companies can use to meet technical and staffing needs that will stay in flux across their growth journey.\n\nSPEAKER\n\nBrad Stanton, Managing Director, Sand Technologies\n\nBrad Stanton is Managing Director of Business Development at Sand Technologies. He has more than 25 years of consulting and software-development experience with leading global brands including Dell, Accenture and Hewlett-Packard. Brad has led high-performing teams in a number of capacities, from staffing and engineering process design to RevOps and channel formation. Based in Texas, he helps companies looking to harness AI talent and solutions in India, LATAM, Eastern Europe, Africa and the USA.",
        "url": "https://techcrunch.com/sponsor/sand-technologies/how-to-evolve-your-tech-and-staff-strategies-for-future-rounds/",
        "category": 3,
        "summary": "Based in Texas, he helps companies looking to harness AI talent and solutions in India, LATAM, Eastern Europe, Africa and the USA. In this session, Sand Technologies Managing Director, Brad Stanton, discussed how to be an operational unicorn, not just a commercial one, even when your team and tech feel strapped. This session also explored practical but meaningful strategies early-stage companies can use to meet technical and staffing needs that will stay in flux across their growth journey."
    },
    {
        "title": "Hard Tech for Early-Stage Founders: HAX Invests in Startups Solving the Hardest Problems in Climate, Industrial Independence, and Healthcare",
        "text": "TechCrunch was proud to host HAX at Early Stage in Boston on April 25, 2024. Here\u2019s an overview of their breakout session.\n\nThere\u2019s no tougher, early stage startup category than hard tech, and no one knows that better than SOSV\u2019s HAX team, which has backed more than 300 startups with capital and intensive design, scientific advancement and commercial engineering over the past 12 years. In this session, Duncan Turner, SOSV GP and HAX Managing Director, and Dr. Susan Schofer, HAX Chief Science Officer, discussed the hard tech / physical sciences ecosystem today, how HAX\u2019s full-stack technical team turns unique IP from research into commercial reality, and what hard tech investing categories excite the HAX team. Duncan and Susan also provided an update on HAX\u2019s new, 35,000 sq foot office in Newark, NJ, where 30 startups are currently at work.\n\nSPEAKERS\n\nSusan Schofer, SOSV Partner and HAX Chief Science Officer, HAX\n\nSusan was an NSF Postdoctoral Fellow at Stockholm and Uppsala Universities, where she worked to develop catalyst systems for artificial photosynthesis. She holds a Ph.D. in chemistry from Caltech and an Sc.B. in chemistry from Brown.\n\nDuncan Turner, SOSV General Partner and Managing Director of HAX\n\nDuncan is a General Partner at SOSV, and the Managing Director of HAX, the world\u2019s first and largest VC-backed program for hard tech. He has invested in over 100 hard tech companies and serves on multiple boards in the climate, industrial and healthcare sectors. Duncan has an extensive entrepreneurial background and deep experience fundraising and growing businesses across the globe. He has taken numerous technologies to market in various industries. Before joining SOSV, he led design and engineering strategy projects for Fortune 500 companies at the global innovation firm IDEO. Duncan obtained his Master\u2019s from the Royal College of Art & Imperial College. His design and engineering work has won multiple awards and is included in the permanent collection at The Museum of Modern Art. He has a deep passion for new technologies and engineering breakthroughs that can benefit our planet.\n\nSabriya Stukes, SOSV Partner and IndieBio Chief Science Officer, SOSV\n\nSabriya is a Partner at SOSV and Chief Scientific Officer for IndieBio NY. Prior to joining, she was Operations Director for Stellate Therapeutics, a biotech company developing microbiome-derived therapeutics to treat neurodegenerative diseases. After earning her PhD in Biomedical Sciences from the Albert Einstein College of Medicine, she was the founding Associate Director for the Master\u2019s in Translational Medicine (MTM) program at The City College of New York, NYC\u2019s first and only graduate degree that educates and trains scientists and engineers in the hands-on process of medical technology commercialization and healthcare innovation. A microbiologist, educator, and science communicator, her expertise is in working with individuals to identify unmet community needs, design sustainable clinical solutions, think critically about the world around them, and craft compelling scientific narratives. She also has worked for over a decade in fostering equitable and inclusive environments in the STEM disciplines and thinks deeply about how we can build sustainable healthcare solutions that work for all and not just some.",
        "url": "https://techcrunch.com/sponsor/hax/hard-tech-for-early-stage-founders-hax-invests-in-startups-solving-the-hardest-problems-in-climate-industrial-independence-and-healthcare/",
        "category": 1,
        "summary": "There\u2019s no tougher, early stage startup category than hard tech, and no one knows that better than SOSV\u2019s HAX team, which has backed more than 300 startups with capital and intensive design, scientific advancement and commercial engineering over the past 12 years. In this session, Duncan Turner, SOSV GP and HAX Managing Director, and Dr. Susan Schofer, HAX Chief Science Officer, discussed the hard tech / physical sciences ecosystem today, how HAX\u2019s full-stack technical team turns unique IP from research into commercial reality, and what hard tech investing categories excite the HAX team. After earning her PhD in Biomedical Sciences from the Albert Einstein College of Medicine, she was the founding Associate Director for the Master\u2019s in Translational Medicine (MTM) program at The City College of New York, NYC\u2019s first and only graduate degree that educates and trains scientists and engineers in the hands-on process of medical technology commercialization and healthcare innovation."
    },
    {
        "title": "From Inception to Cash. How I Wandered into an Idea and Jumpstarted a Company",
        "text": "TechCrunch was proud to host HomeHQ.ai at Early Stage in Boston on April 25, 2024. Here\u2019s an overview of their breakout session.\n\nIn this session, HomeHQ.ai demonstrated how they rapidly went from absolute zero to paying customers. How to ignite interest from customers and investors. How to get your first deals. How to build an MVP that captivates. How to raise initial capital from investors. How to pick a cofounder and build a team. How to build momentum. How to know when to double down and go all in. How to leverage every opportunity for success and generate momentum for your new company.\n\nSPEAKERS\n\nGabi Monico, Senior Associate, Primary VC\n\nGabi is a Senior Associate at Primary, where she focuses on Built World, SMB Tech, and Consumer businesses. Prior to joining Primary, she was an investor at Fractal Software where she led incubations of vertical software companies. Gabi started her career as a management consultant at the Boston Consulting Group, spending the bulk of her tenure in the Technology, Media, and Telecom practice area. She holds an AB in Economics from Harvard University. Originally from Brazil, she\u2019s always on the search for a decent Brazilian Steakhouse in New York. Outside of work, Gabi enjoys traveling, cooking, workout classes, and reading great novels.\n\nVinny Romano, Co-founder and COO, HomeHQ.ai\n\nVinny is the co-founder of HomeHQ.ai, an innovative AI tool for real estate agents, offering personalized AI assistants and insights to help agents work more efficiently and close more deals. With a rich background in digital media, focusing on analytics and paid media, Vinny previously played a crucial role in evolving a TV company into a digital media leader with highly successful social media and direct-response ads businesses. Passionate about demystifying data for better business decisions, Vinny combines his expertise in analytics with technology to transform real estate practices, proving his commitment to driving success through data-driven solutions.\n\nOliver Palnau, Co-Founder & CEO, HomeHQ.ai\n\nOliver Palnau is a co-founder of HomeHQ.ai along with Vinny Romano. Oliver\u2019s entrepreneurial journey accelerated at the age of 23, diving into the real estate market by flipping his first house. This initial venture led him to redevelop over 20 properties, gaining invaluable insights into the housing industry\u2019s intricacies and potential for innovation. Feeling burned out from building in real estate, Oliver started building in robotics with the goal of building a fleet of humanoid and quadruped robots designed to bring efficiency and innovation to the building process. This exploration into robotics served as a basis into the world of applied AI, tying together his hands-on experience in homebuilding with the cutting-edge possibilities of AI. His approach is grounded in practicality, leveraging AI to create tangible solutions that enhance the lives of millions. He is currently building AI Assistants and AI Analytics for Real Estate Agents and Brokerages at HomeHQ.ai.",
        "url": "https://techcrunch.com/sponsor/homehq-ai/from-inception-to-cash-how-i-wandered-into-an-idea-and-jumpstarted-a-company/",
        "category": 3,
        "summary": "Vinny Romano, Co-founder and COO, HomeHQ.ai\n\nVinny is the co-founder of HomeHQ.ai, an innovative AI tool for real estate agents, offering personalized AI assistants and insights to help agents work more efficiently and close more deals. With a rich background in digital media, focusing on analytics and paid media, Vinny previously played a crucial role in evolving a TV company into a digital media leader with highly successful social media and direct-response ads businesses. Passionate about demystifying data for better business decisions, Vinny combines his expertise in analytics with technology to transform real estate practices, proving his commitment to driving success through data-driven solutions."
    },
    {
        "title": "Preparing to Raise: Cap Table Best Practices to Help You Close Fast",
        "text": "TechCrunch was proud to host Fidelity Private Shares at Early Stage in Boston on April 25, 2024. Here\u2019s an overview of their breakout session.\n\nSo, you\u2019re preparing to raise money to fuel your startup. How confident are you that your cap table and data room are squeaky clean? This question should be top of mind for most founders because a messy data room may drag out your raise and could cost you tens of thousands in legal expenses. This session covered the best practices to help you close easily and efficiently. Our 4 speakers offered tips from the legal perspective, the investor perspective, and the founder perspective. Founders left this session, armed with tangible, actionable guidance.\n\nSPEAKERS\n\nKristen Craft, Vice President & Business Partner Manager, Fidelity Private Shares\n\nKristen Craft brings deep startup roots to her role as VP of Business Partnerships at Fidelity. In this role, she\u2019s building out Fidelity\u2019s startup engagement platform, supporting founders and investors with equity management tools, fundraising strategy, and go-to-market best practices. Prior to Fidelity, Kristen was a founder herself, and then a longtime startup operator. She enjoyed working on strategic partnerships and digital marketing, predominantly in B2B SaaS companies. A Boston-area native, Kristen holds a B.A. from Brown University, an M.Ed. from Harvard University, and an MBA from MIT Sloan. She\u2019s particularly passionate about building community, creating connections, and supporting diverse founders.\n\nLaura Stoffel, Partner, Gunderson Dettmer\n\nLaura Stoffel is a partner at Gunderson Dettmer, the preeminent international law firm with an exclusive focus on the innovation economy. Laura represents entrepreneurs as they form and structure new businesses, counsels companies through equity and debt financing rounds, and executes complex M&A transactions. Laura specializes in representing emerging growth companies, frequently starting from formation and continuing through their achievement of scale and an M&A event. Laura is highly experienced with governance and venture financing matters, advising early and late-stage start-ups on everything from day-to-day matters to material strategic events. Laura also represents venture capital, growth and private equity investors on investment transactions and portfolio company matters.\n\nAlicia Tulsee, CEO and Founder, Moxie Scrubs\n\nAlicia Tulsee is a native New Yorker and Harvard alum, based in Boston, MA, and is the founder of the first direct-to-consumer medical apparel brand for nurses, Moxie Scrubs. In awe of all of the amazing nurses who cared for her loved ones, Alicia felt a calling to do something meaningful for the nursing profession and founded Moxie Scrubs out of Harvard University\u2019s Innovation Lab with the passion to create a brand dedicated to giving nurses the sense of fashion, professionalism, and respect that they want and deserve.",
        "url": "https://techcrunch.com/sponsor/fidelity-private-shares/preparing-to-raise-cap-table-best-practices-to-help-you-close-fast/",
        "category": 3,
        "summary": "In this role, she\u2019s building out Fidelity\u2019s startup engagement platform, supporting founders and investors with equity management tools, fundraising strategy, and go-to-market best practices. Alicia Tulsee, CEO and Founder, Moxie Scrubs\n\nAlicia Tulsee is a native New Yorker and Harvard alum, based in Boston, MA, and is the founder of the first direct-to-consumer medical apparel brand for nurses, Moxie Scrubs. In awe of all of the amazing nurses who cared for her loved ones, Alicia felt a calling to do something meaningful for the nursing profession and founded Moxie Scrubs out of Harvard University\u2019s Innovation Lab with the passion to create a brand dedicated to giving nurses the sense of fashion, professionalism, and respect that they want and deserve."
    },
    {
        "title": "Why Identity Needs a Seat at the Cybersecurity Table",
        "text": "Last year, a stunning 74% of cybersecurity attacks involved social engineering, human errors, or misuse. It\u2019s easy to see why attackers have capitalized on the human factor in the current environment: As strong as network perimeters have become, remote access has created a new landscape that needs to be defended differently, so attackers have pivoted to focus on the easier route\u2014people and the devices we use. Whether the target is a CEO or a temporary contractor, the new reality is clear: Identity must now be treated as a full-blown cybersecurity perimeter.\n\n\u201cExploiting a vulnerability requires a deep expertise and sophisticated tooling. Instead, attackers focus on what\u2019s easy\u2014and that\u2019s usually breaching the identity,\u201d says Iva Blazina Vukelja, VP of Product Management, Cisco Duo. \u201cEven using multi-factor authentication, which is more secure than traditional passwords, attackers can exploit you if you\u2019re using weaker forms of MFA. And because there is less visibility around those attacks, they\u2019re harder to detect.\u201d\n\nNot all authenticators are equal\n\nMulti-factor authentication (MFA) can mitigate risk by introducing additional hurdles for potential attacks, but the rise of identity-based cyberattacks has shown that simply enabling an additional factor does not make an account impenetrable. Strong cybersecurity requires visibility into identity systems activity, identity risk detection, and automated risk and trust driven controls, so that even if a user is targeted, the chances of an attacker completing the compromise are significantly lower.\n\nIdentity and access management software like Cisco Duo meet market demands for both stricter security controls and ease of use, with state-of-the-art techniques to defend against sophisticated phishing, attacker-in-the-middle and push-bombing attacks that may compromise weaker forms of MFA. By providing greater visibility of the security perimeter, Vukelja says, it\u2019s easier to recognize whether advanced MFA factors like passwordless authentication are covering all individuals and accounts\u2014and if they haven\u2019t, you can spring into action to secure those gaps before they\u2019re compromised.\n\n\u201cYou have to really understand what\u2019s going on in that identity perimeter,\u201d she explains. \u201cYou may roll out your MFA, but is everybody on it? It\u2019s important to know if the controls you think you have rolled out have been adopted by all disparate workforce populations. And if not, think about mitigating controls.\u201d\n\nWhy ITDR should be the top IT priority\n\nIdentity threat detection and response (ITDR) unlocks unprecedented visibility and observability across different identity systems. It also offers new calculations of risk signals based on identity data that were not previously possible to detect.\n\n\u201cRelying on weak forms of MFA, like SMS texts and push notifications, reminds me of a house with shabby locks,\u201d Vukelja says. \u201cIt\u2019s easier to break in and harder to tell who has entered. By comparison, identity threat detection and response allows comprehensive and correlated visibility into what is actually going on. It\u2019s like adding a whole-house security system.\u201d\n\nPowered by advanced ITDR capabilities, identity and access management software like Cisco Duo can automatically detect and respond to advanced attacks such as session hijacking. Security teams are no longer limited to responding post-breach, and as risk signals are identified, they\u2019re seamlessly integrated into your access security and management controls to make confident decisions in real time. This emerging innovation in identity security provides much-needed visibility into digital identities and automation of security responses based on risk analytics\u2014all without adding unnecessary friction to the user experience.\n\n\u201cFor the first time, the MFA can actually take a risk signal and automate a response without too much authenticating,\u201d Vukelja says. \u201cWe can do that because Cisco Duo has this unprecedented observability that we use to automate breaking up trust and do that only when it\u2019s needed. When we receive a risk signal, we can react quickly, protect the user, and provide security professionals visibility.\u201d\n\nThe rise of privacy-first cybersecurity\n\nOne key difference in Cisco Duo\u2019s strategy for comprehensive identity protection is a total commitment to user privacy. By using a patented method to ascertain trust without intrusive GPS tracking, for example, Cisco Duo can monitor the identity perimeter without knowing a user\u2019s exact location.\n\nMost contextual access controls rely on IP addresses and geo locations, making the location signal noisy and ineffective when using VPNs. Enter Duo\u2019s patent-pending WiFi Fingerprint technology: It creates an anonymized fingerprint of the wi-fi networks available to a user\u2019s device to detect a change in location at the time of authentication. This helps to improve accuracy and reduce false-positives while preserving user privacy. If location has changed, Duo can automatically step up authentication requirements.\n\nAs attackers develop new methods to compromise digital identities and access, comprehensive protection of the identity perimeter will only become more essential for enterprises. That\u2019s why IT leaders should swap out their \u201cshabby door keys\u201d and prioritize ITDR for greater visibility and observability of risk signals. Effective identity and access management software confirms device trust, user trust, and context trust, while providing the ability to automate agile access controls in real time, reacting to emerging risks without jeopardizing user privacy.\n\nThe rapid maturation of cyberattacks highlights why identity security tools and strategies are crucial for both large and small enterprises. With identity now central to digital operations, organizations prioritizing strong yet frictionless identity and access management will benefit by staying ahead of threats and minimizing the possibility of future compromises.\n\nUltimately, the most important step is recognizing identity as the foundation of effective cybersecurity. \u201cEven the best cybersecurity strategy,\u201d Vukelja insists, \u201cis only as strong as its weakest point.\u201d\n\nGet a free identity security assessment with Cisco Duo.",
        "url": "https://techcrunch.com/sponsor/cisco/why-identity-needs-a-seat-at-the-cybersecurity-table/",
        "category": 2,
        "summary": "It\u2019s easy to see why attackers have capitalized on the human factor in the current environment: As strong as network perimeters have become, remote access has created a new landscape that needs to be defended differently, so attackers have pivoted to focus on the easier route\u2014people and the devices we use. And because there is less visibility around those attacks, they\u2019re harder to detect.\u201d\n\nNot all authenticators are equal\n\nMulti-factor authentication (MFA) can mitigate risk by introducing additional hurdles for potential attacks, but the rise of identity-based cyberattacks has shown that simply enabling an additional factor does not make an account impenetrable. Identity and access management software like Cisco Duo meet market demands for both stricter security controls and ease of use, with state-of-the-art techniques to defend against sophisticated phishing, attacker-in-the-middle and push-bombing attacks that may compromise weaker forms of MFA."
    },
    {
        "title": "Unlocking the power of collaboration at college: preparing students for the future of tech",
        "text": "Many of us can likely recall a college group project that didn\u2019t go smoothly. Maybe some group members carried the bulk of the workload while others shied away. Maybe the more dominant voices within the group made crucial decisions while others were hesitant to speak up. Maybe the final result felt like several separate projects rather than a cohesive whole.\n\nCollaboration isn\u2019t just something you\u2019re naturally good at; it\u2019s a skill that requires ongoing practice and growth. A study from the American Association of Colleges and Universities found that 83% of employers see teamwork and collaboration as crucial skills, but only 37% think recent college graduates are ready for them. Research also shows that teamwork skills usually need to be taught directly.\n\nHaving spent decades navigating various sectors of the tech industry and regularly recruiting new team members, I\u2019ve come to recognize the essential role of collaboration in the workforce. As AI starts to handle coding and other technical aspects of the work, it may become the single most important skill. By redefining collaboration as a teachable skill, educational institutions can empower the next generation with the tools for success in their careers and beyond.\n\nWhy collaboration is so important in tech\n\nAt Canva, we want to empower the world to design. It\u2019s a massive goal \u2013 and one that we can only achieve if we work together effectively \u2013 that\u2019s why I\u2019m committed to promoting a culture of inclusive creativity and collaboration within my teams. As the saying goes, \u201cTo go fast, go alone; to go far, go together.\u201d I\u2019ve seen firsthand that connected teams are strong teams, and innovation can emerge from any corner. Nurturing an inclusive team culture that fosters and encourages collaboration (particularly in hybrid teams) not only leads to better products but also creates a more enjoyable experience for everyone on the team.\n\nBuilding a culture of collaboration\n\nBuilding a strong sense of psychological safety within teams is essential for fostering creativity and collaboration. This starts with creating an environment where every team member feels safe to share their ideas without fear of judgment. I prioritize spending one-on-one time with each team member to build trust and meaningful relationships, encouraging them to feel comfortable in sharing their thoughts and ideas.\n\nWe also promote a team culture of seeking to understand rather than criticize. When someone presents a new idea, the first step is to be curious and ask questions like \u201cCan you say more about this idea?\u201d \u201cWhat data informed this recommendation?\u201d \u201cWhat problem are you looking to solve?\u201d. More often than not, it\u2019s a great idea that may trigger a different line of thinking and allow teams to build even better solutions.\n\nEncouraging creativity is also key for nurturing trust and effective collaboration, especially among teams building products together. Whether it\u2019s through visual brainstorms or even activities like painting together outside of work, these experiences strengthen bonds and spark innovation. My team is more excited about \u201cthinking outside of the box\u201d when they\u2019ve had opportunities to be creative together.\n\nHow AI can support collaboration\n\nCollaboration has always been essential in tech, but it\u2019s been amazing to see how AI and other technology have taken collaboration to the next level. One good example of this is how we use a virtual Whiteboard for \u201cproduct jams.\u201d During these sessions, a product leader will present a vision statement about a problem we want to solve. Each team member, from senior executives to new hires, contributes by posting \u201ccards\u201d with potential solutions on the whiteboard. What makes this exercise so impactful is that there\u2019s no such thing as a bad idea, and everyone has an opportunity to participate in the exact same way.\n\n\n\nWe then use Canva\u2019s AI \u2018Transform into Doc\u2019 function (and sometimes Magic Write) to summarise these ideas into a simple, digestible format. What I love about this process is that it\u2019s truly inclusive. Every idea is treated in the same way, regardless of who submitted it \u2013 the substance is what matters, not the creator. It\u2019s amazing to see how this technology can help us collaborate in an inclusive way while saving so much time!\n\nUnlocking the power of collaboration in higher education\n\nTo set students up for successful careers, I truly believe they\u2019ll need access to these kinds of tools and opportunities, along with being taught the philosophy and soft skills behind how to be an effective collaborator. Providing students with the right tools to complete a group assignment not only improves their learning experience but also exposes them to the benefits of collaborating effectively with new perspectives. It\u2019s becoming increasingly crucial for colleges and professors to actively teach collaboration skills, explaining their value and workforce applications rather than assuming students will naturally possess them.\n\nAs AI streamlines many work processes, it also underscores the importance of human skills like collaboration and teamwork. Colleges have a crucial role in enhancing student preparation for a workforce that highly values and requires collaboration and creativity. By fostering these skills and leveraging modern communication tools and technology like AI, colleges can equip students with the skills they need for their best careers.\n\n\u2014 Carly Daff, Head of Teams & Education at Canva\n\nLearn more about how to bring Canva to your college or university here.",
        "url": "https://techcrunch.com/sponsor/canva/unlocking-the-power-of-collaboration-at-college-preparing-students-for-the-future-of-tech/",
        "category": 1,
        "summary": "A study from the American Association of Colleges and Universities found that 83% of employers see teamwork and collaboration as crucial skills, but only 37% think recent college graduates are ready for them. Having spent decades navigating various sectors of the tech industry and regularly recruiting new team members, I\u2019ve come to recognize the essential role of collaboration in the workforce. Unlocking the power of collaboration in higher education\n\nTo set students up for successful careers, I truly believe they\u2019ll need access to these kinds of tools and opportunities, along with being taught the philosophy and soft skills behind how to be an effective collaborator."
    },
    {
        "title": "Revolutionizing legal document generation: DocPro.com unveils DocLegal.ai",
        "text": "In the dynamic realm of legal tech, innovation is paramount. DocPro.com, a trailblazer in legal document generation, is thrilled to announce the soft launch of DocLegal.ai. This groundbreaking platform represents a leap forward in document generation and offers an AI-powered chatbot for seamless document and contract drafting. This AI-powered solution sets new benchmarks for accuracy, efficiency, and user experience.\n\nFounded by experienced lawyer and visionary entrepreneur Kim Chan, DocPro.com seamlessly integrates legal documentation services with cutting-edge technology. Honored with the GoGlobal Award 2021 for legal tech, recognized as the Best Legal Documents Platform 2022 by Legal Elite as well as a Rising Star Award by FinancesOnline, DocPro.com has solidified its position as a leader in the legal tech landscape. Now, with the introduction of DocLegal.ai, DocPro.com is poised to redefine legal document generation.\n\nDocLegal.ai: Unleashing the Power of Generative AI\n\nDocLegal.ai marks a significant milestone in legal tech, harnessing the power of Generative AI to revolutionize document generation. Through Retrieval Augmented Generation technology, DocLegal.ai enhances accuracy and minimizes errors, offering users unparalleled document quality. From contract drafting and review to legal research and advice, DocLegal.ai provides a comprehensive suite of services, laying the foundation for a transformative legal co-pilot experience.\n\nKey Features:\n\nRetrieval Augmented Generation : Trained on vast repositories of legal documents, DocLegal.ai ensures unparalleled accuracy and relevance in AI legal document generation. Say goodbye to generic templates and hello to tailored, contextually rich legal documents.\n\nError Minimization : DocLegal.ai employs sophisticated algorithms to avoid hallucinations and address limited token issues, ensuring that generated documents meet the highest standards of quality and completeness.\n\nPrivacy Protection : DocLegal.ai prioritizes user privacy above all else, ensuring peace of mind for users. User information will not be used as training materials for the AI.\n\nComprehensive Solutions: From document generation to review, DocLegal.ai offers a wide array of legal services tailored to diverse user needs.\n\n\u201cOur mission at DocLegal.ai is to empower businesses with cutting-edge legal AI powered tools, enhancing productivity while ensuring the integrity of legal documents. Our vision is to provide accessible legal solutions for everyone,\u201d said Kim Chan, founder of DocLegal.ai\n\nA Vision for the Future\n\nDocLegal.ai proudly unveils the world\u2019s first comprehensive public database powered by the most advanced iteration of GPT-4, exclusively designed for the generation of legal documents. This avant-garde innovation transcends the traditional limitations associated with legal document creation, offering the capacity to produce extensive documents without the constraints of token limits, substantially reducing the potential for inaccuracies traditionally known as \u2018hallucinations\u2019.\n\nDocLegal.ai bridges the gap between ChatGPT\u2019s broad capabilities and the specialized needs of legal document creation, delivering context-specific accuracy and detail that directly using ChatGPT cannot match. This specialized platform safeguards confidentiality and streamlines the legal document creation process, redefining excellence in AI-driven legal support\n\nWhile other Legal AIs, such as Harvey, cater to specific law firms with private databases, DocLegal.ai breaks new ground by democratizing access to cutting-edge legal document assistance. The platform is not merely a tool but a transformative force, designed to serve an expansive audience\u2014from bustling firms to dedicated solo practitioners\u2014setting a new benchmark in precision, accessibility, and transformative legal capabilities.\n\nEnvisioning the future, DocLegal.ai is moving beyond document generation to provide full-service AI co-pilot legal assistance. With capabilities stretching from document review to sophisticated legal analyses, from crafting compelling arguments to conducting exhaustive legal research, and from managing intricate data rooms to navigating the complexities of the discovery process, DocLegal.ai aspires to embody the future of legal support.\n\nEarly Bird Program\n\nTo celebrate the soft launch, DocLegal.ai is inviting 500 early bird users to trial DocLegal.ai. Visit DocLegal.ai to sign up and experience the future of legal document generation firsthand.",
        "url": "https://techcrunch.com/sponsor/docpro/revolutionizing-legal-document-generation-docpro-com-unveils-doclegal-ai/",
        "category": 0,
        "summary": "Our vision is to provide accessible legal solutions for everyone,\u201d said Kim Chan, founder of DocLegal.ai\n\nA Vision for the Future\n\nDocLegal.ai proudly unveils the world\u2019s first comprehensive public database powered by the most advanced iteration of GPT-4, exclusively designed for the generation of legal documents. With capabilities stretching from document review to sophisticated legal analyses, from crafting compelling arguments to conducting exhaustive legal research, and from managing intricate data rooms to navigating the complexities of the discovery process, DocLegal.ai aspires to embody the future of legal support. This specialized platform safeguards confidentiality and streamlines the legal document creation process, redefining excellence in AI-driven legal support\n\nWhile other Legal AIs, such as Harvey, cater to specific law firms with private databases, DocLegal.ai breaks new ground by democratizing access to cutting-edge legal document assistance."
    },
    {
        "title": "Too many tabs? Dodge the \u2018toggling tax\u2019 with the Shift power browser",
        "text": "Jumping back and forth between email accounts. Scanning through dozens of tabs in search of that one story you started reading a week ago. Switching between apps again\u2026 and again\u2026 and again. Exhausting, right? As much as the internet has evolved to broaden and improve our online lives, we\u2019re still stuck paying an invisible \u201ctoggling tax\u201d that slows us down, distracts us, and erodes our control of what we do online.\n\nHow much time does the toggling tax cost us, exactly? It\u2019s a lot more than you may realize: In 2022, the Harvard Business Review found that people switch between apps and websites nearly 1,200 times each day, at the cost of two seconds per switch\u2014which adds up to a whopping four hours a week wasted on hopping between the many aspects of our online lives.\n\nThe toggling tax isn\u2019t just paid in time, either. Constantly moving back and forth online is a type of context switching, which puts a heavier cognitive load on our brains as we adjust to each new task. Context switching has been found to raise levels of the stress hormone cortisol, making it even harder to focus. \u201cWhen people think they\u2019re multitasking, they\u2019re actually just switching from one task to another very rapidly,\u201d MIT neuroscientist Earl Miller told the Guardian. \u201cAnd every time they do, there\u2019s a cognitive cost in doing so.\u201d\n\nBut we don\u2019t have to pay the toggling tax. A new generation of web browsers promise to streamline the online experience\u2014none of them more innovative or intuitive than Shift, which centralizes every facet of online life into a single window. Shift\u2019s mission is simple, according to VP of Product and Customer Success, Michael Foucher: \u201cWe create calm out of tab chaos.\u201d\n\nThe rapid evolution of the power browser\n\nShift was born from an all-too-familiar predicament. Back in 2016, Foucher was using multiple email accounts all the time, but no single browser could quickly and easily switch between them. He had to cobble together a common makeshift solution. \u201cI would have one account open in Chrome. I\u2019d have another open in an incognito window of Chrome. I\u2019d have Safari open and another incognito window of Safari too,\u201d he recalls. \u201cBut it was untenable, so I started thinking about what a real solution would look like.\u201d\n\nThat search led Foucher and his team to develop Shift, which officially launched as a subscription-based browser built on Electron in December 2016. They quickly found a devoted customer base, whose feedback and product requests sparked growth and innovation over the next eight years: Shift saw 10X ARR in 2018, 5X ARR in 2019, and more recently, launched an ambitious rebuild on Chromium to boost speed, security, and user experience.\n\nToday, Shift seamlessly integrates over 1,500 apps for ultra-fast access to all the tools that people need to stream, shop, work, browse, and stay connected online, eliminating the need to search, open, and log into accounts across multiple windows and tabs. And user feedback continues to play an essential role in development. Foucher talks to a dedicated group of customers on a regular basis to understand how Shift saves them time and improves their browsing experience. By allowing people to tailor exactly how they navigate and organize each facet of their online lives, they\u2019re using Shift to massively cut down the toggling tax.\n\nSimplified, centralized, customized UX\n\nHere\u2019s how it works: Shift anchors your customized Workspaces in the left side of the browser window that can be connected to email accounts including Gmail, Outlook, or Office 365, each Space can be customized to the stream of online activity through integrating your most used apps \u201cWe created a mapping that is easy for people to pay attention to,\u201d Foucher says. \u201cWe\u2019re lowering the cognitive load required to keep track of what you\u2019re doing online.\u201d\n\nCompared to legacy browsers, Shift offers an unparalleled degree of customization for integrating web apps, managing email and notifications, and even tailoring Workspaces for focused browsing. There are a lot of basic, generic browsers out there. Some of them can be reliable, but none of them can be tailored to your needs so specifically that you\u2019ll feel that you can never live or work without them. That\u2019s what makes Shift so unique.\u201d Unlike other new browsers, which tend to be technically powerful but difficult to learn and use, Shift is meticulously tested to be as approachable and intuitive as possible.\n\nThat commitment to an intuitive interface has driven a number of innovative product features, such as a unified calendar that displays every event across different accounts within a single pop-out panel. What\u2019s more, when Shift wants to push visual changes to its product, it can do so much faster than most projects built on Chromium because of how its interface is built. \u201cWe\u2019re very nimble\u2014and that makes a massive difference,\u201d Foucher says.\n\nAs a portfolio company of the Redbrick family, Shift is now looking to the future to improve its browser even more. What\u2019s coming up on the horizon? Foucher can\u2019t reveal too much about what they\u2019re innovating, yet. What he can say is that they\u2019ve begun leveraging AI models to solve daily human pain points. Whatever the feature, he promises that Shift will be laser-focused on alleviating tab chaos and making it easier to be online, because that\u2019s what users need and want.\n\n\u201cI never want to release anything that would force the user to go find help to figure it out,\u201d he says. \u201cThe user should always understand exactly what they\u2019re doing. That\u2019s our sweet spot.\u201d\n\nDon\u2019t pay the toggling tax. Try Shift for free.",
        "url": "https://techcrunch.com/sponsor/shift/too-many-tabs-dodge-the-toggling-tax-with-the-shift-power-browser/",
        "category": 2,
        "summary": "Today, Shift seamlessly integrates over 1,500 apps for ultra-fast access to all the tools that people need to stream, shop, work, browse, and stay connected online, eliminating the need to search, open, and log into accounts across multiple windows and tabs. They quickly found a devoted customer base, whose feedback and product requests sparked growth and innovation over the next eight years: Shift saw 10X ARR in 2018, 5X ARR in 2019, and more recently, launched an ambitious rebuild on Chromium to boost speed, security, and user experience. Simplified, centralized, customized UX\n\nHere\u2019s how it works: Shift anchors your customized Workspaces in the left side of the browser window that can be connected to email accounts including Gmail, Outlook, or Office 365, each Space can be customized to the stream of online activity through integrating your most used apps \u201cWe created a mapping that is easy for people to pay attention to,\u201d Foucher says."
    },
    {
        "title": "How embedded banking helps retailers grow without compromise",
        "text": "Compromise is a fact of life. When you\u2019re choosing where to eat with friends, splitting up household chores, or facing any number of other day-to-day decisions, it\u2019s inevitable that you\u2019ll end up making some trade-offs.\n\nBut compromise shouldn\u2019t be a fact of business. When you\u2019re scaling up, you can\u2019t compromise at the expense of your business, your customers, or your colleagues\u2014even in the face of a digital landscape where competition has never been more fierce. That\u2019s how a promising business ends up hurting itself instead of growing.\n\nOf course, it\u2019s not easy to hold firm when the ground is shifting beneath your feet. In just five years, McKinsey predicts that the integrated network economy could represent 33% of the world\u2019s total sales output\u2014a stark sign of how the accelerated digitalization of the payments experience is reshaping industries like retail and consumer goods. As this $100 trillion future comes into focus, the surging demand by clients for integrated experiences has put tremendous pressure on retail and consumer leaders to deliver on modernization all at once. Their customers want lower prices, easy transactions, and seamless experiences alongside full transparency, safety, and fraud protection on every single platform they are on and every marketplace where they make purchases.\n\nWithout the right technologies, counsel and support, compromise might seem like a tempting fallback. Enter the world\u2019s largest merchant acquirer: J.P. Morgan Payments. They are able to help businesses practically do it all through an unparalleled combination of world-class banking, financial services, and fintech solutions. By leveraging global infrastructure that moves nearly $10 trillion a day in more than 160 countries and 120 currencies, J.P. Morgan Payments clients use commerce and embedded banking solutions to scale today without losing sight of what will shape their business in the years to come.\n\n\u201cClients need a partner who has global reach, who offers a network of financial products that not only move and accept payments but also facilitate payouts to third-party sellers, and who navigates regulations in a safe, secure way,\u201d says Ryan Schmiedl, Managing Director, Global Head of Trust and Safety for J.P. Morgan Payments. \u201cWe\u2019re in a really unique situation to meet these needs.\u201d\n\nBuilding marketplace APIs from A to Z\n\nThe rise of digital marketplaces illustrates what\u2019s at stake as businesses evolve. If a company wants to create a marketplace or platform to facilitate commerce between buyers and sellers, they need an end-to-end payments solution that can handle frictionless money movement on a global scale, at low cost, while meeting all requirements for risk control and data management within a well-regulated infrastructure. Every element needs to work seamlessly with the rest, or else the marketplace may hit roadblocks as it expands.\n\nWithin a small pool of vendors that offer a full spectrum of solutions, J.P. Morgan Payments stands out. They offer the stability and resiliency of a bank alongside a breadth of rails, a broad portfolio of products, complete understanding of regulatory environments across regions and the ability to move money at speed and scale. As a result, the entire marketplace benefits from solutions that are built to grow.\n\nWith an engineering mindset that translates their deep financial knowledge into a language that developers know best, J.P. Morgan Payments has streamlined essential processes like onboarding and account validation to facilitate money movement across these growing marketplaces.\n\n\u201cThe folks putting together these marketplaces are developers and engineers who want to test APIs in a sandbox,\u201d Schmiedl explains. \u201cWe\u2019re bringing together the stability and reach of J.P. Morgan to service the engineering needs of this particular market to create a seamless, frictionless experience.\u201d\n\nImproved trust and safety for the AI era\n\nIn such rapidly evolving times, mitigating fraud can feel like playing a high-stakes game of Whack-a-Mole. As customers seek faster payment options and bad actors develop more complex methods of fraud, merchants, platforms and marketplaces face new risks that call for adopting comprehensive trust and safety solutions.\n\nYet again, compromise isn\u2019t an option. Neither is searching for an impossible silver bullet that can solve all these challenges at once. Instead, Schmiedl says that businesses should implement multiple layers of protection across the entire customer journey, weaving together a trust and safety strategy that together is stronger than the sum of its parts. Fraudsters are constantly looking for paths of least resistance, such as historically vulnerable legacy points, which is why it\u2019s invaluable to find a partner who can offer a full suite of solutions.\n\nIncreasingly, the backbone of these solutions is AI/ML technology. Breakthrough applications of AI/ML, neural networks and deep learning have enabled new techniques to improve trust and safety\u2014not just for detecting fraudulent new accounts, analyzing transactions to minimize risk, and identifying anomalous behavior or events within the ecosystem, but also instantly pinpointing fraud and calculating risk at any given point in time.\n\n\u201cClients demand simple, fast digital interactions, so you need to minimize the impact you\u2019re having on legitimate activity,\u201d Schmiedl says. \u201cIf something gets caught, automation makes it as simple as possible for clients to prove their legitimacy\u2014and you can still determine the appropriate level of friction based on risk, which is really important not only today, but also tomorrow.\u201d\n\nThe use of this technology isn\u2019t entirely new, of course: For years, businesses have deployed ML-based risk scores to detect fake or synthetic identities, user impersonation, account takeovers, improper or fraudulent payments, stolen credit cards, money laundering, and criminal networks. But improved algorithms and modeling techniques suggest that embedded banking and commerce is at the dawn of a powerful new era for fraud prevention.\n\nSchmiedl stressed the need for further innovation and more sophisticated applications across the customer journey, from ML-based models that predict new threat patterns, to biometrics and device-based behavior monitoring that reduce friction during onboarding and payment, to deep learning innovations that help spot deep fakes. All of these innovations will help pave the way to the future of embedded banking and commerce\u2014and do so without compromise.\n\n\u201cThe goal is not only to service customers, but to do so in a very controlled, safe way as we continue to build a modern payments business,\u201d Schmiedl says. \u201cThat will be extremely important as we continue to proliferate the digitalization of our economy.\u201d\n\nCTA: Discover how J.P. Morgan Payments is building the future.",
        "url": "https://techcrunch.com/sponsor/j-p-morgan-payments/how-embedded-banking-helps-retailers-scale-without-compromise/",
        "category": 2,
        "summary": "\u201cWe\u2019re bringing together the stability and reach of J.P. Morgan to service the engineering needs of this particular market to create a seamless, frictionless experience.\u201d\n\nImproved trust and safety for the AI era\n\nIn such rapidly evolving times, mitigating fraud can feel like playing a high-stakes game of Whack-a-Mole. Breakthrough applications of AI/ML, neural networks and deep learning have enabled new techniques to improve trust and safety\u2014not just for detecting fraudulent new accounts, analyzing transactions to minimize risk, and identifying anomalous behavior or events within the ecosystem, but also instantly pinpointing fraud and calculating risk at any given point in time. \u201cIf something gets caught, automation makes it as simple as possible for clients to prove their legitimacy\u2014and you can still determine the appropriate level of friction based on risk, which is really important not only today, but also tomorrow.\u201d\n\nThe use of this technology isn\u2019t entirely new, of course: For years, businesses have deployed ML-based risk scores to detect fake or synthetic identities, user impersonation, account takeovers, improper or fraudulent payments, stolen credit cards, money laundering, and criminal networks."
    },
    {
        "title": "5 Traits Companies Should Demand in a Payments Provider",
        "text": "Whether you\u2019re a start-up or an established business, the processes behind making payments and managing cash flow can be expensive, complicated, and labor-intensive.\n\nThat\u2019s why it\u2019s important to have the right payments partner to help guide you through your journey and power growth. But how do you know which provider is up for the task? Do you know what features and benefits you should expect in today\u2019s market? Are sure your provider can meet your organization\u2019s needs as they evolve?\n\nIn this online event, hosted by TechCrunch and sponsored by KeyBank, longtime payments experts will discuss the five traits that modern companies should demand from a payments provider, such as:\n\n\u2022 Scalability: Your provider should be able to handle your current and future needs, whether you are a small startup or a large enterprise, whether you operate locally or globally, and whether you accept online or offline payments.\n\n\u2022 Vision: Your provider should be innovative and forward-thinking, offering you the latest technologies and solutions to help you grow your business and stay ahead of the competition.\n\n\u2022 Partnership: Your provider should be more than just a vendor, but a trusted partner who understands your business goals and challenges, and who provides you with personalized support and guidance.\n\nBy the end of the session, you should understand how to choose the right provider to enable your organization\u2019s success both today and into the future.",
        "url": "https://techcrunch.com/sponsor/keybank/5-traits-companies-should-demand-in-a-payments-provider/",
        "category": 2,
        "summary": "\u2022 Partnership: Your provider should be more than just a vendor, but a trusted partner who understands your business goals and challenges, and who provides you with personalized support and guidance. \u2022 Vision: Your provider should be innovative and forward-thinking, offering you the latest technologies and solutions to help you grow your business and stay ahead of the competition. In this online event, hosted by TechCrunch and sponsored by KeyBank, longtime payments experts will discuss the five traits that modern companies should demand from a payments provider, such as:\n\n\u2022 Scalability: Your provider should be able to handle your current and future needs, whether you are a small startup or a large enterprise, whether you operate locally or globally, and whether you accept online or offline payments."
    },
    {
        "title": "Visa Everywhere Initiative: Looking for the next generation of fintech",
        "text": "In an era where technology and finance intersect more deeply than ever before, the Visa Everywhere Initiative stands out as a beacon for fintech startups around the world. It is an opportunity that fintech entrepreneurs dream of, offering not just a big prize of $100,000, but also a platform to highlight their innovations at the TechCrunch Disrupt event in San Francisco. The opportunity that Visa offers to the fintech startups to pitch their solutions on stage at TechCrunch Disrupt and have their pitches live-streamed worldwide is a transformative experience. This unique platform not only catapults these startups into the global spotlight but also bridges the gap between their technologies and potential investors or partners attending or watching the event. This can be particularly valuable for startups in their early stages, where exposure and networks are as critical as funding.\n\nLaunched in 2015, the Visa Everywhere Initiative has grown significantly, reaching over one hundred countries, and engaging nearly 15,000 startups. Its mission is straightforward yet impactful: to challenge and empower fintech innovators to contribute to the future of payments and commerce. The initiative focuses on key areas relevant to the evolution of financial services, including money movement, digital issuance, cross border payments, open banking, embedded finance, and cloud computing, among others.\n\n\u201cBy supporting these global innovators, Visa is not just shaping the future of payments, but also ensuring more dynamic financial tools will reach every corner of the world. The diverse perspectives and fresh ideas of these founders have the potential to shape how we pay, save, and invest tomorrow.\u201d Said Vanessa Colella, Visa Head of Global Digital Partnerships in support of the program.\n\nFor fintech startups looking to make a mark on the global stage, the Visa Everywhere Initiative stands for an unparalleled opportunity. As the initiative continues to evolve, it promises to keep fueling the next wave of fintech innovation, ensuring that the future of finance is bright and accessible to all.\n\nReady to shape the future of payments?\n\nJoin the Visa Everywhere Initiative 2024 if you are a fintech startup with a creative and effective solution for the payments industry. This could be your opportunity to participate in a global competition and be a part of a select group of emerging talent in fintech. You have the potential to become the next Visa Everywhere Initiative Global Champion!\n\nTo learn more about the Visa Everywhere Initiative, deadlines and how to be part of it, visit the website Visa Everywhere Initiative 2024.\n\nIf you are ready to register go to the Visa Everywhere Initiative global application form.",
        "url": "https://techcrunch.com/sponsor/visa-everywhere-initiative/visa-everywhere-initiative-looking-for-the-next-generation-of-fintech/",
        "category": 3,
        "summary": "It is an opportunity that fintech entrepreneurs dream of, offering not just a big prize of $100,000, but also a platform to highlight their innovations at the TechCrunch Disrupt event in San Francisco. The diverse perspectives and fresh ideas of these founders have the potential to shape how we pay, save, and invest tomorrow.\u201d Said Vanessa Colella, Visa Head of Global Digital Partnerships in support of the program. The initiative focuses on key areas relevant to the evolution of financial services, including money movement, digital issuance, cross border payments, open banking, embedded finance, and cloud computing, among others."
    },
    {
        "title": "Why Dynamic Net Terms is Reshaping Fintech\u2014FASHIONGO Trailblazes a New B2B Payment Model",
        "text": "Access to funds has always been instrumental to success for all businesses as it enables organizations to expand their offerings, scale operations, and capture needed resources to capitalize on growth opportunities. This is especially true in retail business-to-business operations with net terms being the most widely practiced payment method to secure inventory now but defer payments to either 60, 45, or 30 days. According to a 2023 Market Report by Billd, 65% of B2B sellers consider payment terms vital for influencing business growth and this type of trade credit, according to the Federal Reserve, is the most important form of short-term finance for firms. In fact, in 2019, U.S. non-financial firms had about $4.5 trillion in trade credit outstanding equaling 21% of U.S. GDP.\n\nAlthough the B2B payment space remains the largest sector in terms of transaction volume, it still lags behind its B2C counterparts in innovation, accessibility, and flexibility. Traditional approaches to net terms have outdated qualification models that fail to serve a demographic of small to medium-sized retail buyers. FASHIONGO, the leading online B2B wholesale fashion marketplace with over 2 decades of expertise in technology-driven solutions, is pioneering a new approach to address these foundational process flaws in net terms that create challenges and issues for overlooked business owners.\n\nInnovating with Dynamic Net Terms\n\nTraditional Net Terms solutions boast a one-size-fits-all qualification process with rigid and stringent criteria that the applicant must meet that will result in a binary approval decision of \u201cyes, they qualify\u201d or \u201cno, they don\u2019t\u201d. This inflexible qualification process characterized by generalized and limited in financial data sources can overlook about 90% of creditworthy and true in need small and medium-sized retailers, who are the backbone of US economy. The current process for net terms qualification results in an average net terms credit approval rating between 5%-15%.\n\nEnter FASHIONGO, the leading online B2B fashion wholesale marketplace aiming to revolutionize B2B net terms through Dynamic Net Terms, a first-of-its-kind solution that approves buyers dynamically across different net term criteria, relevant to retail business, adjusting to each individual business profile to maximize fund access. There is a crucial need for scalable technological solutions that consolidate diverse relevant data sources and enable real-time approval for deserving buyers in a specific industry who are typically declined by other payment programs which Dynamic Net Terms precisely delivers.\n\nLowering the Barrier to Ignite Business Growth\n\nFASHIONGO, pioneers a new solution to address these issues called Dynamic Net Terms taking a more nuanced approach through industry-leading risk models and lending infrastructure. To break down barriers and help businesses grow on their terms, FASHIONGO has partnered with Balance, the leading B2B payment technology provider. Instead of a rigid binary yes or no approval decision, FASHIONGO offers variable 60, 45, or 30-day terms dynamic to the applicant\u2019s profile. This allows a broader spectrum of retailers by lowering the barriers to accessing capital critical for business growth. Ultimately, FASHIONGO aims for an approval rating of 5-6x times above the industry standard.\n\nRather than relying on incomplete information and arbitrary standards, FASHIONGO leverages rich data and over 20 years of fashion industry expertise. The focus is on understanding the customer\u2019s full purchase journey and growth objectives to provide the most practical solution that addresses the real business needs and demands of each buyer based on their financial history on FASHIONGO. As buyers continue to purchase and pay down balances, FASHIONGO dynamically adjusts the terms to fuel further expansion for both the platform and the buyer.\n\nThe commitment is clear \u2013 maximize access to cash for all buyers, not just for the select few but for the many buyers that need it most. FASHIONGO aims to push high net terms approval rates to create a model that will set a new standard for an inclusive B2B payment landscape, especially for buyers who need access to funds quickly. In a recent survey by Balance, 71% of buyers said easy, quick access to net terms would be the biggest factor in choosing an e-commerce platform. With real-time approval processes through Dynamic Net Terms, FASHIONGO accelerates the sales cycle for buyers, vendors, and suppliers on the platform.\n\nThe power of Dynamic Net Terms not only lies in its accessibility but also in the continued growth of buyers\u2019 purchasing power on FASHIONGO. As buyers continue building their financial history through order placements and on-time repayment on FASHIONGO, buyers\u2019 net term credit will automatically increase.\n\nBuyers can also enjoy flexibility in order payment by leveraging seamlessly both net credit and credit cards together for a singular order, giving them the ability to secure larger inventory and freedom to pay their way. This innovative approach supports businesses to grow their sales by enabling them to place more substantial orders and pre-orders with the ability to combine different payment methods.\n\nFASHIONGO is No Stranger to Innovation\n\n\u201cDynamic Net Terms is not just a payment solution; it\u2019s a catalyst for growth, designed to empower retailers who have historically been underserved,\u201d says Paul Lee, CEO of FASHIONGO. \u201cWe\u2019re a tech company addressing foundational industry issues, not just buzzwords. Dynamic Net Terms prioritizes a customer-centric approach designed to cater to each business\u2019s unique needs that is both accessible and flexible\u201d\n\nThe future looks bright for platforms, vendors, and retailers alike as innovative fintech solutions reshape traditional norms. Dynamic Net Terms pioneers a movement towards synchronization \u2013 understanding buyer needs first, then providing the tailored tools for their business to thrive. As part of the wholesale ecosystem, FashionGo remains committed to continually investing in solutions that are most impactful to buyer\u2019s success, especially when it is needed the most. Dynamic Net Terms will empower retail buyers with greater purchasing power to position them for success in an ever-changing and turbulent retail landscape.\n\nFor more information on Dynamic Net Terms, visit here.",
        "url": "https://techcrunch.com/sponsor/fashiongo/why-dynamic-net-terms-is-reshaping-fintech-fashiongo-trailblazes-a-new-b2b-payment-model/",
        "category": 2,
        "summary": "FASHIONGO, the leading online B2B wholesale fashion marketplace with over 2 decades of expertise in technology-driven solutions, is pioneering a new approach to address these foundational process flaws in net terms that create challenges and issues for overlooked business owners. Dynamic Net Terms prioritizes a customer-centric approach designed to cater to each business\u2019s unique needs that is both accessible and flexible\u201d\n\nThe future looks bright for platforms, vendors, and retailers alike as innovative fintech solutions reshape traditional norms. Enter FASHIONGO, the leading online B2B fashion wholesale marketplace aiming to revolutionize B2B net terms through Dynamic Net Terms, a first-of-its-kind solution that approves buyers dynamically across different net term criteria, relevant to retail business, adjusting to each individual business profile to maximize fund access."
    },
    {
        "title": "How to protect your content platform\u2014and your business\u2014from cyberattacks",
        "text": "Your CMS connects you with your readers, your employees and your partners. It\u2019s the drumbeat of your organization. A compromised CMS, however, is a highly sought-after target for cyber criminals\u2014and potentially a significant area of vulnerability for your business.\n\nDigital transformation efforts have been underway for decades, but over the last several years, businesses had to expedite their digitization journeys as they shifted from survival mode at the beginning of the pandemic to new remote and hybrid ways of working. This hybrid mode of communication and access continues today.\n\nMcKinsey called this expedition the \u201cThe Quickening\u201d\u2014where some businesses took a years-long roadmap and reduced execution to a few months in order to navigate the pandemic effectively. While this record-breaking agility in developing and implementing new technologies in the face of a fast-changing digital landscape should be celebrated, it also has been met with new challenges, including the rise in frequency and sophistication of cyberattacks.\n\nFrom 2013 to 2022 there was an 800% increase in the number of DDoS attacks worldwide. One study says that Q1 2023 saw 47% more attacks than the same time period a year prior. Fast forward to today, hardly a week goes by without some new story reporting that tens of thousands of WordPress sites have been exposed to security vulnerabilities through a plugin breach or sites running outdated versions of Drupal have fallen prey to hackers coming in through the backdoor.\n\nIn short, organizations need to start planning for when they\u2019ll be attacked, not if\u2014and a key part of that planning process is to ensure they\u2019re in lock-step within their own organization and with their partners and providers who play an important role in ensuring the security, safety and privacy of a business and its data.\n\nYour CMS is the heart of an important relationship\u2014with your readers, your employees and your partners. A compromised CMS, however, is a gold mine for cyber criminals and a source of risk for your business.\n\nWhat does this mean for content management systems, specifically?\n\nDigital transformation used to focus solely on products, applications and solutions, but organizations have been forced to evolve how they communicate as well\u2014internally, with partners and vendors, and with customers.\n\nHaving the right content management system is a crucial component in ensuring the right messages are shared at the right time and place. It\u2019s at the center of your operations and is the heart of the relationship that you have with your employees (via an intranet) and your readers and viewers if you\u2019re publishing news articles or other content. Your CMS represents your brand and is the vehicle you\u2019re using to communicate with your intended audience.\n\nBecause CMSs are an important piece in every organization\u2019s tech stack and because of their potential reach with various large and engaged audiences, they\u2019re also potential targets for attacks.\n\nOrganizations with a media presence or those who deliver digital content across multiple channels are especially hot targets, as the implications and fallout of the attack can spread quickly\u2014they\u2019re not just compromising a single website, but potentially a platform hosting millions of users.\n\nAccording to TechNative, a CMS breach can threaten business continuity and bring even the largest corporations to their knees within hours, so building a strong and reliable underlying infrastructure on which to host your CMS has never been more important.\n\nWe know that businesses have multiple systems, channels and processes in play as they try to digitally transform, and that adding one more challenge to those efforts can feel daunting. So, let\u2019s walk through some key considerations and security best practices together, so that you feel confident in your approach and can adjust as needed to ensure ultimate security for your organization.\n\nNearly 80% of senior IT and IT security leaders believe their organizations lack sufficient protection against cyberattacks. This is despite increased IT security investments made in 2020 to deal with distributed IT and work-from-home challenges, according to an IDG Research Services survey commissioned by Insight Enterprises.\n\nWhat are the different types of cyberattacks?\n\nFirst, it\u2019s important to be aware of the most common types of cyberattacks.\n\n\u201cRansomware,\u201d \u201cphishing\u201d and \u201cmalware\u201d are part of our everyday vernacular now. These are a few popular types of cyberattacks, but the approaches cyber criminals deploy are evolving as businesses continue to expand and use different platforms and channels of communicating.\n\nThis isn\u2019t only a concern over weak passwords; there\u2019s simply more opportunity for cyber criminals to attack.\n\nThe 3 most common types of attacks:\n\nDenial of service: Prevents you from providing your service to clients or customers\n\nDefacement or corruption: Changes the appearance of your online properties and can be more difficult to identify quickly\n\nData exfiltration: When the attacker takes and uses your data against you or negatively towards your clients or customers\n\nWhat your organization can do to avoid an attack: Security hygiene + assessment checklist\n\nThere are a few simple steps to take to ensure your CMS can and does comply with your company\u2019s security best practices. The critical component here, however, is that everyone needs to abide by them.\n\nPassword complexity: Ensure that your CMS is in compliance with your company\u2019s policies and guidelines regarding password length, complexity and expiration.\n\nMulti-factor authentication: Apply two-factor authentication for all access points to your CMS to create an additional firewall in the case of password infiltration among existing CMS users.\n\nIntegration with central identity management: Regularly maintain and monitor all users who have access to your CMS and audit levels of access and permissions via a centralized identity management database.\n\nIntegration with your security tools: Maintain your CMS security as you would any other software application, ensuring frequent backups of data, upgrading to the latest versions, and monitoring your systems for unusual activities and usage patterns.\n\nEven before an actual attack or assessment of a potential threat, it\u2019s important to follow these five steps to ensure the security of your CMS as a matter of routine protection.\n\nAssessment checklist\n\nReview your CMS users and eliminate unnecessary ones. Likewise, review all the roles and permissions for users of your CMS throughout your organization. Regularly monitor your websites and microsites to identify potential defacement. Regularly review all of your publishing changes made within the CMS to ensure they\u2019re legitimate and expected. Establish a specific method for your employees to report issues they believe are suspicious; create a streamlined communication process for this. Have your security incident processes documented; this allows you to conduct a postmortem with your organization and vendors that helped you navigate the attack.\n\nFinally, keep your organization trained and aware of what the cyber threats are today and hold regular training sessions to discuss what to watch for so they understand how these threats are evolving.\n\nThis includes making sure everybody knows how to report something if (or more realistically, when) they see something suspicious.\n\nWhat you and your tech partners can do to avoid an attack: Defense-in-depth approach\n\n\u201cDefense in depth\u201d is a time-tested strategy that ensures you don\u2019t have a single point of failure in your infrastructure by deploying distinct protocols at various layers.\n\nThe more customization you can do within the platform to meet your organization\u2019s security protocols, the better. And the right partner will have the tools and technology to integrate with and abide by your rules at different layers and levels.\n\nIt\u2019s key to partner with those that have their eye on multi-layered security to help protect against threats\u2014and ensure they understand and agree to your approach to security as well. Asking key questions that drill down into their approach is an essential step here.\n\nVendor Due Diligence: Security Questions for Your Partner\n\nLayer 1\n\nDo you have a security program handbook or guide?\n\nHow do you respond when a customer reports a security vulnerability?\n\nWhat\u2019s your process during and after an attack?\n\nWhat are you doing from a prevention standpoint?\n\nLayer 2\n\nWhat are you doing from a security standpoint at the code level?\n\nWhat operational security components are included in your platform\u2019s architecture?\n\nLayer 3\n\nAre you partnering with major cloud providers? What services are included through them?\n\nWhat do your partners leverage in terms of security architecture and code? Do they have a due diligence process you\u2019re familiar with?\n\nThen, it\u2019s important to make sure the best practices and approach that you\u2019ve agreed to within your organization\u2014and with your partners\u2014is manageable.\n\nOftentimes, businesses tend to make it too hard or prohibitive for their workforce to follow along and abide by security protocols and policies.\n\nFor example, if you write a policy or a practice in a vacuum and put together a workflow to support it, and if that process is too difficult for people to manage in their day-to-day, they will go around it or find a shortcut.\n\nWhen people start going around your policies, you start losing the ability to manage them, and you start introducing additional risk in your system. It\u2019s always important to not just make sure that you\u2019re checking all the security boxes, but also watching the behavior of people who are using those processes, tools and systems.\n\nIf you find they\u2019re creating alternate paths around certain controls\u2014fix the control to make it more friendly and attainable so everyone can more easily stay in compliance.\n\nIn conclusion: Stay ahead of the threat with a content platform you can trust\n\nOrganizations can and must be proactive in the face of a cyberattack. They also must be prepared well before a disruptive and potentially devastating incident occurs.\n\nTo assist, modern CMSs like Brightspot ensure elasticity within your operations and allow you to be nimble and act swiftly during turbulent times, all backed by the support of Brightspot experts.\n\nThat\u2019s why we have strong security defenses baked into our solutions as well as a dedicated support team available to provide guidance today\u2014and in times of crisis.Don\u2019t wait for cyber threats to strike. Set up a demo today and discover how Brightspot can fortify your digital resilience. If you know a developer who might be interested in trying out Brightspot, we can facilitate their trial request here.",
        "url": "https://techcrunch.com/sponsor/brightspot/how-to-protect-your-content-platform-and-your-business-from-cyberattacks/",
        "category": 2,
        "summary": "Organizations with a media presence or those who deliver digital content across multiple channels are especially hot targets, as the implications and fallout of the attack can spread quickly\u2014they\u2019re not just compromising a single website, but potentially a platform hosting millions of users. Fast forward to today, hardly a week goes by without some new story reporting that tens of thousands of WordPress sites have been exposed to security vulnerabilities through a plugin breach or sites running outdated versions of Drupal have fallen prey to hackers coming in through the backdoor. The 3 most common types of attacks:\n\nDenial of service: Prevents you from providing your service to clients or customers\n\nDefacement or corruption: Changes the appearance of your online properties and can be more difficult to identify quickly\n\nData exfiltration: When the attacker takes and uses your data against you or negatively towards your clients or customers\n\nWhat your organization can do to avoid an attack: Security hygiene + assessment checklist\n\nThere are a few simple steps to take to ensure your CMS can and does comply with your company\u2019s security best practices."
    },
    {
        "title": "How colleges can prepare students for today\u2019s modern workforce",
        "text": "When I was in college and imagined what my career might look like, I assumed it would be like what I witnessed in my internships at Boeing and Microsoft. I\u2019d be communicating by writing a lot of memos, letters, and emails. Collaborating with colleagues across the world would require extensive travel and lots of in person meetings. My educational experience was designed with that future in mind.\n\nBut today\u2019s economy is remarkably visual and globalized, and powered by technologies that I could hardly have imagined when I was in college. I have teammates literally all around the world, and we\u2019re still able to collaborate effectively. Visuals, rather than words, power our communication and story telling.\n\nMy experience illustrates one of the central challenges of our education system. The world is changing rapidly, and students change right alongside it. Education institutions are in a position where they must constantly adjust\u2014and quickly\u2014to prepare students for jobs that are guaranteed to be different from those that exist today.\n\nMany colleges and universities need support in adequately preparing students for the transition to the professional world. A recent Wiley poll found that just 46% of college students feel that their school is preparing students for employment in the real world after they graduate. This is contributing to a significant drop in college enrollment\u2014creating an existential threat for colleges and universities, most of which have limited financial flexibility.\n\nColleges and universities must respond to these pressing needs to ensure students acquire the skills necessary for success in the workforce. While this may feel daunting, we\u2019ve been here before. When computers and the internet started emerging in classrooms, there was a lot of fear and concern\u2014but now they\u2019re as much a part of the classroom as a calculator. With thoughtful changes to the student experience, we can empower students across the world to do their best work, achieve their goals, and acquire the skills to thrive both today and in the future.\n\nPreparing students to communicate visually\n\nAs workspaces continue to become more globalized, visual communication will play an even more pivotal role in facilitating collaboration and improving productivity. At Canva, we\u2019ve seen it in our Visual Economy Report \u2014 visuals are rapidly becoming the most impactful form of communication in the workplace, with 90% of global business leaders believing visual communication enhances efficiency, 89% seeing improved collaboration, and 85% acknowledging its authoritative impact. About two-thirds (61%) of global business leaders also say they expect workers in non-design roles to have \u201cextensive design knowledge,\u201d including the ability to create new graphics and presentations from scratch.\n\nThe good news is that young individuals are well-prepared for this shift, given the integral role visual communication plays in their daily interactions, particularly on social media. 80% of Gen Z teens say that YouTube has helped them become more knowledgeable about something \u2014 they already believe in visual communication because they use it every day.\n\nMany colleges and universities are building on that foundation by giving their students and staff access to products like Canva for Campus. Students can create their own presentations, images, videos, whiteboards and even animations. This allows them to create their best work while still having the ability to experiment and explore\u2014helping them learn how to communicate visually while unlocking their creativity, all while collaborating with their classmates.\n\nA new education imperative: AI literacy and skills\n\nIn the ever-evolving landscape of education, there\u2019s also a growing imperative for AI literacy and skills. The next decade of work is going to look different as AI has firmly establishes itself in today\u2019s workforce and is evolves into a crucial job skill.\n\nWhile this development may seem daunting, AI is already a reality, with millions utilizing tools like ChatGPT and DALL-E every day. According to Canva\u2019s recent survey of more than 4,000 global marketing leaders, the majority are already embracing AI to elevate creativity and increase output in the workplace. We also learned from our very first AI in Education study that teachers are increasingly seeing AI as a tool for enhancing student creativity.\n\nFor colleges and universities, it\u2019s not just about staying current with these technological trends; it\u2019s about empowering student with the practical skills necessary to excel in a workforce shaped by technology. By integrating AI education into the curriculum and providing hands-on experiences through platforms like Canva, universities play a pivotal role in ensuring their graduates are not only academically adept but also well-prepared for the demands of a technology-driven professional landscape.\n\nEmbracing a new era of education\n\nThe next decade of education is set to be a transformative one, and it\u2019s our collective repsonsibility to ensure we\u2019re setting the next generation of the workforce up for success. The college and university learning experience is a critical bridge between educational institutions and today\u2019s modern workplace. With more than 60 million students, teachers, and professors using Canva every month, this is a responsibility we take very seriously, and we\u2019re incredibly excited to be introducing our global community to the tools of the future.\n\n\u2014 Jason Wilmot, Canva",
        "url": "https://techcrunch.com/sponsor/canva/how-colleges-can-prepare-students-for-todays-modern-workforce/",
        "category": 1,
        "summary": "About two-thirds (61%) of global business leaders also say they expect workers in non-design roles to have \u201cextensive design knowledge,\u201d including the ability to create new graphics and presentations from scratch. By integrating AI education into the curriculum and providing hands-on experiences through platforms like Canva, universities play a pivotal role in ensuring their graduates are not only academically adept but also well-prepared for the demands of a technology-driven professional landscape. At Canva, we\u2019ve seen it in our Visual Economy Report \u2014 visuals are rapidly becoming the most impactful form of communication in the workplace, with 90% of global business leaders believing visual communication enhances efficiency, 89% seeing improved collaboration, and 85% acknowledging its authoritative impact."
    }
]